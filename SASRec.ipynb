{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sistemas de Recomendação Sequenciais\n",
    "\n",
    "Nesse projeto, iremos implementar o algoritmo SASRec, que é um algoritmo de\n",
    "recomendação sequencial.\n",
    "\n",
    "Primeiramente, o que é um algoritmo de recomendação sequencial? Um algoritmo de\n",
    "recomendação sequencial é uma subcategorial dos sistemas de recomendação, que\n",
    "são uma categoria de sistemas que tem como objetivo predizer o filtrar itens\n",
    "(como filmes, livros, etc.) que um usuário alvo irá gostar. Os sistemas de\n",
    "recomendação sequenciais se diferem ao tomar em consideração o tempo, ou seja,\n",
    "a ordem em que os usuários interagem com os itens do sistema, tentando predizer\n",
    "a partir disso a sua próxima interação.\n",
    "\n",
    "Esses sistemas são bastante semelhantes aos sistemas de recomendação baseados\n",
    "em sessão, tendo bastante intersectação entre eles. A diferença principal é que\n",
    "os sistemas de recomendação sequencial se baseia na ordem em que os usuários\n",
    "interagem os itens, já os sistemas de recomendação baseados em sessão se baseiam\n",
    "nos grupos de itens que um usuário interage com durante suas sessões de uso.\n",
    "\n",
    "Nesse projeto iremos usar um conjunto de dados de reprodução de músicas do \n",
    "last.fm (bem antigo, com reproduções até o final de 2009). Tomaremos uma \n",
    "abordagem mista, onde separaremos a sequência dos usuários em blocos menores de\n",
    "reprodução contínua de músicas que chamaremos de sessões de uso, já que isso nos\n",
    "permitirá expandir os dados em mais blocos de sequências menores, o que\n",
    "acreditamos fazer mais sentido no contexto de predizer a próxima música, já que\n",
    "assumimos que o passado recente é mais relevante para a próxima música que\n",
    "históricos distantes e temos uma limitação de janela de quantos itens podemos\n",
    "escolher para o passado recente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T20:06:54.045698Z",
     "start_time": "2024-11-23T20:06:54.042378Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import warnings\n",
    "import contextlib\n",
    "from datetime import timedelta, datetime\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import display\n",
    "from ipywidgets.widgets import HBox\n",
    "\n",
    "import torch\n",
    "from torch.functional import F\n",
    "from torch import nn, optim, cuda\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Colab\n",
    "\n",
    "Configurando persistência de dados caso esteja rodando dentro do ambiente do Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T19:10:42.037723Z",
     "start_time": "2024-11-23T19:10:42.035812Z"
    }
   },
   "outputs": [],
   "source": [
    "ROOT_PATH = './'\n",
    "DRIVE_PATH = 'Colab/RecSys-TP'\n",
    "\n",
    "# When on Colab, use Google Drive as the root path to persist and load data\n",
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import drive, output\n",
    "    output.enable_custom_widget_manager()\n",
    "\n",
    "    drive.mount('/content/drive')\n",
    "    ROOT_PATH = os.path.join('/content/drive/My Drive/', DRIVE_PATH)\n",
    "    os.makedirs(ROOT_PATH, exist_ok=True)\n",
    "    os.chdir(ROOT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurações\n",
    "\n",
    "Detectando o dispositivo a ser utilizado para treinamento (CPU ou GPU), além de outras configurações de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T19:10:42.236754Z",
     "start_time": "2024-11-23T19:10:42.083373Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device for PyTorch\n"
     ]
    }
   ],
   "source": [
    "RANDOM_SEED = 1984\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "MAX_SEQUENCE_LENGTH = 50\n",
    "DROPOUT_PROB = 0.4\n",
    "HIDDEN_DIM = 64\n",
    "NUM_BLOCKS = 2\n",
    "\n",
    "TOTAL_EPOCHS = 500\n",
    "\n",
    "BETA_1 = 0.9\n",
    "BETA_2 = 0.999\n",
    "EPS = 1e-8\n",
    "AMSGRAD = False\n",
    "WEIGHT_DECAY = 0.01\n",
    "\n",
    "WARMUP_RATIO = 0.05\n",
    "LEARNING_RATE = 0.04\n",
    "USE_SCHEDULER = True\n",
    "\n",
    "# LEARNING_RATE = 0.004\n",
    "# USE_SCHEDULER = False\n",
    "\n",
    "EVAL_K = 10\n",
    "\n",
    "\n",
    "PYTORCH_DEVICE = 'cpu'\n",
    "\n",
    "# Use NVIDIA GPU if available\n",
    "if cuda.is_available():\n",
    "    PYTORCH_DEVICE = 'cuda'\n",
    "\n",
    "# Use Apple Metal backend if available\n",
    "if torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\"Your device supports MPS but it is not installed. Checkout https://developer.apple.com/metal/pytorch/\")\n",
    "    else:\n",
    "        PYTORCH_DEVICE = 'mps'\n",
    "\n",
    "\n",
    "print (f\"Using {PYTORCH_DEVICE} device for PyTorch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T19:10:42.245640Z",
     "start_time": "2024-11-23T19:10:42.240744Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.mps.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T19:10:43.461033Z",
     "start_time": "2024-11-23T19:10:42.285170Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>gender</th><th>age</th><th>country</th><th>registered</th></tr><tr><td>str</td><td>str</td><td>i64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;user_000809&quot;</td><td>&quot;m&quot;</td><td>null</td><td>&quot;Finland&quot;</td><td>&quot;Jun&nbsp;8,&nbsp;2005&quot;</td></tr><tr><td>&quot;user_000112&quot;</td><td>&quot;f&quot;</td><td>30</td><td>&quot;Turkey&quot;</td><td>&quot;Mar&nbsp;25,&nbsp;2006&quot;</td></tr><tr><td>&quot;user_000086&quot;</td><td>&quot;f&quot;</td><td>27</td><td>null</td><td>&quot;Sep&nbsp;21,&nbsp;2007&quot;</td></tr><tr><td>&quot;user_000403&quot;</td><td>&quot;f&quot;</td><td>null</td><td>&quot;United&nbsp;States&quot;</td><td>&quot;May&nbsp;17,&nbsp;2006&quot;</td></tr><tr><td>&quot;user_000863&quot;</td><td>null</td><td>null</td><td>&quot;United&nbsp;Kingdom&quot;</td><td>&quot;Oct&nbsp;15,&nbsp;2004&quot;</td></tr><tr><td>&quot;user_000720&quot;</td><td>&quot;f&quot;</td><td>null</td><td>&quot;Norway&quot;</td><td>&quot;Jun&nbsp;29,&nbsp;2007&quot;</td></tr><tr><td>&quot;user_000985&quot;</td><td>&quot;f&quot;</td><td>null</td><td>&quot;Australia&quot;</td><td>&quot;May&nbsp;22,&nbsp;2006&quot;</td></tr><tr><td>&quot;user_000487&quot;</td><td>&quot;m&quot;</td><td>null</td><td>&quot;Netherlands&quot;</td><td>&quot;Mar&nbsp;8,&nbsp;2006&quot;</td></tr><tr><td>&quot;user_000049&quot;</td><td>null</td><td>null</td><td>null</td><td>&quot;Jan&nbsp;11,&nbsp;2006&quot;</td></tr><tr><td>&quot;user_000184&quot;</td><td>&quot;f&quot;</td><td>23</td><td>&quot;Canada&quot;</td><td>&quot;Jun&nbsp;3,&nbsp;2006&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 5)\n",
       "┌─────────────┬────────┬──────┬────────────────┬──────────────┐\n",
       "│ user_id     ┆ gender ┆ age  ┆ country        ┆ registered   │\n",
       "│ ---         ┆ ---    ┆ ---  ┆ ---            ┆ ---          │\n",
       "│ str         ┆ str    ┆ i64  ┆ str            ┆ str          │\n",
       "╞═════════════╪════════╪══════╪════════════════╪══════════════╡\n",
       "│ user_000809 ┆ m      ┆ null ┆ Finland        ┆ Jun 8, 2005  │\n",
       "│ user_000112 ┆ f      ┆ 30   ┆ Turkey         ┆ Mar 25, 2006 │\n",
       "│ user_000086 ┆ f      ┆ 27   ┆ null           ┆ Sep 21, 2007 │\n",
       "│ user_000403 ┆ f      ┆ null ┆ United States  ┆ May 17, 2006 │\n",
       "│ user_000863 ┆ null   ┆ null ┆ United Kingdom ┆ Oct 15, 2004 │\n",
       "│ user_000720 ┆ f      ┆ null ┆ Norway         ┆ Jun 29, 2007 │\n",
       "│ user_000985 ┆ f      ┆ null ┆ Australia      ┆ May 22, 2006 │\n",
       "│ user_000487 ┆ m      ┆ null ┆ Netherlands    ┆ Mar 8, 2006  │\n",
       "│ user_000049 ┆ null   ┆ null ┆ null           ┆ Jan 11, 2006 │\n",
       "│ user_000184 ┆ f      ┆ 23   ┆ Canada         ┆ Jun 3, 2006  │\n",
       "└─────────────┴────────┴──────┴────────────────┴──────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>timestamp</th><th>artist_id</th><th>artist_name</th><th>track_id</th><th>track_name</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;user_000806&quot;</td><td>&quot;2008-08-09T19:28:14Z&quot;</td><td>&quot;fc61dd75-880b-44ba-9ba9-c7b643…</td><td>&quot;Prefuse&nbsp;73&quot;</td><td>&quot;60f3a1c9-e756-4a48-8a3e-c44140…</td><td>&quot;Altoid&nbsp;Addiction&nbsp;(Interlude)&quot;</td></tr><tr><td>&quot;user_000108&quot;</td><td>&quot;2007-12-19T17:14:42Z&quot;</td><td>&quot;6ae51665-8261-4ae5-883f-189965…</td><td>&quot;Filter&quot;</td><td>&quot;784f24f6-6fa7-44e7-81a5-a7b592…</td><td>&quot;The&nbsp;Best&nbsp;Things&quot;</td></tr><tr><td>&quot;user_000079&quot;</td><td>&quot;2008-12-01T00:09:19Z&quot;</td><td>&quot;48896dee-a985-424d-9849-84802f…</td><td>&quot;Johnny&nbsp;Mathis&quot;</td><td>&quot;e77a742f-eb2c-417c-9b48-45e404…</td><td>&quot;Can&#x27;T&nbsp;Get&nbsp;Out&nbsp;Of&nbsp;This&nbsp;Mood&quot;</td></tr><tr><td>&quot;user_000407&quot;</td><td>&quot;2008-05-20T15:37:40Z&quot;</td><td>&quot;8bfac288-ccc5-448d-9573-c33ea2…</td><td>&quot;Red&nbsp;Hot&nbsp;Chili&nbsp;Peppers&quot;</td><td>&quot;7a3e8796-a0b3-4999-b268-4e2d47…</td><td>&quot;Otherside&quot;</td></tr><tr><td>&quot;user_000861&quot;</td><td>&quot;2008-02-12T22:25:17Z&quot;</td><td>&quot;31aa6f87-8d00-4ae9-a5cc-6d7eee…</td><td>&quot;Alphaville&quot;</td><td>&quot;f11939cf-9ad1-45b8-b927-a89b00…</td><td>&quot;Big&nbsp;In&nbsp;Japan&quot;</td></tr><tr><td>&quot;user_000728&quot;</td><td>&quot;2009-05-21T19:04:24Z&quot;</td><td>&quot;41c86965-305a-482d-bc1e-2daeca…</td><td>&quot;Skankfunk&quot;</td><td>&quot;e48c9ed7-34ac-44aa-ab5a-3d792a…</td><td>&quot;Melo-Pole&quot;</td></tr><tr><td>&quot;user_000990&quot;</td><td>&quot;2009-03-31T10:20:28Z&quot;</td><td>&quot;1bc69a93-8020-4e07-8b05-0b6331…</td><td>&quot;The&nbsp;Cliks&quot;</td><td>&quot;f89ba590-0226-4c65-b5c5-4b69ee…</td><td>&quot;Complicated&quot;</td></tr><tr><td>&quot;user_000174&quot;</td><td>&quot;2005-05-03T18:42:12Z&quot;</td><td>&quot;fc178247-53b6-4702-ad77-546cb0…</td><td>&quot;The&nbsp;Exposures&quot;</td><td>&quot;b222a53c-3168-43e5-a40d-65e95a…</td><td>&quot;Sake&nbsp;Rock&quot;</td></tr><tr><td>&quot;user_000412&quot;</td><td>&quot;2005-11-04T22:08:08Z&quot;</td><td>&quot;86e736b4-93e2-40ff-9e1c-fb7c63…</td><td>&quot;Barenaked&nbsp;Ladies&quot;</td><td>&quot;05b34070-535a-4b92-aa9b-ecb97c…</td><td>&quot;Call&nbsp;And&nbsp;Answer&quot;</td></tr><tr><td>&quot;user_000112&quot;</td><td>&quot;2007-12-11T01:00:05Z&quot;</td><td>&quot;fc63a914-272d-4b95-9221-61adcc…</td><td>&quot;Gal&nbsp;Costa&quot;</td><td>&quot;08345bf4-f7b1-40ff-98c3-21b34c…</td><td>&quot;Estrada&nbsp;Do&nbsp;Sol&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 6)\n",
       "┌─────────────┬────────────────┬────────────────┬────────────────┬────────────────┬────────────────┐\n",
       "│ user_id     ┆ timestamp      ┆ artist_id      ┆ artist_name    ┆ track_id       ┆ track_name     │\n",
       "│ ---         ┆ ---            ┆ ---            ┆ ---            ┆ ---            ┆ ---            │\n",
       "│ str         ┆ str            ┆ str            ┆ str            ┆ str            ┆ str            │\n",
       "╞═════════════╪════════════════╪════════════════╪════════════════╪════════════════╪════════════════╡\n",
       "│ user_000806 ┆ 2008-08-09T19: ┆ fc61dd75-880b- ┆ Prefuse 73     ┆ 60f3a1c9-e756- ┆ Altoid         │\n",
       "│             ┆ 28:14Z         ┆ 44ba-9ba9-c7b6 ┆                ┆ 4a48-8a3e-c441 ┆ Addiction      │\n",
       "│             ┆                ┆ 43…            ┆                ┆ 40…            ┆ (Interlude)    │\n",
       "│ user_000108 ┆ 2007-12-19T17: ┆ 6ae51665-8261- ┆ Filter         ┆ 784f24f6-6fa7- ┆ The Best       │\n",
       "│             ┆ 14:42Z         ┆ 4ae5-883f-1899 ┆                ┆ 44e7-81a5-a7b5 ┆ Things         │\n",
       "│             ┆                ┆ 65…            ┆                ┆ 92…            ┆                │\n",
       "│ user_000079 ┆ 2008-12-01T00: ┆ 48896dee-a985- ┆ Johnny Mathis  ┆ e77a742f-eb2c- ┆ Can'T Get Out  │\n",
       "│             ┆ 09:19Z         ┆ 424d-9849-8480 ┆                ┆ 417c-9b48-45e4 ┆ Of This Mood   │\n",
       "│             ┆                ┆ 2f…            ┆                ┆ 04…            ┆                │\n",
       "│ user_000407 ┆ 2008-05-20T15: ┆ 8bfac288-ccc5- ┆ Red Hot Chili  ┆ 7a3e8796-a0b3- ┆ Otherside      │\n",
       "│             ┆ 37:40Z         ┆ 448d-9573-c33e ┆ Peppers        ┆ 4999-b268-4e2d ┆                │\n",
       "│             ┆                ┆ a2…            ┆                ┆ 47…            ┆                │\n",
       "│ user_000861 ┆ 2008-02-12T22: ┆ 31aa6f87-8d00- ┆ Alphaville     ┆ f11939cf-9ad1- ┆ Big In Japan   │\n",
       "│             ┆ 25:17Z         ┆ 4ae9-a5cc-6d7e ┆                ┆ 45b8-b927-a89b ┆                │\n",
       "│             ┆                ┆ ee…            ┆                ┆ 00…            ┆                │\n",
       "│ user_000728 ┆ 2009-05-21T19: ┆ 41c86965-305a- ┆ Skankfunk      ┆ e48c9ed7-34ac- ┆ Melo-Pole      │\n",
       "│             ┆ 04:24Z         ┆ 482d-bc1e-2dae ┆                ┆ 44aa-ab5a-3d79 ┆                │\n",
       "│             ┆                ┆ ca…            ┆                ┆ 2a…            ┆                │\n",
       "│ user_000990 ┆ 2009-03-31T10: ┆ 1bc69a93-8020- ┆ The Cliks      ┆ f89ba590-0226- ┆ Complicated    │\n",
       "│             ┆ 20:28Z         ┆ 4e07-8b05-0b63 ┆                ┆ 4c65-b5c5-4b69 ┆                │\n",
       "│             ┆                ┆ 31…            ┆                ┆ ee…            ┆                │\n",
       "│ user_000174 ┆ 2005-05-03T18: ┆ fc178247-53b6- ┆ The Exposures  ┆ b222a53c-3168- ┆ Sake Rock      │\n",
       "│             ┆ 42:12Z         ┆ 4702-ad77-546c ┆                ┆ 43e5-a40d-65e9 ┆                │\n",
       "│             ┆                ┆ b0…            ┆                ┆ 5a…            ┆                │\n",
       "│ user_000412 ┆ 2005-11-04T22: ┆ 86e736b4-93e2- ┆ Barenaked      ┆ 05b34070-535a- ┆ Call And       │\n",
       "│             ┆ 08:08Z         ┆ 40ff-9e1c-fb7c ┆ Ladies         ┆ 4b92-aa9b-ecb9 ┆ Answer         │\n",
       "│             ┆                ┆ 63…            ┆                ┆ 7c…            ┆                │\n",
       "│ user_000112 ┆ 2007-12-11T01: ┆ fc63a914-272d- ┆ Gal Costa      ┆ 08345bf4-f7b1- ┆ Estrada Do Sol │\n",
       "│             ┆ 00:05Z         ┆ 4b95-9221-61ad ┆                ┆ 40ff-98c3-21b3 ┆                │\n",
       "│             ┆                ┆ cc…            ┆                ┆ 4c…            ┆                │\n",
       "└─────────────┴────────────────┴────────────────┴────────────────┴────────────────┴────────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Carrega os dados do dataset (http://ocelma.net/MusicRecommendationDataset/lastfm-1K.html)\n",
    "user_profiles = pl.read_csv(\"./data/lastfm-dataset-1K/userid-profile.tsv\", separator=\"\\t\")\n",
    "user_interactions = pl.read_csv(\"./data/lastfm-dataset-1K/userid-timestamp-artid-artname-traid-traname.tsv\", separator=\"\\t\", has_header=False, quote_char=None)\n",
    "\n",
    "# Renomeia as colunas\n",
    "user_profiles.columns = [\"user_id\", \"gender\", \"age\", \"country\", \"registered\"]\n",
    "user_interactions.columns = [\"user_id\", \"timestamp\", \"artist_id\", \"artist_name\", \"track_id\", \"track_name\"]\n",
    "\n",
    "# Descarta linhas com valores nulos nas iterações\n",
    "user_interactions = user_interactions.drop_nulls()\n",
    "\n",
    "display(user_profiles.sample(10, seed=RANDOM_SEED))\n",
    "display(user_interactions.sample(10, seed=RANDOM_SEED))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T19:10:53.402635Z",
     "start_time": "2024-11-23T19:10:43.477374Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>uid</th><th>iid</th><th>ts</th></tr><tr><td>i64</td><td>i64</td><td>datetime[μs]</td></tr></thead><tbody><tr><td>1</td><td>597423</td><td>2006-03-17&nbsp;14:08:20</td></tr><tr><td>1</td><td>110737</td><td>2006-03-17&nbsp;14:13:36</td></tr><tr><td>1</td><td>699216</td><td>2006-03-17&nbsp;14:21:22</td></tr><tr><td>1</td><td>261464</td><td>2006-03-17&nbsp;14:24:38</td></tr><tr><td>1</td><td>403066</td><td>2006-03-17&nbsp;14:27:18</td></tr><tr><td>1</td><td>660618</td><td>2006-03-17&nbsp;14:29:43</td></tr><tr><td>1</td><td>498360</td><td>2006-03-17&nbsp;14:32:44</td></tr><tr><td>1</td><td>90850</td><td>2006-03-17&nbsp;14:37:24</td></tr><tr><td>1</td><td>349638</td><td>2006-03-17&nbsp;14:42:10</td></tr><tr><td>1</td><td>891170</td><td>2006-03-17&nbsp;14:46:10</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 3)\n",
       "┌─────┬────────┬─────────────────────┐\n",
       "│ uid ┆ iid    ┆ ts                  │\n",
       "│ --- ┆ ---    ┆ ---                 │\n",
       "│ i64 ┆ i64    ┆ datetime[μs]        │\n",
       "╞═════╪════════╪═════════════════════╡\n",
       "│ 1   ┆ 597423 ┆ 2006-03-17 14:08:20 │\n",
       "│ 1   ┆ 110737 ┆ 2006-03-17 14:13:36 │\n",
       "│ 1   ┆ 699216 ┆ 2006-03-17 14:21:22 │\n",
       "│ 1   ┆ 261464 ┆ 2006-03-17 14:24:38 │\n",
       "│ 1   ┆ 403066 ┆ 2006-03-17 14:27:18 │\n",
       "│ 1   ┆ 660618 ┆ 2006-03-17 14:29:43 │\n",
       "│ 1   ┆ 498360 ┆ 2006-03-17 14:32:44 │\n",
       "│ 1   ┆ 90850  ┆ 2006-03-17 14:37:24 │\n",
       "│ 1   ┆ 349638 ┆ 2006-03-17 14:42:10 │\n",
       "│ 1   ┆ 891170 ┆ 2006-03-17 14:46:10 │\n",
       "└─────┴────────┴─────────────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cria um mapeamento dos IDs para números\n",
    "item_ids = user_interactions['track_id'].unique().to_list()\n",
    "user_ids = user_interactions['user_id'].unique().to_list()\n",
    "\n",
    "\n",
    "item_id_index = {id: i + 1 for i, id in enumerate(item_ids)}\n",
    "item_id_index_rev = {v: k for k, v in item_id_index.items()}\n",
    "\n",
    "user_id_index = {id: i + 1 for i, id in enumerate(user_ids)}\n",
    "user_id_index_rev = {v: k for k, v in user_id_index.items()}\n",
    "\n",
    "\n",
    "# Aplica as transformações no dataframe\n",
    "dataset = user_interactions.select(\n",
    "    pl.col('user_id').replace_strict(user_id_index).alias('uid'),\n",
    "    pl.col('track_id').replace_strict(item_id_index).alias('iid'),\n",
    "    pl.col('timestamp').cast(pl.Datetime).alias('ts')\n",
    ").sort('uid', 'ts')\n",
    "\n",
    "max_iid = dataset['iid'].max()\n",
    "\n",
    "display(dataset.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separando as sessões\n",
    "\n",
    "Devido a natureza do Last.FM, cada usuário possui um histórico de músicas ao \n",
    "longo de um extenso período de tempo. Para melhorar a qualidade e usabilidade do\n",
    "modelo, separamemos as reproduções em sessões, definindo o fim de uma sessão \n",
    "como um período de tempo de 30 minutos onde não houve nenhuma reprodução de \n",
    "música.\n",
    "\n",
    "Desse modo conseguimos ter sessões de tamanho arbitrário que representam a \n",
    "reprodução contínua de músicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T19:10:54.014693Z",
     "start_time": "2024-11-23T19:10:53.644882Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (16_982_280, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>uid</th><th>iid</th><th>ts</th><th>sid</th></tr><tr><td>i64</td><td>i64</td><td>datetime[μs]</td><td>u32</td></tr></thead><tbody><tr><td>1</td><td>597423</td><td>2006-03-17&nbsp;14:08:20</td><td>1</td></tr><tr><td>1</td><td>110737</td><td>2006-03-17&nbsp;14:13:36</td><td>1</td></tr><tr><td>1</td><td>699216</td><td>2006-03-17&nbsp;14:21:22</td><td>1</td></tr><tr><td>1</td><td>261464</td><td>2006-03-17&nbsp;14:24:38</td><td>1</td></tr><tr><td>1</td><td>403066</td><td>2006-03-17&nbsp;14:27:18</td><td>1</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>992</td><td>136460</td><td>2009-04-30&nbsp;17:30:16</td><td>899897</td></tr><tr><td>992</td><td>438858</td><td>2009-04-30&nbsp;17:32:23</td><td>899897</td></tr><tr><td>992</td><td>103181</td><td>2009-04-30&nbsp;17:34:48</td><td>899897</td></tr><tr><td>992</td><td>330690</td><td>2009-04-30&nbsp;17:39:25</td><td>899897</td></tr><tr><td>992</td><td>867190</td><td>2009-05-01&nbsp;18:19:46</td><td>899898</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (16_982_280, 4)\n",
       "┌─────┬────────┬─────────────────────┬────────┐\n",
       "│ uid ┆ iid    ┆ ts                  ┆ sid    │\n",
       "│ --- ┆ ---    ┆ ---                 ┆ ---    │\n",
       "│ i64 ┆ i64    ┆ datetime[μs]        ┆ u32    │\n",
       "╞═════╪════════╪═════════════════════╪════════╡\n",
       "│ 1   ┆ 597423 ┆ 2006-03-17 14:08:20 ┆ 1      │\n",
       "│ 1   ┆ 110737 ┆ 2006-03-17 14:13:36 ┆ 1      │\n",
       "│ 1   ┆ 699216 ┆ 2006-03-17 14:21:22 ┆ 1      │\n",
       "│ 1   ┆ 261464 ┆ 2006-03-17 14:24:38 ┆ 1      │\n",
       "│ 1   ┆ 403066 ┆ 2006-03-17 14:27:18 ┆ 1      │\n",
       "│ …   ┆ …      ┆ …                   ┆ …      │\n",
       "│ 992 ┆ 136460 ┆ 2009-04-30 17:30:16 ┆ 899897 │\n",
       "│ 992 ┆ 438858 ┆ 2009-04-30 17:32:23 ┆ 899897 │\n",
       "│ 992 ┆ 103181 ┆ 2009-04-30 17:34:48 ┆ 899897 │\n",
       "│ 992 ┆ 330690 ┆ 2009-04-30 17:39:25 ┆ 899897 │\n",
       "│ 992 ┆ 867190 ┆ 2009-05-01 18:19:46 ┆ 899898 │\n",
       "└─────┴────────┴─────────────────────┴────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "threshold = timedelta(minutes=30)\n",
    "\n",
    "# Marca cada música como se ela representa ou não o início de uma nova sessão\n",
    "new_session_col = dataset.group_by('uid') \\\n",
    "    .agg(\n",
    "        # Separa por usuário (uma sessão é de um usuário)\n",
    "        pl.col('iid'), \n",
    "\n",
    "        # Computa a diferença entre a música atual e a anterior, se essa \n",
    "        # diferença for nula ou maior igual ao nosso limite de tempo,\n",
    "        # então é um início de sessão.\n",
    "        (pl.col('ts').diff().fill_null(threshold) >= threshold).alias('start') , \n",
    "    # Expande as duas listas simultaneamente para que voltemos ao formato inicial\n",
    "    ).explode('iid', 'start')['start'] \n",
    "\n",
    "# Agora, para criar um id para cada sessão, vamos usar a função cum_sum (isso \n",
    "# funciona pois nossos dados estão ordenados por usuário e timestamp, \n",
    "# respectivamente)\n",
    "dataset_with_session = dataset.with_columns(new_session_col.cum_sum().alias('sid'))\n",
    "\n",
    "display(dataset_with_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T19:10:54.404130Z",
     "start_time": "2024-11-23T19:10:54.252276Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>sid</th><th>iids</th></tr><tr><td>u32</td><td>list[i64]</td></tr></thead><tbody><tr><td>117591</td><td>[832385,&nbsp;225508,&nbsp;…&nbsp;239103]</td></tr><tr><td>154938</td><td>[472615,&nbsp;199975,&nbsp;…&nbsp;117821]</td></tr><tr><td>609790</td><td>[562867,&nbsp;653424,&nbsp;…&nbsp;307823]</td></tr><tr><td>142353</td><td>[611574,&nbsp;239273,&nbsp;…&nbsp;718995]</td></tr><tr><td>422608</td><td>[907537,&nbsp;907537,&nbsp;…&nbsp;687487]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 2)\n",
       "┌────────┬────────────────────────────┐\n",
       "│ sid    ┆ iids                       │\n",
       "│ ---    ┆ ---                        │\n",
       "│ u32    ┆ list[i64]                  │\n",
       "╞════════╪════════════════════════════╡\n",
       "│ 117591 ┆ [832385, 225508, … 239103] │\n",
       "│ 154938 ┆ [472615, 199975, … 117821] │\n",
       "│ 609790 ┆ [562867, 653424, … 307823] │\n",
       "│ 142353 ┆ [611574, 239273, … 718995] │\n",
       "│ 422608 ┆ [907537, 907537, … 687487] │\n",
       "└────────┴────────────────────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>value</th></tr><tr><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>899898.0</td></tr><tr><td>&quot;null_count&quot;</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>18.871339</td></tr><tr><td>&quot;std&quot;</td><td>43.066011</td></tr><tr><td>&quot;min&quot;</td><td>1.0</td></tr><tr><td>&quot;25%&quot;</td><td>3.0</td></tr><tr><td>&quot;50%&quot;</td><td>9.0</td></tr><tr><td>&quot;75%&quot;</td><td>21.0</td></tr><tr><td>&quot;max&quot;</td><td>5435.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 2)\n",
       "┌────────────┬───────────┐\n",
       "│ statistic  ┆ value     │\n",
       "│ ---        ┆ ---       │\n",
       "│ str        ┆ f64       │\n",
       "╞════════════╪═══════════╡\n",
       "│ count      ┆ 899898.0  │\n",
       "│ null_count ┆ 0.0       │\n",
       "│ mean       ┆ 18.871339 │\n",
       "│ std        ┆ 43.066011 │\n",
       "│ min        ┆ 1.0       │\n",
       "│ 25%        ┆ 3.0       │\n",
       "│ 50%        ┆ 9.0       │\n",
       "│ 75%        ┆ 21.0      │\n",
       "│ max        ┆ 5435.0    │\n",
       "└────────────┴───────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Agrupa as reproduções por sessão em um array\n",
    "dataset_grouped = dataset_with_session.group_by('sid').agg(pl.col('iid').alias('iids'))\n",
    "display(dataset_grouped.head())\n",
    "\n",
    "# Imprime a distribuição do tamanho das sessões\n",
    "display(dataset_grouped['iids'].list.len().describe())\n",
    "\n",
    "\n",
    "# Reduz o número de amostras para reduzir o tempo de treinamento (ao custo de\n",
    "# uma redução na qualidade da base de dados) Seguiremos com 100k sessões das\n",
    "# ~900k presentes na base.\n",
    "dataset_grouped = dataset_grouped.sample(1e5, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separação dos dados de treino, teste e validação\n",
    "\n",
    "Iremos dividir o dataset em 3 conjuntos de treino, teste e validação. Desta\n",
    "forma, conseguimos avaliar ao longo do treinamento a qualidade do modelo\n",
    "por meio dos dados de validação evitando um enviesamento para a avaliação final\n",
    "utilizando os dados de teste.\n",
    "\n",
    "Temos duas estratégias possíveis para separação aqui: a primeira seria\n",
    "utilizar uma separação por sessão, ou seja, dedicar parte das sessões para\n",
    "cada um dos conjuntos. Outra alternativa é manter todas as sessões nos 3\n",
    "conjuntos, modificando removendo as últimas duas reproduções para os dados\n",
    "de treino, a última para os dados de validação e mantendo os dados completos\n",
    "para os dados de teste.\n",
    "\n",
    "Seguiremos com a segunda estratégia, mantendo todas as sessões nos 3 conjuntos,\n",
    "já que parece ter sido a estratégia tomada no artigo original, entretanto \n",
    "acreditamos que isso pode afetar a qualidade da avaliação final pela\n",
    "similaridade com os dados de treino durante a validação e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T19:10:55.006495Z",
     "start_time": "2024-11-23T19:10:54.642475Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_slice(data: list[int]) -> list[int]:\n",
    "    if len(data) < 3:\n",
    "        return data\n",
    "    \n",
    "    return data[:-2]\n",
    "\n",
    "def validation_slice(data: list[int]) -> tuple[list[int], int] | None:\n",
    "    if len(data) < 3:\n",
    "        return None\n",
    "    \n",
    "    return (data[:-2], data[-2])\n",
    "\n",
    "def test_slice(data: list[int]) -> tuple[list[int], int] | None:\n",
    "    if len(data) < 3:\n",
    "        return None\n",
    "    \n",
    "    return (data[:-1], data[-1])\n",
    "\n",
    "train_data = [train_slice(data.to_numpy()) for data in dataset_grouped['iids']]\n",
    "validation_data = [validation_slice(data.to_numpy()) for data in dataset_grouped['iids'] if len(data) > 2]\n",
    "test_data = [test_slice(data.to_numpy()) for data in dataset_grouped['iids'] if len(data) > 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O modelo \"Self-Attentive Sequential Recommendation\" (SASRec)\n",
    "\n",
    "O modelo SASRec foi proposto em 2018 pelos pesquisadores\n",
    "[Wang-Cheng Kang e Julian McAuley](https://arxiv.org/abs/1808.09781). Ele\n",
    "consiste de um modelo para recomendação sequencial baseado na (recente no \n",
    "momento de lançamento) arquitetura de atenção \n",
    "([Attention is All You Need](https://arxiv.org/abs/1706.03762)), construindo\n",
    "assim uma rede neural profunda com embeddings, camadas de atenção e camadas de\n",
    "avanço pontual para o propósito de gerar recomendações baseadas em dados \n",
    "sequenciais. Esse modelo foi um dos pioneiros nessa estratégia, resultando em\n",
    "avanços significativos na qualidade das recomendações. Um dos seus pontos\n",
    "limitantes é a não inclusão de informações contextuais (como dados dos itens e\n",
    "usuários) para a geração das recomendações.\n",
    "\n",
    "![Diagrama simplificado da estrutura do modelo - retirado do paper original](./assets/sasrec-diagram.png)\n",
    "\n",
    "Esse modelo foi capaz de superar os resultados de outros modelos proeminentes\n",
    "durante seu lançamento, como o BPR, FPMC, TransRec e GRU4Rec.\n",
    "\n",
    "### A implementação\n",
    "\n",
    "Partimos de uma implementação já existente em PyTorch que se baseia, \n",
    "indiretamente, na implementação original dos autores em TensorFlow:\n",
    "[versão em PyTorch por _seanswyi_](https://github.com/seanswyi/sasrec-pytorch).\n",
    "\n",
    "Fizemos algumas adaptações em relação ao original, porém sem afetar a estrutura\n",
    "da rede em si, apenas mudando o otmizado utilizado, batch size, parâmetros e\n",
    "alguns pequenos ajustes no código para fica mais organizado, marginalmente mais\n",
    "eficiente e ao ambiente de desenvolvimento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T19:10:55.243881Z",
     "start_time": "2024-11-23T19:10:55.238120Z"
    }
   },
   "outputs": [],
   "source": [
    "# The following SASRec implementation is an adaptation from https://github.com/seanswyi/sasrec-pytorch\n",
    "\n",
    "InputSequences = torch.Tensor\n",
    "PositiveSamples = torch.Tensor\n",
    "NegativeSamples = torch.Tensor\n",
    "\n",
    "class PointWiseFFNN(nn.Module):\n",
    "    def __init__(self, hidden_dim: int) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.W1 = nn.Linear(in_features=hidden_dim, out_features=hidden_dim)\n",
    "        self.W2 = nn.Linear(in_features=hidden_dim, out_features=hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_1 = self.relu(self.W1(x))\n",
    "        x_2 = self.W2(x_1)\n",
    "\n",
    "        return x_2\n",
    "\n",
    "\n",
    "class SelfAttnBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_seq_len: int,\n",
    "        hidden_dim: int,\n",
    "        dropout_p: float,\n",
    "        device: str,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.layer_norm = nn.LayerNorm(normalized_shape=hidden_dim)\n",
    "        self.dropout = nn.Dropout(p=dropout_p)\n",
    "\n",
    "        self.self_attn = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_dim,\n",
    "            num_heads=1,\n",
    "            dropout=dropout_p,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.ffnn = PointWiseFFNN(hidden_dim=hidden_dim)\n",
    "\n",
    "    def dropout_layernorm(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        layer_norm_output = self.layer_norm(x)\n",
    "        dropout_output = self.dropout(layer_norm_output)\n",
    "\n",
    "        return dropout_output\n",
    "\n",
    "    def forward(self, x: torch.Tensor, padding_mask: torch.Tensor) -> torch.Tensor:\n",
    "        seq_len = x.shape[1]\n",
    "        attention_mask = ~torch.tril(\n",
    "            torch.ones(size=(seq_len, seq_len), dtype=torch.bool, device=x.device.type)\n",
    "        )\n",
    "\n",
    "        x_attn, _ = self.self_attn(\n",
    "            key=self.layer_norm(x),\n",
    "            query=x,\n",
    "            value=x,\n",
    "            attn_mask=attention_mask,\n",
    "        )\n",
    "        x_attn_output = x + self.dropout_layernorm(x_attn)\n",
    "\n",
    "        x_ffnn = self.ffnn(x_attn_output)\n",
    "        x_ffnn_output = x_attn_output + self.dropout_layernorm(x_ffnn)\n",
    "\n",
    "        output = x_ffnn_output * padding_mask.unsqueeze(-1)\n",
    "        return output\n",
    "\n",
    "\n",
    "class EmbeddingLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_items: int,\n",
    "        hidden_dim: int,\n",
    "        max_seq_len: int,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.item_emb_matrix = nn.Embedding(\n",
    "            num_embeddings=num_items + 1,\n",
    "            embedding_dim=hidden_dim,\n",
    "        )\n",
    "        self.positional_emb = nn.Embedding(\n",
    "            num_embeddings=max_seq_len,\n",
    "            embedding_dim=hidden_dim,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.item_emb_matrix(x)\n",
    "        x *= self.hidden_dim ** 0.5\n",
    "\n",
    "        batch_size = x.shape[0]\n",
    "        seq_len = x.shape[1]\n",
    "        device = x.device.type\n",
    "\n",
    "        positions = torch.tile(torch.arange(seq_len, device=device), dims=(batch_size, 1))\n",
    "\n",
    "        positional_embs = self.positional_emb(positions)\n",
    "        x += positional_embs\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class SASRec(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_items: int,\n",
    "        num_blocks: int,\n",
    "        hidden_dim: int,\n",
    "        max_seq_len: int,\n",
    "        dropout_p: float,\n",
    "        device: str,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        self.embedding_layer = EmbeddingLayer(\n",
    "            num_items=num_items,\n",
    "            hidden_dim=hidden_dim,\n",
    "            max_seq_len=max_seq_len,\n",
    "        )\n",
    "        self_attn_blocks = [\n",
    "            SelfAttnBlock(\n",
    "                max_seq_len=max_seq_len,\n",
    "                hidden_dim=hidden_dim,\n",
    "                dropout_p=dropout_p,\n",
    "                device=device,\n",
    "            )\n",
    "            for _ in range(num_blocks)\n",
    "        ]\n",
    "        self.self_attn_blocks = nn.Sequential(*self_attn_blocks)\n",
    "\n",
    "        self.dropout = nn.Dropout(p=dropout_p)\n",
    "        self.layer_norm = nn.LayerNorm(normalized_shape=hidden_dim)\n",
    "\n",
    "    def get_padding_mask(self, seqs: torch.Tensor) -> torch.Tensor:\n",
    "        is_padding = seqs == 0\n",
    "        padding_mask = ~is_padding\n",
    "\n",
    "        return padding_mask\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_seqs: torch.Tensor,\n",
    "        item_idxs: torch.Tensor = None,\n",
    "        positive_seqs: torch.Tensor = None,\n",
    "        negative_seqs: torch.Tensor = None,\n",
    "    ) -> torch.Tensor:\n",
    "        padding_mask = self.get_padding_mask(seqs=input_seqs)\n",
    "\n",
    "        input_embs = self.dropout(self.embedding_layer(input_seqs))\n",
    "        input_embs *= padding_mask.unsqueeze(-1)\n",
    "\n",
    "        # For loop because nn.Sequential can't handle multiple inputs.\n",
    "        attn_output = input_embs\n",
    "        for block in self.self_attn_blocks:\n",
    "            attn_output = block(x=attn_output, padding_mask=padding_mask)\n",
    "        attn_output = self.layer_norm(attn_output)\n",
    "\n",
    "        if item_idxs is not None:  # Inference.\n",
    "            item_embs = self.embedding_layer.item_emb_matrix(item_idxs)\n",
    "            logits = attn_output @ item_embs.transpose(2, 1)\n",
    "            logits = logits[:, -1, :]\n",
    "            outputs = (logits,)\n",
    "        elif (positive_seqs is not None) and (negative_seqs is not None):  # Training.\n",
    "            positive_embs = self.dropout(self.embedding_layer(positive_seqs))\n",
    "            negative_embs = self.dropout(self.embedding_layer(negative_seqs))\n",
    "\n",
    "            positive_logits = (attn_output * positive_embs).sum(dim=-1)\n",
    "            negative_logits = (attn_output * negative_embs).sum(dim=-1)\n",
    "\n",
    "            outputs = (positive_logits,)\n",
    "            outputs += (negative_logits,)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobre os dados de entrada\n",
    "\n",
    "Conforme feito originalmente, seguimos a estratégia de geramento de amostras\n",
    "negativas para as recomendações, isto é, para cada recomendação esperada, \n",
    "geramos aleatoriamente exemplos de recomendações negativas (\"errada\"), desse\n",
    "modo alcançando resultados melhores e expandindo o conjunto de dados.\n",
    "\n",
    "Além disso, devido a natureza do modelo, é imporante que as sequências tenham\n",
    "tamanho fixo, por conta disso é feito um processamento de _padding_ ou \n",
    "truncamento da amostra para que tenha esse tamanho. Isso também influenciou o\n",
    "nosso mapeamento anterior dos itens em identificadores numéricos, inciando a\n",
    "sequência a partir do 1, já que usaremos o 0 como identificador de padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T19:11:11.572685Z",
     "start_time": "2024-11-23T19:10:55.718929Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bb7db28d9664cfcb82e490af626a44a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Samples:   0%|          | 0/961416 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Barra de progresso para a execução paralela no joblib\n",
    "# Obtido em: https://stackoverflow.com/questions/24983493/tracking-progress-of-joblib-parallel-execution/58936697#58936697\n",
    "@contextlib.contextmanager\n",
    "def tqdm_joblib(tqdm_object):\n",
    "    \"\"\"Context manager to patch joblib to report into tqdm progress bar given as argument\"\"\"\n",
    "    class TqdmBatchCompletionCallback(joblib.parallel.BatchCompletionCallBack):\n",
    "        def __call__(self, *args, **kwargs):\n",
    "            tqdm_object.update(n=self.batch_size)\n",
    "            return super().__call__(*args, **kwargs)\n",
    "\n",
    "    old_batch_callback = joblib.parallel.BatchCompletionCallBack\n",
    "    joblib.parallel.BatchCompletionCallBack = TqdmBatchCompletionCallback\n",
    "    try:\n",
    "        yield tqdm_object\n",
    "    finally:\n",
    "        joblib.parallel.BatchCompletionCallBack = old_batch_callback\n",
    "        tqdm_object.close()\n",
    "    \n",
    "# Gera as amostras negativas para um item positivo\n",
    "def gen_samples(\n",
    "    positive_sample: int,\n",
    "    num_items: int,\n",
    "    num_samples: int,\n",
    "    seed: int,\n",
    ") -> tuple[int, list[int]]:\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "\n",
    "    negative_samples = []\n",
    "    while len(negative_samples) < num_samples:\n",
    "        negative_sample = np.random.randint(1, num_items + 1)\n",
    "        if negative_sample not in negative_samples and negative_sample != positive_sample:\n",
    "            negative_samples.append(negative_sample)\n",
    "\n",
    "    return positive_sample, negative_samples\n",
    "    \n",
    "\n",
    "# Pré-computação das amostras negativas para todas as amostras positivas, \n",
    "# computado concorrentemente com o joblib, já que o processo pode ser demorado.\n",
    "def get_positive2negatives(num_items: int, num_samples: int = 100) -> dict[int, list[int]]:\n",
    "    all_samples = np.arange(1, num_items + 1)\n",
    "\n",
    "    with warnings.catch_warnings(action=\"ignore\"):\n",
    "        with tqdm_joblib(tqdm(desc=\"Samples: \", total=len(all_samples))) as pbar:\n",
    "            res = joblib.Parallel(n_jobs=-1)(joblib.delayed(gen_samples)(n, num_items, num_samples, np.random.randint(2e9)) for n in all_samples)\n",
    "            positive2negatives = {k: v for k, v in res}\n",
    "\n",
    "    return positive2negatives\n",
    "\n",
    "\n",
    "positive2negatives = get_positive2negatives(num_items=max_iid)\n",
    "\n",
    "\n",
    "def pad_or_truncate_seq(\n",
    "    sequence: list[int],\n",
    "    max_seq_len: int,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Pads or truncates sequences depending on max_seq_len.\"\"\"\n",
    "    if isinstance(sequence, list) or isinstance(sequence, np.ndarray):\n",
    "        sequence = torch.tensor(sequence)\n",
    "\n",
    "    if len(sequence) > max_seq_len:\n",
    "        sequence = sequence[-max_seq_len:]\n",
    "    else:\n",
    "        diff = max_seq_len - len(sequence)\n",
    "        sequence = F.pad(sequence, pad=(diff, 0))\n",
    "\n",
    "    return sequence\n",
    "\n",
    "def collate_fn_train(\n",
    "    batch: list[list[int]], \n",
    "    max_seq_len: int = MAX_SEQUENCE_LENGTH\n",
    ") -> torch.Tensor:\n",
    "    seq_tensors = [pad_or_truncate_seq(seq, max_seq_len=max_seq_len) for seq in batch]\n",
    "    return torch.stack(seq_tensors)\n",
    "\n",
    "def collate_fn_eval(\n",
    "    batch: list[tuple[list[int], int]], \n",
    "    max_seq_len: int = MAX_SEQUENCE_LENGTH\n",
    ") -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    seq_tensors = [pad_or_truncate_seq(seq[0], max_seq_len=max_seq_len) for seq in batch]\n",
    "    input_seqs = torch.stack(seq_tensors)\n",
    "\n",
    "    item_idxs = [x[1] for x in batch]\n",
    "    item_idxs = torch.tensor(item_idxs, dtype=torch.long)\n",
    "\n",
    "    return input_seqs, item_idxs\n",
    "\n",
    "def build_train_dataloader(\n",
    "    data: list[list[int]],\n",
    "    batch_size: int = BATCH_SIZE,\n",
    "    max_seq_len: int = MAX_SEQUENCE_LENGTH,\n",
    ") -> DataLoader:\n",
    "    return DataLoader(\n",
    "        dataset=data,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=lambda batch: collate_fn_train(batch, max_seq_len=max_seq_len),\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "def build_eval_dataloader(\n",
    "    data: list[tuple[list[int], int]],\n",
    "    batch_size: int = BATCH_SIZE,\n",
    "    max_seq_len: int = MAX_SEQUENCE_LENGTH,\n",
    ") -> DataLoader:\n",
    "    global positive2negatives\n",
    "\n",
    "    input_seqs = [d[0] for d in data]\n",
    "    all_pred_item_idxs = []\n",
    "\n",
    "    for (_, positive_sample) in data:\n",
    "        negative_samples = positive2negatives[positive_sample]\n",
    "        all_pred_item_idxs.append([positive_sample] + negative_samples)\n",
    "    \n",
    "    # Join the inputs with the predictions (positive, ...negatives)\n",
    "    final_data = list(zip(input_seqs, all_pred_item_idxs))\n",
    "\n",
    "    return DataLoader(\n",
    "        dataset=final_data,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=lambda batch: collate_fn_eval(batch, max_seq_len=max_seq_len),\n",
    "        shuffle=False,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T19:11:12.014215Z",
     "start_time": "2024-11-23T19:11:11.575741Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = build_train_dataloader(data=train_data, batch_size=BATCH_SIZE, max_seq_len=MAX_SEQUENCE_LENGTH)\n",
    "test_loader = build_eval_dataloader(data=test_data, batch_size=BATCH_SIZE, max_seq_len=MAX_SEQUENCE_LENGTH)\n",
    "validation_loader = build_eval_dataloader(data=validation_data, batch_size=BATCH_SIZE, max_seq_len=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento\n",
    "\n",
    "Por fim chegamos ao treinamento do modelo. Usaremos duas métricas de avaliação,\n",
    "o NDCG@10 (Normalized Discounted Cumulative Gain nas 10 primeiras recomendações)\n",
    "e o HIT@10 (Hit Rate nas 10 primeiras recomendações). Para mais informações sobre,\n",
    "recomendamos a leitura na página do [EvidentlyAI](https://www.evidentlyai.com/ranking-metrics/evaluating-recommender-systems#hit-rate).\n",
    "Que explica melhor essas métricas.\n",
    "\n",
    "Para o treinamento, usamos um _batch size_ de 512 e um _scheduler_ para a taxa\n",
    "de aprendizado (OneCycleLR), com um warmup de 5% e um _learning rate_ máximo de \n",
    "0.04. Para o otimizador usamos o AdamW e como função de perda usamos o \n",
    "BCELossWithLogits (Binary Cross Entropy with Logits).\n",
    "\n",
    "Mais informações sobre os parâmetros de treinamento estão no começo do notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T19:11:12.623423Z",
     "start_time": "2024-11-23T19:11:12.602836Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: maybe pre-compute this?\n",
    "def get_negative_samples(\n",
    "    positive2negatives: dict[int, list[int]],\n",
    "    positive_seqs: torch.Tensor,\n",
    "    num_samples=1,\n",
    ") -> torch.Tensor:\n",
    "    negative_seqs = torch.zeros(size=positive_seqs.shape, dtype=torch.long)\n",
    "    for row_idx in range(positive_seqs.shape[0]):\n",
    "        for col_idx in range(positive_seqs[row_idx].shape[0]):\n",
    "            positive_sample = positive_seqs[row_idx][col_idx].item()\n",
    "\n",
    "            if positive_sample == 0:\n",
    "                continue\n",
    "\n",
    "            negative_samples = positive2negatives[positive_sample]\n",
    "            negative_sample = np.random.choice(\n",
    "                a=negative_samples, size=(num_samples,), replace=False\n",
    "            )\n",
    "            negative_seqs[row_idx][col_idx] = negative_sample[0]\n",
    "\n",
    "    return negative_seqs\n",
    "\n",
    "def compute_loss(\n",
    "    positive_idxs: torch.Tensor,\n",
    "    negative_idxs: torch.Tensor,\n",
    "    positive_logits: torch.Tensor,\n",
    "    negative_logits: torch.Tensor,\n",
    ") -> torch.Tensor:\n",
    "    global bce_criterion, PYTORCH_DEVICE\n",
    "\n",
    "    positive_logits = positive_logits[positive_idxs]\n",
    "    positive_labels = torch.ones(size=positive_logits.shape, device=PYTORCH_DEVICE)\n",
    "\n",
    "    negative_logits = negative_logits[negative_idxs]\n",
    "    negative_labels = torch.zeros(size=negative_logits.shape, device=PYTORCH_DEVICE)\n",
    "\n",
    "    positive_loss = bce_criterion(positive_logits, positive_labels)\n",
    "    negative_loss = bce_criterion(negative_logits, negative_labels)\n",
    "\n",
    "    return positive_loss + negative_loss\n",
    "\n",
    "def evaluate_model(\n",
    "    model: SASRec,\n",
    "    loader: DataLoader,\n",
    "    device: str = PYTORCH_DEVICE,\n",
    "    autocast: bool = False,\n",
    "    autocast_dtype: torch.dtype = torch.bfloat16,\n",
    ") -> tuple[float, float]:\n",
    "    global EVAL_K\n",
    "    ndcg = 0\n",
    "    hit = 0\n",
    "    total = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=\"Evaluating Validation: \", total=len(loader), leave=False):\n",
    "            input_seqs, item_idxs = batch\n",
    "            total += input_seqs.shape[0]\n",
    "\n",
    "            input_seqs = input_seqs.to(device)\n",
    "            item_idxs = item_idxs.to(device)\n",
    "\n",
    "            if autocast:\n",
    "                with torch.amp.autocast(device_type=device, dtype=autocast_dtype):\n",
    "                    outputs = model(input_seqs, item_idxs=item_idxs)\n",
    "            else:\n",
    "                outputs = model(input_seqs, item_idxs=item_idxs)\n",
    "\n",
    "            logits = -outputs[0]\n",
    "\n",
    "            # Metal shenanigans\n",
    "            if logits.device.type == 'mps':\n",
    "                logits = logits.detach().cpu()\n",
    "            \n",
    "            ranks = logits.argsort().argsort()\n",
    "            ranks = [r[0].item() for r in ranks]\n",
    "\n",
    "            for rank in ranks:\n",
    "                if rank < EVAL_K:\n",
    "                    ndcg += 1 / np.log2(rank + 2)\n",
    "                    hit += 1\n",
    "        \n",
    "    ndcg /= total\n",
    "    hit /= total\n",
    "\n",
    "    return ndcg, hit\n",
    "\n",
    "def train_model(\n",
    "    model: SASRec,\n",
    "    optimizer: optim.Optimizer,\n",
    "    scheduler: optim.lr_scheduler.LRScheduler | None,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    num_epochs: int,\n",
    "    device: str = PYTORCH_DEVICE,\n",
    "    autocast: bool = False,\n",
    "    autocast_dtype: torch.dtype = torch.bfloat16,\n",
    ") -> tuple[list[float], list[float], list[float], tuple[dict, dict, dict], tuple[dict, dict, dict]]:\n",
    "    global positive2negatives\n",
    "\n",
    "    best_ndcg = 0\n",
    "    best_hit = 0\n",
    "    best_ndcg_epoch = 0\n",
    "    best_hit_epoch = 0\n",
    "\n",
    "    losses = []\n",
    "    ndcgs = []\n",
    "    hits = []\n",
    "    lrs = []\n",
    "\n",
    "    best_ncdg_model_state = None\n",
    "    best_ncdg_optimizer_state = None\n",
    "    best_ncdg_scheduler_state = None\n",
    "\n",
    "    best_hit_model_state = None\n",
    "    best_hit_optimizer_state = None \n",
    "    best_hit_scheduler_state = None\n",
    "\n",
    "    # Plot the loss and other metrics\n",
    "\n",
    "    fig_loss_widget = go.FigureWidget(layout=go.Layout(title=\"Loss\"))\n",
    "    fig_ndcg_widget = go.FigureWidget(layout=go.Layout(title=\"NDCG@\" + str(EVAL_K)))\n",
    "    fig_hit_widget = go.FigureWidget(layout=go.Layout(title=\"HIT@\" + str(EVAL_K)))\n",
    "    fig_lr_widget = go.FigureWidget(layout=go.Layout(title=\"Learning Rate\"))\n",
    "\n",
    "\n",
    "    fig_loss_widget.add_scatter(x=np.arange(len(losses)) + 1, y=losses)\n",
    "    fig_ndcg_widget.add_scatter(x=np.arange(len(ndcgs)) + 1, y=ndcgs)\n",
    "    fig_hit_widget.add_scatter(x=np.arange(len(hits)) + 1, y=hits)\n",
    "    fig_lr_widget.add_scatter(x=np.arange(len(lrs)) + 1, y=lrs)\n",
    "\n",
    "    fig_loss_widget.update_xaxes(title_text='Epoch')\n",
    "    fig_ndcg_widget.update_xaxes(title_text='Epoch')\n",
    "    fig_hit_widget.update_xaxes(title_text='Epoch')\n",
    "    fig_lr_widget.update_xaxes(title_text='Epoch')\n",
    "    \n",
    "    fig_loss_widget.update_yaxes(title_text='Loss', type='log')\n",
    "    fig_ndcg_widget.update_yaxes(title_text='NDCG@' + str(EVAL_K))\n",
    "    fig_hit_widget.update_yaxes(title_text='Epoch@' + str(EVAL_K))\n",
    "    fig_lr_widget.update_yaxes(title_text='Learning Rate')\n",
    "\n",
    "    display(HBox([fig_loss_widget, fig_lr_widget]))\n",
    "    display(HBox([fig_ndcg_widget, fig_hit_widget]))\n",
    "\n",
    "    # Wait for widgets to load\n",
    "    time.sleep(1)\n",
    "\n",
    "    steps = 0\n",
    "    for epoch in tqdm(range(num_epochs), desc=\"Epoch: \"):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        lrs.append([pg['lr'] for pg in optimizer.param_groups][0])\n",
    "\n",
    "        for batch in tqdm(train_loader, desc=\"Training: \", total=len(train_loader), leave=False):\n",
    "            model.zero_grad()\n",
    "\n",
    "            positive_seqs = batch.clone()\n",
    "            positive_idxs = torch.where(positive_seqs != 0)\n",
    "\n",
    "            batch[:, -1] = 0\n",
    "            input_seqs = batch.roll(shifts=1)\n",
    "            negative_seqs = get_negative_samples(positive2negatives, positive_seqs)\n",
    "            negative_idxs = torch.where(negative_seqs != 0)\n",
    "\n",
    "            input_seqs = input_seqs.to(device)\n",
    "            positive_seqs = positive_seqs.to(device)\n",
    "            negative_seqs = negative_seqs.to(device)\n",
    "\n",
    "            if autocast:\n",
    "                with torch.amp.autocast(device_type=device, dtype=autocast_dtype):\n",
    "                    output = model(input_seqs, positive_seqs=positive_seqs, negative_seqs=negative_seqs)\n",
    "        \n",
    "                    positive_logits = output[0]\n",
    "                    negative_logits = output[1]\n",
    "        \n",
    "                    loss = compute_loss(positive_idxs, negative_idxs, positive_logits, negative_logits)\n",
    "            else:\n",
    "                output = model(input_seqs, positive_seqs=positive_seqs, negative_seqs=negative_seqs)\n",
    "    \n",
    "                positive_logits = output[0]\n",
    "                negative_logits = output[1]\n",
    "    \n",
    "                loss = compute_loss(positive_idxs, negative_idxs, positive_logits, negative_logits)\n",
    "                \n",
    "            loss.backward()\n",
    "            epoch_loss += loss.item()\n",
    "            optimizer.step()\n",
    "\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "            \n",
    "            steps += 1\n",
    "\n",
    "        ndcg, hit = evaluate_model(model, val_loader, device=device, autocast=autocast, autocast_dtype=autocast_dtype)\n",
    "\n",
    "        if ndcg > best_ndcg:\n",
    "            best_ndcg = ndcg\n",
    "            best_ndcg_epoch = epoch\n",
    "            best_ncdg_model_state = copy.deepcopy(model.state_dict())\n",
    "            best_ncdg_optimizer_state = copy.deepcopy(optimizer.state_dict())\n",
    "            if scheduler is not None:\n",
    "                best_ncdg_scheduler_state = copy.deepcopy(scheduler.state_dict())\n",
    "        \n",
    "        if hit > best_hit:\n",
    "            best_hit = hit\n",
    "            best_hit_epoch = epoch\n",
    "            best_hit_model_state = copy.deepcopy(model.state_dict())\n",
    "            best_hit_optimizer_state = copy.deepcopy(optimizer.state_dict())\n",
    "            if scheduler is not None:\n",
    "                best_hit_scheduler_state = copy.deepcopy(scheduler.state_dict())\n",
    "        \n",
    "        losses.append(epoch_loss)\n",
    "        ndcgs.append(ndcg)\n",
    "        hits.append(hit)\n",
    "\n",
    "        \n",
    "        fig_loss_widget.data[0].x = np.arange(len(losses)) + 1\n",
    "        fig_loss_widget.data[0].y = losses\n",
    "        fig_ndcg_widget.data[0].x = np.arange(len(ndcgs)) + 1\n",
    "        fig_ndcg_widget.data[0].y = ndcgs\n",
    "        fig_hit_widget.data[0].x = np.arange(len(hits)) + 1\n",
    "        fig_hit_widget.data[0].y = hits\n",
    "        fig_lr_widget.data[0].x = np.arange(len(lrs)) + 1\n",
    "        fig_lr_widget.data[0].y = lrs\n",
    "\n",
    "    print(f\"Best NDCG@{EVAL_K} Epoch: {best_ndcg_epoch + 1}, NDCG@{EVAL_K}: {best_ndcg:.4f}\")\n",
    "    print(f\"Best HIT@{EVAL_K} Epoch: {best_hit_epoch + 1}, HIT@{EVAL_K}: {best_hit:.4f}\")\n",
    "    \n",
    "    return losses, ndcgs, hits, \\\n",
    "        (best_ncdg_model_state, best_ncdg_optimizer_state, best_ncdg_scheduler_state), \\\n",
    "        (best_hit_model_state, best_hit_optimizer_state, best_hit_scheduler_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T19:54:39.148753Z",
     "start_time": "2024-11-23T19:11:12.627671Z"
    }
   },
   "outputs": [],
   "source": [
    "model = SASRec(num_items=max_iid, num_blocks=NUM_BLOCKS, hidden_dim=HIDDEN_DIM, \n",
    "               max_seq_len=MAX_SEQUENCE_LENGTH, dropout_p=DROPOUT_PROB, device=PYTORCH_DEVICE)\n",
    "\n",
    "model.to(PYTORCH_DEVICE)\n",
    "\n",
    "bce_criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, betas=(BETA_1, BETA_2), eps=EPS, weight_decay=WEIGHT_DECAY, amsgrad=AMSGRAD)\n",
    "\n",
    "scheduler = None\n",
    "if USE_SCHEDULER:\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer=optimizer,\n",
    "        max_lr=LEARNING_RATE,\n",
    "        total_steps=TOTAL_EPOCHS * len(train_loader),\n",
    "        pct_start=WARMUP_RATIO,\n",
    "        anneal_strategy=\"linear\",\n",
    "    )\n",
    "\n",
    "results = train_model(model, optimizer, scheduler, train_loader, validation_loader, TOTAL_EPOCHS, device=PYTORCH_DEVICE, autocast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T20:10:16.927522Z",
     "start_time": "2024-11-23T20:10:15.921893Z"
    }
   },
   "outputs": [],
   "source": [
    "losses, ndcgs, hits, \\\n",
    "    (best_ncdg_model_state, best_ncdg_optimizer_state, best_ncdg_scheduler_state), \\\n",
    "    (best_hit_model_state, best_hit_optimizer_state, best_hit_scheduler_state) = results\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "os.makedirs(f\"models/sasrec/{timestamp}/\", exist_ok=True)\n",
    "\n",
    "torch.save(best_ncdg_model_state, f\"models/sasrec/{timestamp}/best_ncdg_model_state.pt\")\n",
    "torch.save(best_hit_model_state, f\"models/sasrec/{timestamp}/best_hit_model_state.pt\")\n",
    "\n",
    "torch.save(best_ncdg_optimizer_state, f\"models/sasrec/{timestamp}/best_ncdg_optimizer_state.pt\")\n",
    "torch.save(best_hit_optimizer_state, f\"models/sasrec/{timestamp}/best_hit_optimizer_state.pt\")\n",
    "\n",
    "torch.save(best_ncdg_scheduler_state, f\"models/sasrec/{timestamp}/best_ncdg_scheduler_state.pt\")\n",
    "torch.save(best_hit_scheduler_state, f\"models/sasrec/{timestamp}/best_hit_scheduler_state.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados\n",
    "\n",
    "Após 3 horas e 50 minutos de treinamento (em 1x RTX 3080TI) foi realizado o \n",
    "treino de 500 epochs com a amostra de 100k sessões. Analisando os gráficos\n",
    "de treinamento, conseguimos ver que o modelo não convergiu completamente, tendo\n",
    "ainda potencial para melhora caso fosse treinado por mais tempo.\n",
    "\n",
    "Os resultados obtidos foram:\n",
    "\n",
    "| Métrica | Valor |\n",
    "| --- | --- |\n",
    "| NDCG@10 Validação | 0.681 |\n",
    "| HIT@10 Validação | 0.777 |\n",
    "| NDCG@10 Teste | 0.653 |\n",
    "| HIT@10 Teste | 0.749 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500
         ],
         "y": [
          9232.840789794922,
          2463.1257821321487,
          272.3911460638046,
          271.2881704568863,
          270.33125603199005,
          267.3339549303055,
          260.0907173156738,
          248.56231939792633,
          233.2105084657669,
          216.14627051353455,
          197.8322872519493,
          182.568814098835,
          170.0958013534546,
          161.10193181037903,
          154.0143839120865,
          147.7366252541542,
          141.46695172786713,
          135.55482357740402,
          129.10189300775528,
          122.4980880022049,
          116.4213250875473,
          111.11758011579514,
          106.77564507722855,
          104.71465080976486,
          118.79281231760979,
          108.68245708942413,
          102.4701138138771,
          100.77966079115868,
          96.91919803619385,
          95.43401703238487,
          108.27923080325127,
          99.69889497756958,
          95.04354798793793,
          117.4552675485611,
          119.02101719379425,
          98.51993790268898,
          94.25980332493782,
          93.96381986141205,
          92.12346053123474,
          106.51038008928299,
          102.52826637029648,
          90.46451011300087,
          88.72067606449127,
          87.3221962749958,
          87.18340903520584,
          87.7001501917839,
          87.84166613221169,
          88.69314232468605,
          85.94199880957603,
          91.33636951446533,
          92.11989200115204,
          84.82147487998009,
          85.24701136350632,
          83.36550629138947,
          82.1857839524746,
          82.90963444113731,
          98.90636283159256,
          103.45309168100357,
          83.86510401964188,
          81.2973904311657,
          81.78355592489243,
          81.23374140262604,
          80.17630738019943,
          79.84499469399452,
          79.19762232899666,
          81.04481065273285,
          80.21169397234917,
          78.30049639940262,
          78.72718638181686,
          78.29407957196236,
          82.72566866874695,
          78.35118049383163,
          78.6351607143879,
          78.86504390835762,
          92.34015890955925,
          80.19666740298271,
          77.09906134009361,
          75.42394834756851,
          75.29713013768196,
          75.16256123781204,
          75.052521109581,
          75.48520654439926,
          75.3612191081047,
          77.3798179924488,
          75.93695810437202,
          74.90270039439201,
          76.38781815767288,
          74.88930648565292,
          75.08839902281761,
          74.84009170532227,
          74.16821703314781,
          73.35469427704811,
          75.33888640999794,
          73.77757650613785,
          73.11992540955544,
          74.064224421978,
          72.88470268249512,
          72.91975939273834,
          72.70526766777039,
          72.48468551039696,
          72.91344955563545,
          73.23310574889183,
          72.39100703597069,
          71.78321948647499,
          72.83228906989098,
          71.49290582537651,
          71.68875622749329,
          71.16065099835396,
          71.44943615794182,
          70.46286934614182,
          70.86491030454636,
          70.88285112380981,
          70.94191345572472,
          70.41581463813782,
          70.69404035806656,
          70.55770787596703,
          70.2335816025734,
          70.0606620311737,
          69.0385111272335,
          69.410545617342,
          70.189736276865,
          69.62552484869957,
          69.76368397474289,
          69.82422745227814,
          69.23047378659248,
          68.86766597628593,
          68.64530000090599,
          68.27844309806824,
          68.47811695933342,
          68.53500479459763,
          68.09750536084175,
          67.64026874303818,
          67.79037109017372,
          68.43968349695206,
          68.26831948757172,
          68.84371542930603,
          67.98903658986092,
          68.00321561098099,
          67.48251193761826,
          67.51174241304398,
          67.53175470232964,
          66.69302263855934,
          66.96907672286034,
          67.39345061779022,
          67.32960966229439,
          66.95203194022179,
          67.05838611721992,
          66.29059660434723,
          66.31593677401543,
          66.54087236523628,
          66.16177394986153,
          66.8374034166336,
          65.68414679169655,
          65.68368887901306,
          66.1414304971695,
          66.34731784462929,
          66.77064788341522,
          66.09193602204323,
          65.56148383021355,
          65.33720541000366,
          65.49061995744705,
          65.70400983095169,
          64.83321225643158,
          65.21154901385307,
          64.67096492648125,
          64.63082033395767,
          63.860335528850555,
          64.30712363123894,
          64.06280276179314,
          64.10439419746399,
          63.412146389484406,
          63.620463371276855,
          63.634810090065,
          63.47851365804672,
          63.378818929195404,
          63.49372750520706,
          63.19010627269745,
          63.55824854969978,
          63.1871300637722,
          63.062293976545334,
          63.19864830374718,
          62.65378698706627,
          62.34799760580063,
          62.907701671123505,
          62.75927248597145,
          62.73368275165558,
          62.63018998503685,
          62.43287566304207,
          61.942384868860245,
          62.17622286081314,
          61.97279950976372,
          61.505442917346954,
          61.75631886720657,
          62.206749111413956,
          61.81942039728165,
          61.522922962903976,
          61.67244333028793,
          61.359857112169266,
          61.11043560504913,
          60.98450481891632,
          60.75296080112457,
          60.63829219341278,
          60.07450383901596,
          59.81451568007469,
          60.308794260025024,
          59.932806462049484,
          60.064347982406616,
          60.545992493629456,
          59.59720227122307,
          59.64187395572662,
          59.517062336206436,
          59.280798345804214,
          59.5030642747879,
          59.41873416304588,
          59.16935935616493,
          58.77550110220909,
          58.831102669239044,
          59.406186640262604,
          59.26086413860321,
          59.04258134961128,
          58.727862775325775,
          58.56551972031593,
          58.50279891490936,
          58.269323378801346,
          58.15633878111839,
          58.18135327100754,
          57.72810700535774,
          57.51501312851906,
          57.280956864356995,
          57.35133248567581,
          57.50631681084633,
          57.24288699030876,
          56.97115686535835,
          57.079706996679306,
          57.025527626276016,
          57.08140376210213,
          56.95184314250946,
          56.81481742858887,
          56.89281991124153,
          56.87185716629028,
          56.53928753733635,
          56.46672487258911,
          56.15270334482193,
          55.81854709982872,
          56.151344656944275,
          56.06191071867943,
          55.528496474027634,
          55.58808249235153,
          55.4361757338047,
          55.336336851119995,
          55.26549741625786,
          55.371422067284584,
          55.21504580974579,
          55.211306512355804,
          54.58881539106369,
          54.450353771448135,
          54.94273194670677,
          54.819247364997864,
          54.64095824956894,
          54.26744510233402,
          54.336866691708565,
          54.06984508037567,
          54.46467670798302,
          53.73735769093037,
          53.71130535006523,
          53.72501650452614,
          53.636915773153305,
          53.49698603153229,
          53.31623995304108,
          53.25782898068428,
          53.13187626004219,
          53.215279802680016,
          53.255675941705704,
          52.9742815643549,
          52.96244287490845,
          52.17299772799015,
          52.43562960624695,
          52.37447389960289,
          52.281421169638634,
          52.20298174023628,
          51.85195754468441,
          52.19460202753544,
          52.00501683354378,
          52.43033695220947,
          51.66899633407593,
          52.0581368803978,
          51.82042221724987,
          51.44123262166977,
          51.4044029712677,
          51.514871180057526,
          51.10092484951019,
          50.7911221832037,
          50.713803216814995,
          50.56706985831261,
          50.66509671509266,
          50.3456808924675,
          50.247227028012276,
          50.37628619372845,
          49.972716838121414,
          49.812035009264946,
          49.93936409056187,
          49.72071301937103,
          49.87097026407719,
          49.80141080915928,
          49.44453038275242,
          49.30367761850357,
          49.379512414336205,
          49.181059673428535,
          49.03076808154583,
          48.87609124183655,
          48.944344356656075,
          48.674767792224884,
          48.25850073993206,
          48.510471656918526,
          48.26756428182125,
          48.027277290821075,
          48.078637689352036,
          47.774475663900375,
          47.946337297558784,
          47.70002166926861,
          47.61464287340641,
          47.529643192887306,
          47.38470444083214,
          47.26959675550461,
          47.20807133615017,
          46.847920432686806,
          46.82196716964245,
          46.687906205654144,
          46.890626326203346,
          46.58336454629898,
          46.29644985496998,
          46.080515429377556,
          45.9748837351799,
          46.02026915550232,
          45.69799202680588,
          45.513985350728035,
          45.76652176678181,
          45.589158207178116,
          45.14713513851166,
          45.02791476249695,
          45.02559672296047,
          45.00990816950798,
          44.810396283864975,
          44.82127431035042,
          44.88092885911465,
          44.80144211649895,
          44.90261486172676,
          44.25316408276558,
          44.29187270998955,
          44.27873358130455,
          44.1216956526041,
          44.14300638437271,
          44.00381362438202,
          43.71979530155659,
          43.72137603163719,
          43.45574992895126,
          43.62628224492073,
          43.502337113022804,
          43.35071602463722,
          43.08835877478123,
          43.023212894797325,
          42.79867732524872,
          42.769458055496216,
          42.48897850513458,
          42.31125956773758,
          42.32471443712711,
          41.864858746528625,
          41.92789928615093,
          42.07399995625019,
          41.74807517230511,
          41.76846091449261,
          41.538134068250656,
          41.42038334906101,
          41.304897502064705,
          41.03186218440533,
          40.95795738697052,
          40.93548399209976,
          40.94973058998585,
          40.7692681401968,
          40.8520869910717,
          40.67127227783203,
          40.21968023478985,
          39.97361469268799,
          40.11591336131096,
          39.84365251660347,
          39.835913851857185,
          39.67229001224041,
          39.341509744524956,
          39.48272807896137,
          39.288307532668114,
          38.95213781297207,
          38.634980618953705,
          38.75941298902035,
          38.64400890469551,
          38.20967210829258,
          38.47320231795311,
          38.026043474674225,
          38.357196509838104,
          37.92431451380253,
          37.7890991717577,
          37.682138323783875,
          37.48303684592247,
          37.24115562438965,
          37.227335050702095,
          37.09239910542965,
          36.828754633665085,
          36.819380179047585,
          36.567932188510895,
          36.68239529430866,
          36.327904775738716,
          36.253756538033485,
          36.07155402004719,
          35.806064397096634,
          35.81534692645073,
          35.933598428964615,
          35.451937928795815,
          35.413106366992,
          35.13164238631725,
          34.91371123492718,
          34.93109115958214,
          34.87661190330982,
          34.76389788091183,
          34.710719019174576,
          34.15780505537987,
          34.143790528178215,
          34.26926673948765,
          33.852456137537956,
          34.021030113101006,
          33.723621025681496,
          33.4710613489151,
          33.38139522075653,
          33.197733879089355,
          33.08004929125309,
          32.801983654499054,
          32.66088929772377,
          32.571344301104546,
          32.64761699736118,
          32.31721289455891,
          32.432703986763954,
          31.912838518619537,
          31.99773146212101,
          31.730716690421104,
          31.621605575084686,
          31.56767500936985,
          31.26924206316471,
          31.314034327864647,
          31.03217102587223,
          30.900785759091377,
          30.741498365998268,
          30.493266105651855,
          30.263645216822624,
          30.351319640874863,
          30.28022500872612,
          29.95916099846363,
          30.02230893075466,
          29.642921715974808,
          29.74103280901909,
          29.516876623034477,
          29.39036823809147,
          29.30387008190155,
          29.128295332193375,
          28.995357245206833,
          28.834258884191513,
          28.53424384444952,
          28.564624071121216,
          28.52682761847973,
          28.30631633102894,
          28.030887007713318,
          27.760152384638786,
          27.79434099793434,
          27.579020850360394,
          27.562367528676987,
          27.62051786482334,
          27.18203718215227,
          27.078076004981995,
          27.041025139391422,
          26.933880679309368,
          26.830209501087666,
          26.794542387127876,
          26.501251600682735,
          26.57637247443199,
          26.227977596223354,
          26.265278831124306,
          26.21350510418415,
          26.125718735158443,
          25.85929836332798,
          25.76602441072464,
          25.663266882300377,
          25.524590030312538,
          25.422070041298866,
          25.444398902356625,
          25.46621622145176,
          25.338996097445488,
          25.219335302710533,
          25.052648313343525,
          25.067549027502537,
          25.02296682447195,
          25.095302261412144,
          24.96594448387623,
          25.032948039472103
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Loss"
        },
        "xaxis": {
         "title": {
          "text": "Epoch"
         },
         "type": "log"
        },
        "yaxis": {
         "title": {
          "text": "Loss"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500
         ],
         "y": [
          0.0820297753224078,
          0.0423597719174941,
          0.0834958689655434,
          0.08572474887815906,
          0.08989713399119208,
          0.09780958239376669,
          0.11461870834842589,
          0.1360298506004349,
          0.16655991131320866,
          0.20368117407675798,
          0.2545289288983332,
          0.3022045245219482,
          0.3374906438348886,
          0.3686271447975748,
          0.38819461940287936,
          0.4058517890772184,
          0.4163186211611249,
          0.42487690145859675,
          0.4376028844616605,
          0.45392979579276077,
          0.466840588682139,
          0.4779882229200673,
          0.48462718713202146,
          0.48250924024078856,
          0.452628338819623,
          0.4887481636182042,
          0.49221265486607063,
          0.5112654848265303,
          0.5168789088614423,
          0.5198199248080715,
          0.4875716556862262,
          0.5178923629396347,
          0.5196122035198527,
          0.4784153821032703,
          0.5036084006899906,
          0.5159753614058109,
          0.5153715339500146,
          0.5279721248596091,
          0.5274397376646711,
          0.487835110214286,
          0.5243444477577366,
          0.5313914123470957,
          0.5335064735115363,
          0.534790175137244,
          0.536125821544803,
          0.5376936838265172,
          0.5428598568663008,
          0.5370159835809439,
          0.5408907741209309,
          0.5396037915726556,
          0.5430059575965595,
          0.547409381447455,
          0.5461251471283751,
          0.5496368187620213,
          0.5434465513933695,
          0.545210580163749,
          0.46330431553595147,
          0.5427157446125035,
          0.5477231446711044,
          0.548521593911488,
          0.548479167775749,
          0.5507439316254764,
          0.5555521114635834,
          0.5548761713010945,
          0.5596099550957192,
          0.553044639451084,
          0.5600718143875586,
          0.5587907040689435,
          0.5596699947104775,
          0.565772383518563,
          0.5621544647952066,
          0.562954766468517,
          0.5619361431058174,
          0.5545573191556777,
          0.5512362971674759,
          0.5678459612203792,
          0.5736846589686603,
          0.5736781160699848,
          0.5757795862562416,
          0.5751373056837885,
          0.5729786636005804,
          0.5727817882552874,
          0.571072890402681,
          0.5789411360391327,
          0.5771689944937723,
          0.5706288461267839,
          0.5763143577441275,
          0.5756980084957121,
          0.5837296857971168,
          0.5800257389283213,
          0.5804321868447522,
          0.5853217554208267,
          0.5737147993536094,
          0.5841402555860123,
          0.5895992492669917,
          0.5848624943261455,
          0.5803512318677922,
          0.5880283392860042,
          0.5880904377740839,
          0.5930658625247353,
          0.5863551661686792,
          0.5939245801151127,
          0.5925606088537797,
          0.5949880902766435,
          0.596380933001185,
          0.5940563013326144,
          0.5944252062803627,
          0.5965579619506248,
          0.5967533358550371,
          0.5943332480892852,
          0.5967395699042688,
          0.6000347275873947,
          0.596524174424698,
          0.6027931410727674,
          0.596980955546838,
          0.5995592555482258,
          0.5974830226840959,
          0.5992135917239283,
          0.6026777523623444,
          0.6034851991767147,
          0.6006539520143798,
          0.6008635271540907,
          0.5990769751366917,
          0.6033025408530333,
          0.6041885198414036,
          0.6068142824637379,
          0.6049500905054975,
          0.6037929789137049,
          0.6003205726659706,
          0.6043211217164881,
          0.6057711944271941,
          0.6096220814676285,
          0.6049030536371518,
          0.6040327430249883,
          0.6081391826347327,
          0.6071561818959709,
          0.6095709531004723,
          0.6069746633308303,
          0.6024395117367118,
          0.6075835870690506,
          0.6032349501276637,
          0.6077934186918752,
          0.609154087877965,
          0.6089181366876382,
          0.6074164570322492,
          0.6087471754513184,
          0.613099342148885,
          0.6125444343877309,
          0.6125598587084375,
          0.6119053918041385,
          0.6104246661604972,
          0.6117505068835287,
          0.6138901873810104,
          0.6119349359855217,
          0.6139291269309055,
          0.6130912960036614,
          0.6147425358430324,
          0.6149369155944728,
          0.6111853402531021,
          0.6138597574874438,
          0.6140111821523876,
          0.614670980583953,
          0.6179379896313535,
          0.614975173513159,
          0.6161810783934999,
          0.6158771417495085,
          0.6170521579879443,
          0.6157361140654484,
          0.6119611259677238,
          0.6172502703545427,
          0.6179532969490568,
          0.6183811232833072,
          0.6169126850362685,
          0.6196227785740496,
          0.6184039262429786,
          0.6170825708109564,
          0.6183371585840606,
          0.6166167854469368,
          0.6184158461723965,
          0.6174281832468873,
          0.619409955799317,
          0.619032206683389,
          0.6223746836948035,
          0.6160279274565614,
          0.6193641498748084,
          0.6180480770198242,
          0.6202788498011789,
          0.6194035005365972,
          0.622017140265161,
          0.6227948571620829,
          0.6217763034369076,
          0.6193013868209084,
          0.6211407525802708,
          0.6199300430545064,
          0.6214262892661448,
          0.6219070980041782,
          0.6204748820032967,
          0.6236499128349343,
          0.6242187771350948,
          0.6249156116161929,
          0.6249417510895534,
          0.62347524227017,
          0.6251606646039715,
          0.624895000273128,
          0.6252096214572093,
          0.6265551584410535,
          0.6257083054598328,
          0.6245781902701872,
          0.623087579217958,
          0.6230675191542933,
          0.6258358537549652,
          0.6264902196943509,
          0.6258067796785457,
          0.627820719618017,
          0.6287154270624377,
          0.6252187563091993,
          0.6266841847190133,
          0.6296118650124194,
          0.6260958336049465,
          0.6278412223026885,
          0.6281919818973767,
          0.6243311867495664,
          0.6287580081718148,
          0.630156273995133,
          0.6293633670997166,
          0.6272298735780893,
          0.6290675556863096,
          0.6288127828257551,
          0.631120069377296,
          0.628521512929012,
          0.6309975509728717,
          0.6292759336294613,
          0.6286454113045512,
          0.6273281421584619,
          0.632104198457457,
          0.6286374509115998,
          0.6304345588270336,
          0.6299742457484167,
          0.630572087250967,
          0.6320570900936867,
          0.6326856850734469,
          0.6311421183747237,
          0.6296230651759003,
          0.6317784355088305,
          0.6329373826381357,
          0.6320808146068028,
          0.6339008048814571,
          0.6331808940830205,
          0.6330141913994161,
          0.6326904441413518,
          0.6321005037423452,
          0.6333061220542742,
          0.6331907773360401,
          0.6347851171139196,
          0.6354845198602889,
          0.6328540067267503,
          0.6352821726362515,
          0.636048010029132,
          0.636597540091346,
          0.6356282789599202,
          0.6349560675702038,
          0.6378612389140388,
          0.6370153338258382,
          0.6373078609360803,
          0.6358704660258068,
          0.637484050663202,
          0.6377079035629192,
          0.6376712087396087,
          0.6344463876239309,
          0.6377311550632957,
          0.6373084636154698,
          0.6382705076314927,
          0.6397159317480197,
          0.6389046563928705,
          0.6394321272729404,
          0.639356528752728,
          0.6399028812569433,
          0.6393794086430424,
          0.6399902330529552,
          0.6377273524840253,
          0.6396224300567738,
          0.6415762956800015,
          0.6395821019969149,
          0.6412801176387857,
          0.6397316135737063,
          0.641337997794931,
          0.6411246927905008,
          0.6409504114118892,
          0.640571345053374,
          0.6392203188321403,
          0.6407554162720546,
          0.6405300232854206,
          0.6417997981096502,
          0.6420596067805137,
          0.6398677144984048,
          0.6429864940359977,
          0.6430632082116929,
          0.6421021861866508,
          0.6419998265560827,
          0.642920979781892,
          0.6418318679995272,
          0.6430323775916981,
          0.643642700755318,
          0.6432721156178054,
          0.6427471993829204,
          0.6441388468669117,
          0.6441613292574986,
          0.6448635337093475,
          0.6448974833866129,
          0.6440251056427934,
          0.6461634830383689,
          0.6475109811820423,
          0.6452518548347771,
          0.6465090060382778,
          0.6467878593447873,
          0.6470507278247882,
          0.6471669140466837,
          0.6474376943863002,
          0.6460811591188128,
          0.6476937565787773,
          0.6470951298675529,
          0.6459949901223243,
          0.6483953105486525,
          0.6478677633133723,
          0.6486782997436887,
          0.6476824882263492,
          0.6469119546100479,
          0.6483442017015619,
          0.6477362786019789,
          0.6479074375404149,
          0.6492890475935785,
          0.649806846691118,
          0.6509292967016459,
          0.6506031835486191,
          0.6508331154588745,
          0.6506178661038142,
          0.651953757444939,
          0.652289780049229,
          0.6538167353704046,
          0.6533600279131879,
          0.6525703184235292,
          0.6533057582039309,
          0.652106280033537,
          0.650668974950753,
          0.6516633992377698,
          0.6530627098633663,
          0.6506321554017619,
          0.6521227918647999,
          0.6537642889291349,
          0.6529643493382281,
          0.6527900017142728,
          0.653812837176145,
          0.6533257408210447,
          0.6539195135941921,
          0.6526673679788627,
          0.6537927468580849,
          0.6531921933878618,
          0.654564405784223,
          0.6549364115079985,
          0.6544079432796622,
          0.6545239508636338,
          0.6536218351387939,
          0.6546184659791427,
          0.6544396913473538,
          0.6563577799594607,
          0.6545228618458913,
          0.6554955462822951,
          0.6558166217069739,
          0.6557673317211431,
          0.6563485086399572,
          0.657269063325403,
          0.6576751924772319,
          0.6577765092313107,
          0.656633219830423,
          0.6570068533194884,
          0.6578010216873708,
          0.6579673730562495,
          0.6576359284715659,
          0.6572950161202132,
          0.657619443633231,
          0.6578176281944922,
          0.6588115004469275,
          0.658746553706144,
          0.6594934526152945,
          0.6588445582273518,
          0.6607853718279608,
          0.6593212594181079,
          0.6602789917593107,
          0.6600418533626474,
          0.6608386648059638,
          0.6613759758312796,
          0.6613345642937354,
          0.6621487437257474,
          0.660782456142343,
          0.6624934787867622,
          0.6618062397884814,
          0.6626057692738097,
          0.6629548700245685,
          0.6631650079540238,
          0.6628370495961879,
          0.6639300334137065,
          0.6630833609573069,
          0.6635254998555326,
          0.6636091172126318,
          0.6636469990772649,
          0.6642229145337445,
          0.6645576618072051,
          0.6654185968744694,
          0.6656609219021079,
          0.6653000209862246,
          0.6654227281223254,
          0.6658563223739556,
          0.6659204074138825,
          0.665813390889458,
          0.6662907360214044,
          0.666460141808997,
          0.6655548136058362,
          0.665633628171777,
          0.6665849319229806,
          0.6668816154407894,
          0.6669343370203739,
          0.6668523465180061,
          0.6684907727245715,
          0.6678284958005297,
          0.6685893025954011,
          0.6677999893041235,
          0.668855780033112,
          0.668874837567117,
          0.6695036093686053,
          0.6695183970208354,
          0.6694755526590469,
          0.6701825877981635,
          0.6692788342651484,
          0.670388813091174,
          0.6698596528842437,
          0.6705548598795954,
          0.6713400013986095,
          0.6714407634299269,
          0.67139489317694,
          0.6720354763651454,
          0.6725903754246829,
          0.6721063471338754,
          0.6723514416093636,
          0.6726960693920596,
          0.672844088047644,
          0.6728537277714977,
          0.6726407862120654,
          0.6729162919953594,
          0.6731883208625926,
          0.6732168899160564,
          0.6733784638907991,
          0.6740484994846219,
          0.6739404873675023,
          0.6742569087345675,
          0.6742626370305052,
          0.6745394803119149,
          0.6753675169747506,
          0.6752389657468262,
          0.6751549083445356,
          0.6759146300942387,
          0.676483611400043,
          0.6761298139458519,
          0.6772127885954463,
          0.6762666789104645,
          0.676965555835113,
          0.6771542621257007,
          0.6775325060703951,
          0.6781325665899234,
          0.6775152534575315,
          0.6775152184920464,
          0.6782095139652856,
          0.6786264653366767,
          0.6786730337568765,
          0.678427617207793,
          0.6789003674458214,
          0.6791396806352997,
          0.6796131440685842,
          0.6792959109404519,
          0.6792393497931067,
          0.6796598135603799,
          0.6798263018042578,
          0.6799030974416675,
          0.6799912894685631,
          0.6799328890173499,
          0.680628549095297,
          0.6805200340534051,
          0.6807433402408893,
          0.6809229208583486,
          0.6808687115232,
          0.6809003359576943,
          0.6807378956615013,
          0.6811423986615426,
          0.6810921254327608,
          0.6812618112846082,
          0.6812550541954494,
          0.6813239221646972,
          0.6815600858518546,
          0.6815619997971738,
          0.6814758035282792,
          0.6814647069961014
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "NDCG@10"
        },
        "xaxis": {
         "title": {
          "text": "Epoch"
         }
        },
        "yaxis": {
         "title": {
          "text": "NDCG@10"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500
         ],
         "y": [
          0.13657456364066134,
          0.09382814346673965,
          0.14023214441223672,
          0.14967467436334458,
          0.16246376631293466,
          0.18836540973613167,
          0.2227640860402334,
          0.2661076622584939,
          0.31982682474714175,
          0.3822420721314739,
          0.45273136686530396,
          0.5135044351277043,
          0.5529167340540675,
          0.5806720493648997,
          0.5981015414090395,
          0.6143242806135778,
          0.6253592266829225,
          0.6368669212873689,
          0.6491708239509337,
          0.6629551759744218,
          0.670208133762954,
          0.6750475858722832,
          0.6780458068449011,
          0.6703823042758861,
          0.6623331384282355,
          0.6760304051952576,
          0.6838805190281285,
          0.6828106144486881,
          0.6856471056592975,
          0.6891305159179408,
          0.6747490078501138,
          0.6867294509896618,
          0.6866174842313482,
          0.6360085094736319,
          0.6824000696682052,
          0.6895037384456526,
          0.6954130951344223,
          0.6875629813015514,
          0.6862567024545602,
          0.6409226060885035,
          0.6816660653637053,
          0.6868662992498227,
          0.6815416578544681,
          0.687127555019221,
          0.6846145233326284,
          0.6859332429305433,
          0.6973289707766761,
          0.6961470994389222,
          0.7012104850648785,
          0.6895535014493475,
          0.696109777186151,
          0.6976648710516167,
          0.6929249449496772,
          0.7022306266406241,
          0.7040096540227168,
          0.6940943755365074,
          0.6686405991465645,
          0.6874758960450853,
          0.6917181921100758,
          0.7016707928490564,
          0.7035991092422339,
          0.6901382167427625,
          0.6978390415645488,
          0.7037359575023948,
          0.7000410544780483,
          0.7067590599768602,
          0.7053159328697081,
          0.7046938953235218,
          0.7079906943183091,
          0.7007750587825481,
          0.701596148343514,
          0.6966447294758712,
          0.7097697217004019,
          0.7112999340640201,
          0.6846020825817046,
          0.7010238738010226,
          0.7092472101616053,
          0.7108893892835372,
          0.7117851233500454,
          0.7065351264602331,
          0.708674935619114,
          0.7097946032022493,
          0.7106654557669101,
          0.714932633333748,
          0.7074681827795126,
          0.6973911745312947,
          0.7113994600714099,
          0.7164130826936714,
          0.7197969669449248,
          0.7162264714298155,
          0.7102673517373509,
          0.7181672285739167,
          0.7193490999116706,
          0.714074221520011,
          0.720244833978179,
          0.7148206665754345,
          0.7200209004615519,
          0.7215386720742464,
          0.7208793122752889,
          0.7248727933218049,
          0.7153307373633072,
          0.7286423408516938,
          0.7233301402072629,
          0.7229444769286274,
          0.7266144984511265,
          0.7267140244585163,
          0.7221731503713564,
          0.725320660355059,
          0.7270872469862281,
          0.7297993306876003,
          0.7285054925915329,
          0.7310060835272018,
          0.7257934088901606,
          0.7289160373720158,
          0.7283935258332193,
          0.7297371269329817,
          0.7303342829773205,
          0.7302347569699307,
          0.730222316219007,
          0.7319515805974048,
          0.7285801370970751,
          0.7302720792227019,
          0.7303716052300917,
          0.7332703001953198,
          0.734078949005362,
          0.73380525248504,
          0.7347258680533957,
          0.7347756310570907,
          0.7289160373720158,
          0.7322003956158794,
          0.7368781179632002,
          0.7351861758375735,
          0.7353727871014294,
          0.7338550154887349,
          0.7373633072492256,
          0.7369652032196663,
          0.7396026424154962,
          0.734302882521989,
          0.7338674562396587,
          0.7369776439705901,
          0.7359077393911496,
          0.7401873577089113,
          0.7392169791368607,
          0.7369527624687426,
          0.7373259849964544,
          0.7367910327067342,
          0.7405356987347756,
          0.7426879486445802,
          0.7396150831664199,
          0.7414438735522076,
          0.7406725469949366,
          0.741107973277267,
          0.7411204140281907,
          0.7414563143031313,
          0.7410955325263433,
          0.7424764558788769,
          0.7418419775817668,
          0.7422774038640972,
          0.738570060088827,
          0.7429740859158259,
          0.7389681641183862,
          0.7437702939749443,
          0.7444047722720544,
          0.744417213022978,
          0.7444296537739018,
          0.7447406725469949,
          0.7443425685174357,
          0.7428870006593598,
          0.7396524054191911,
          0.7460593921449099,
          0.7447655540488424,
          0.743919582986029,
          0.7428123561538175,
          0.7443923315211306,
          0.7431358156778343,
          0.7396772869210385,
          0.7424764558788769,
          0.7447033502942237,
          0.7453627100931812,
          0.7411328547791145,
          0.746233562657842,
          0.7485351015787313,
          0.7481743198019433,
          0.7446287057886815,
          0.7459598661375201,
          0.7435463604583172,
          0.7485848645824262,
          0.7447779947997661,
          0.7458478993792065,
          0.7477015712668417,
          0.7474527562483672,
          0.7466192259364776,
          0.7429740859158259,
          0.7473532302409773,
          0.7481369975491721,
          0.7474651969992909,
          0.7440688719971138,
          0.7492939873850786,
          0.7505380624774511,
          0.7479379455343924,
          0.7487092720916635,
          0.748000149289011,
          0.746731192694791,
          0.7492442243813836,
          0.7501399584478919,
          0.7506749107376122,
          0.7481369975491721,
          0.7482240828056381,
          0.7479006232816213,
          0.7463952924198505,
          0.74923178363046,
          0.750998370261629,
          0.7496298876600191,
          0.748908324106443,
          0.7507122329903833,
          0.7480872345454772,
          0.7474776377502146,
          0.7497916174220276,
          0.7483111680621042,
          0.7483858125676466,
          0.7519687488336796,
          0.7474900785011384,
          0.7511601000236374,
          0.7516079670568916,
          0.7499284656821886,
          0.7531381794205099,
          0.7524788196215524,
          0.7526156678817133,
          0.7532501461788234,
          0.7497045321655615,
          0.7508490812505443,
          0.7526281086326371,
          0.7497791766711038,
          0.7504509772209851,
          0.7524166158669338,
          0.7515582040531966,
          0.7520807155919932,
          0.7518816635772135,
          0.7537850984685436,
          0.7523792936141626,
          0.752541023376171,
          0.7534118759408318,
          0.7508490812505443,
          0.7543573730110349,
          0.7536233687065351,
          0.7505007402246799,
          0.7549545290553737,
          0.7504260957191377,
          0.7521553600975355,
          0.7530635349149675,
          0.7520931563429168,
          0.7519189858299847,
          0.7529142459038828,
          0.7524663788706286,
          0.7546932732859756,
          0.7546559510332044,
          0.7535114019482216,
          0.7560866373894328,
          0.7563230116569836,
          0.7558502631218821,
          0.7541583209962553,
          0.7563852154116022,
          0.7569574899540936,
          0.7560866373894328,
          0.756036874385738,
          0.7559746706311193,
          0.7571441012179495,
          0.7561861633968227,
          0.7572187457234919,
          0.75557656660156,
          0.7567459971883903,
          0.7558005001181871,
          0.7583757355593984,
          0.7569574899540936,
          0.7571938642216444,
          0.76011744068872,
          0.757803461016907,
          0.7571192197161021,
          0.7553401923340093,
          0.7556885333598736,
          0.7582015650464662,
          0.7582388872992374,
          0.7559497891292718,
          0.7590102138565084,
          0.7573431532327292,
          0.7592963511277541,
          0.7567335564374665,
          0.7567833194411615,
          0.758798721090805,
          0.7550291735609161,
          0.7571316604670257,
          0.7572685087271868,
          0.7585250245704831,
          0.7573182717308817,
          0.7564598599171446,
          0.7594456401388388,
          0.7583384133066272,
          0.7582637688010848,
          0.7596820144063896,
          0.7589977731055847,
          0.7571565419688733,
          0.759209265871288,
          0.7585872283251017,
          0.7588484840944999,
          0.7578159017678308,
          0.759072417611127,
          0.7578781055224494,
          0.7602542889488809,
          0.7592963511277541,
          0.7608763264950672,
          0.7610753785098469,
          0.7613490750301688,
          0.7604035779599657,
          0.7599059479230166,
          0.7597815404137793,
          0.7604035779599657,
          0.7597317774100845,
          0.7617596198106518,
          0.7602294074470335,
          0.7608763264950672,
          0.7603786964581182,
          0.7596571329045421,
          0.7612246675209315,
          0.760615070725669,
          0.7611251415135417,
          0.7607768004876775,
          0.7606648337293639,
          0.7602294074470335,
          0.7617347383088043,
          0.7606648337293639,
          0.7610629377589231,
          0.7627797613863972,
          0.7630907801594904,
          0.7633022729251938,
          0.76328983217427,
          0.7632525099214988,
          0.7640113957278462,
          0.7641358032370834,
          0.7653301153257611,
          0.7641233624861596,
          0.7637128177056767,
          0.763613291698287,
          0.7645214665157188,
          0.7640487179806174,
          0.763202746917804,
          0.7649942150508204,
          0.762244809096677,
          0.7629663726502531,
          0.7638621067167615,
          0.7634888841890497,
          0.7640860402333884,
          0.7644965850138714,
          0.7646707555268036,
          0.7650688595563628,
          0.7641731254898546,
          0.7644592627611002,
          0.7648698075415832,
          0.7659272713700999,
          0.7650190965526679,
          0.7639491919732275,
          0.764334855251863,
          0.7643224145009393,
          0.7641358032370834,
          0.7645214665157188,
          0.766288053146888,
          0.7648449260397358,
          0.7648076037869646,
          0.7659272713700999,
          0.7660641196302609,
          0.7659397121210236,
          0.7654296413331508,
          0.7677187395031164,
          0.7663004938978116,
          0.7659148306191762,
          0.7652057078165238,
          0.7670469389532352,
          0.7658899491173288,
          0.7658526268645576,
          0.7650813003072865,
          0.7652554708202187,
          0.7666363941727523,
          0.7674077207300233,
          0.7678307062614299,
          0.7670220574513877,
          0.7663129346487354,
          0.7682661325437603,
          0.7664124606561252,
          0.7677685025068113,
          0.7678804692651249,
          0.7686144735696246,
          0.7696968188999888,
          0.7685149475622348,
          0.7682288102909892,
          0.7681292842835994,
          0.7687886440825569,
          0.7682163695400654,
          0.7689379330936416,
          0.7691867481121161,
          0.7690747813538025,
          0.7684776253094637,
          0.7692240703648873,
          0.7682163695400654,
          0.769049899851955,
          0.7698585486619972,
          0.7691618666102686,
          0.7693982408778194,
          0.769821226409226,
          0.77036861944987,
          0.7702442119406328,
          0.7702690934424802,
          0.7702193304387853,
          0.7699705154203108,
          0.7687513218297857,
          0.7693111556213533,
          0.769597292892599,
          0.7693982408778194,
          0.7690001368482602,
          0.7696346151453701,
          0.7701073636804717,
          0.7701446859332429,
          0.7704308232044886,
          0.770231771189709,
          0.7719237133153357,
          0.7700327191749294,
          0.7711026237543698,
          0.7706049937174207,
          0.7712643535163782,
          0.7706920789738869,
          0.7714136425274629,
          0.771276794267302,
          0.7708164864831242,
          0.7725706323633694,
          0.7715629315385477,
          0.7724959878578271,
          0.772184969084734,
          0.772632836117988,
          0.7734663664298778,
          0.7725581916124458,
          0.7733792811734116,
          0.7730931439021659,
          0.7737773852029709,
          0.7733917219243354,
          0.7736280961918861,
          0.773590773939115,
          0.773453925678954,
          0.7733295181697167,
          0.7730558216493948,
          0.7731677884077083,
          0.7732424329132507,
          0.7727074806235305,
          0.7732673144150981,
          0.7735161294335726,
          0.7741257262288351,
          0.7739017927122082,
          0.7740510817232928,
          0.773864470459437,
          0.7746855600204028,
          0.7749219342879536,
          0.7745735932620893,
          0.7753822420721315,
          0.7754195643249027,
          0.7751707493064282,
          0.7760789241238601,
          0.7748224082805638,
          0.7752329530610468,
          0.7751085455518095,
          0.7752951568156654,
          0.775357360570284,
          0.7753075975665891,
          0.7746233562657842,
          0.7751209863027332,
          0.7754693273285975,
          0.7756683793433772,
          0.7757057015961484,
          0.7759171943618517,
          0.7761411278784788,
          0.7769248951866735,
          0.7762406538858686,
          0.7760167203692415,
          0.7764770281534193,
          0.7763028576404872,
          0.7767880469265125,
          0.7770244211940632,
          0.7768253691792837,
          0.7770990656996056,
          0.7770493026959108,
          0.7768502506811311,
          0.7769124544357497,
          0.7769373359375972,
          0.7769746581903684,
          0.7770741841977582,
          0.7770741841977582,
          0.7772234732088429,
          0.7772483547106903,
          0.7773727622199276,
          0.7770990656996056,
          0.777397643721775,
          0.7773229992162327,
          0.7772732362125377,
          0.7772981177143853
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "HIT@10"
        },
        "xaxis": {
         "title": {
          "text": "Epoch"
         }
        },
        "yaxis": {
         "title": {
          "text": "Epoch@10"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = go.Figure(layout = go.Layout(title=\"Loss\"))\n",
    "fig.add_scatter(x=np.arange(len(losses)) + 1, y=losses)\n",
    "fig.update_xaxes(title_text='Epoch', type='log')\n",
    "fig.update_yaxes(title_text='Loss')\n",
    "display(fig)\n",
    "\n",
    "fig = go.Figure(layout = go.Layout(title=\"NDCG@\" + str(EVAL_K)))\n",
    "fig.add_scatter(x=np.arange(len(ndcgs)) + 1, y=ndcgs)\n",
    "fig.update_xaxes(title_text='Epoch')\n",
    "fig.update_yaxes(title_text='NDCG@' + str(EVAL_K))\n",
    "display(fig)\n",
    "\n",
    "fig = go.Figure(layout = go.Layout(title=\"HIT@\" + str(EVAL_K)))\n",
    "fig.add_scatter(x=np.arange(len(hits)) + 1, y=hits)\n",
    "fig.update_xaxes(title_text='Epoch')\n",
    "fig.update_yaxes(title_text='Epoch@' + str(EVAL_K))\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T20:13:30.975385Z",
     "start_time": "2024-11-23T20:13:29.072236Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bd2025e50a64d6a9be4bdd7db0ec475",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating Validation:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test NDCG@10: 0.6531\n",
      "Test HIT@10: 0.7493\n"
     ]
    }
   ],
   "source": [
    "# Load the best model during training\n",
    "test_model = SASRec(num_items=max_iid, num_blocks=NUM_BLOCKS, hidden_dim=HIDDEN_DIM,\n",
    "                    max_seq_len=MAX_SEQUENCE_LENGTH, dropout_p=DROPOUT_PROB, device=PYTORCH_DEVICE)\n",
    "test_model.to(PYTORCH_DEVICE)\n",
    "test_model.load_state_dict(best_ncdg_model_state)\n",
    "\n",
    "ndcg, hit = evaluate_model(test_model, test_loader, device=PYTORCH_DEVICE, autocast=False)\n",
    "\n",
    "print(f\"Test NDCG@{EVAL_K}: {ndcg:.4f}\")\n",
    "print(f\"Test HIT@{EVAL_K}: {hit:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referências\n",
    "\n",
    "- [Self-Attentive Sequential Recommendation](https://cseweb.ucsd.edu/~jmcauley/pdfs/icdm18.pdf)\n",
    "- [SASRec em PyTorch (por Pmixer)](https://github.com/pmixer/SASRec.pytorch)\n",
    "- [SASRec em PyTorch (por Seanswyi)](https://github.com/seanswyi/sasrec-pytorch)\n",
    "- [Métricas: NDCG e HIT](https://www.evidentlyai.com/ranking-metrics/evaluating-recommender-systems#hit-rate)\n",
    "- [Attention Is All You Need](https://arxiv.org/abs/1706.03762)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys-tp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
