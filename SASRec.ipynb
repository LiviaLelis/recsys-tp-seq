{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sistemas de Recomendação Sequenciais\n",
    "\n",
    "Nesse projeto, iremos implementar o algoritmo SASRec, que é um algoritmo de\n",
    "recomendação sequencial.\n",
    "\n",
    "Primeiramente, o que é um algoritmo de recomendação sequencial? Um algoritmo de\n",
    "recomendação sequencial é uma subcategorial dos sistemas de recomendação, que\n",
    "são uma categoria de sistemas que tem como objetivo predizer o filtrar itens\n",
    "(como filmes, livros, etc.) que um usuário alvo irá gostar. Os sistemas de\n",
    "recomendação sequenciais se diferem ao tomar em consideração o tempo, ou seja,\n",
    "a ordem em que os usuários interagem com os itens do sistema, tentando predizer\n",
    "a partir disso a sua próxima interação.\n",
    "\n",
    "Esses sistemas são bastante semelhantes aos sistemas de recomendação baseados\n",
    "em sessão, tendo bastante intersectação entre eles. A diferença principal é que\n",
    "os sistemas de recomendação sequencial se baseia na ordem em que os usuários\n",
    "interagem os itens, já os sistemas de recomendação baseados em sessão se baseiam\n",
    "nos grupos de itens que um usuário interage com durante suas sessões de uso.\n",
    "\n",
    "Nesse projeto iremos usar um conjunto de dados de reprodução de músicas do \n",
    "last.fm (bem antigo, com reproduções até o final de 2009). Tomaremos uma \n",
    "abordagem mista, onde separaremos a sequência dos usuários em blocos menores de\n",
    "reprodução contínua de músicas que chamaremos de sessões de uso, já que isso nos\n",
    "permitirá expandir os dados em mais blocos de sequências menores, o que\n",
    "acreditamos fazer mais sentido no contexto de predizer a próxima música, já que\n",
    "assumimos que o passado recente é mais relevante para a próxima música que\n",
    "históricos distantes e temos uma limitação de janela de quantos itens podemos\n",
    "escolher para o passado recente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T20:06:54.045698Z",
     "start_time": "2024-11-23T20:06:54.042378Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import warnings\n",
    "from datetime import timedelta, datetime\n",
    "\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import display\n",
    "from ipywidgets.widgets import HBox\n",
    "\n",
    "import torch\n",
    "from torch.functional import F\n",
    "from torch import nn, optim, cuda\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Colab\n",
    "\n",
    "Configurando persistência de dados caso esteja rodando dentro do ambiente do Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T19:10:42.037723Z",
     "start_time": "2024-11-23T19:10:42.035812Z"
    }
   },
   "outputs": [],
   "source": [
    "ROOT_PATH = './'\n",
    "DRIVE_PATH = 'Colab/RecSys-TP'\n",
    "\n",
    "# When on Colab, use Google Drive as the root path to persist and load data\n",
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import drive, output\n",
    "    output.enable_custom_widget_manager()\n",
    "\n",
    "    drive.mount('/content/drive')\n",
    "    ROOT_PATH = os.path.join('/content/drive/My Drive/', DRIVE_PATH)\n",
    "    os.makedirs(ROOT_PATH, exist_ok=True)\n",
    "    os.chdir(ROOT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurações\n",
    "\n",
    "Detectando o dispositivo a ser utilizado para treinamento (CPU ou GPU), além de outras configurações de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T19:10:42.236754Z",
     "start_time": "2024-11-23T19:10:42.083373Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device for PyTorch\n"
     ]
    }
   ],
   "source": [
    "RANDOM_SEED = 1984\n",
    "\n",
    "BATCH_SIZE = 1024\n",
    "MAX_SEQUENCE_LENGTH = 50\n",
    "DROPOUT_PROB = 0.4\n",
    "HIDDEN_DIM = 64\n",
    "NUM_BLOCKS = 2\n",
    "\n",
    "TOTAL_EPOCHS = 500\n",
    "\n",
    "BETA_1 = 0.9\n",
    "BETA_2 = 0.999\n",
    "EPS = 1e-8\n",
    "AMSGRAD = False\n",
    "WEIGHT_DECAY = 0.01\n",
    "\n",
    "WARMUP_RATIO = 0.05\n",
    "# LEARNING_RATE = 0.04\n",
    "# USE_SCHEDULER = True\n",
    "\n",
    "LEARNING_RATE = 0.01\n",
    "USE_SCHEDULER = False\n",
    "\n",
    "EVAL_K = 10\n",
    "\n",
    "\n",
    "PYTORCH_DEVICE = 'cpu'\n",
    "\n",
    "# Use NVIDIA GPU if available\n",
    "if cuda.is_available():\n",
    "    PYTORCH_DEVICE = 'cuda'\n",
    "\n",
    "# Use Apple Metal backend if available\n",
    "if torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\"Your device supports MPS but it is not installed. Checkout https://developer.apple.com/metal/pytorch/\")\n",
    "    else:\n",
    "        PYTORCH_DEVICE = 'mps'\n",
    "\n",
    "\n",
    "print (f\"Using {PYTORCH_DEVICE} device for PyTorch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T19:10:42.245640Z",
     "start_time": "2024-11-23T19:10:42.240744Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.mps.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T19:10:43.461033Z",
     "start_time": "2024-11-23T19:10:42.285170Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>gender</th><th>age</th><th>country</th><th>registered</th></tr><tr><td>str</td><td>str</td><td>i64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;user_000809&quot;</td><td>&quot;m&quot;</td><td>null</td><td>&quot;Finland&quot;</td><td>&quot;Jun&nbsp;8,&nbsp;2005&quot;</td></tr><tr><td>&quot;user_000112&quot;</td><td>&quot;f&quot;</td><td>30</td><td>&quot;Turkey&quot;</td><td>&quot;Mar&nbsp;25,&nbsp;2006&quot;</td></tr><tr><td>&quot;user_000086&quot;</td><td>&quot;f&quot;</td><td>27</td><td>null</td><td>&quot;Sep&nbsp;21,&nbsp;2007&quot;</td></tr><tr><td>&quot;user_000403&quot;</td><td>&quot;f&quot;</td><td>null</td><td>&quot;United&nbsp;States&quot;</td><td>&quot;May&nbsp;17,&nbsp;2006&quot;</td></tr><tr><td>&quot;user_000863&quot;</td><td>null</td><td>null</td><td>&quot;United&nbsp;Kingdom&quot;</td><td>&quot;Oct&nbsp;15,&nbsp;2004&quot;</td></tr><tr><td>&quot;user_000720&quot;</td><td>&quot;f&quot;</td><td>null</td><td>&quot;Norway&quot;</td><td>&quot;Jun&nbsp;29,&nbsp;2007&quot;</td></tr><tr><td>&quot;user_000985&quot;</td><td>&quot;f&quot;</td><td>null</td><td>&quot;Australia&quot;</td><td>&quot;May&nbsp;22,&nbsp;2006&quot;</td></tr><tr><td>&quot;user_000487&quot;</td><td>&quot;m&quot;</td><td>null</td><td>&quot;Netherlands&quot;</td><td>&quot;Mar&nbsp;8,&nbsp;2006&quot;</td></tr><tr><td>&quot;user_000049&quot;</td><td>null</td><td>null</td><td>null</td><td>&quot;Jan&nbsp;11,&nbsp;2006&quot;</td></tr><tr><td>&quot;user_000184&quot;</td><td>&quot;f&quot;</td><td>23</td><td>&quot;Canada&quot;</td><td>&quot;Jun&nbsp;3,&nbsp;2006&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 5)\n",
       "┌─────────────┬────────┬──────┬────────────────┬──────────────┐\n",
       "│ user_id     ┆ gender ┆ age  ┆ country        ┆ registered   │\n",
       "│ ---         ┆ ---    ┆ ---  ┆ ---            ┆ ---          │\n",
       "│ str         ┆ str    ┆ i64  ┆ str            ┆ str          │\n",
       "╞═════════════╪════════╪══════╪════════════════╪══════════════╡\n",
       "│ user_000809 ┆ m      ┆ null ┆ Finland        ┆ Jun 8, 2005  │\n",
       "│ user_000112 ┆ f      ┆ 30   ┆ Turkey         ┆ Mar 25, 2006 │\n",
       "│ user_000086 ┆ f      ┆ 27   ┆ null           ┆ Sep 21, 2007 │\n",
       "│ user_000403 ┆ f      ┆ null ┆ United States  ┆ May 17, 2006 │\n",
       "│ user_000863 ┆ null   ┆ null ┆ United Kingdom ┆ Oct 15, 2004 │\n",
       "│ user_000720 ┆ f      ┆ null ┆ Norway         ┆ Jun 29, 2007 │\n",
       "│ user_000985 ┆ f      ┆ null ┆ Australia      ┆ May 22, 2006 │\n",
       "│ user_000487 ┆ m      ┆ null ┆ Netherlands    ┆ Mar 8, 2006  │\n",
       "│ user_000049 ┆ null   ┆ null ┆ null           ┆ Jan 11, 2006 │\n",
       "│ user_000184 ┆ f      ┆ 23   ┆ Canada         ┆ Jun 3, 2006  │\n",
       "└─────────────┴────────┴──────┴────────────────┴──────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>timestamp</th><th>artist_id</th><th>artist_name</th><th>track_id</th><th>track_name</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;user_000806&quot;</td><td>&quot;2008-08-09T19:28:14Z&quot;</td><td>&quot;fc61dd75-880b-44ba-9ba9-c7b643…</td><td>&quot;Prefuse&nbsp;73&quot;</td><td>&quot;60f3a1c9-e756-4a48-8a3e-c44140…</td><td>&quot;Altoid&nbsp;Addiction&nbsp;(Interlude)&quot;</td></tr><tr><td>&quot;user_000108&quot;</td><td>&quot;2007-12-19T17:14:42Z&quot;</td><td>&quot;6ae51665-8261-4ae5-883f-189965…</td><td>&quot;Filter&quot;</td><td>&quot;784f24f6-6fa7-44e7-81a5-a7b592…</td><td>&quot;The&nbsp;Best&nbsp;Things&quot;</td></tr><tr><td>&quot;user_000079&quot;</td><td>&quot;2008-12-01T00:09:19Z&quot;</td><td>&quot;48896dee-a985-424d-9849-84802f…</td><td>&quot;Johnny&nbsp;Mathis&quot;</td><td>&quot;e77a742f-eb2c-417c-9b48-45e404…</td><td>&quot;Can&#x27;T&nbsp;Get&nbsp;Out&nbsp;Of&nbsp;This&nbsp;Mood&quot;</td></tr><tr><td>&quot;user_000407&quot;</td><td>&quot;2008-05-20T15:37:40Z&quot;</td><td>&quot;8bfac288-ccc5-448d-9573-c33ea2…</td><td>&quot;Red&nbsp;Hot&nbsp;Chili&nbsp;Peppers&quot;</td><td>&quot;7a3e8796-a0b3-4999-b268-4e2d47…</td><td>&quot;Otherside&quot;</td></tr><tr><td>&quot;user_000861&quot;</td><td>&quot;2008-02-12T22:25:17Z&quot;</td><td>&quot;31aa6f87-8d00-4ae9-a5cc-6d7eee…</td><td>&quot;Alphaville&quot;</td><td>&quot;f11939cf-9ad1-45b8-b927-a89b00…</td><td>&quot;Big&nbsp;In&nbsp;Japan&quot;</td></tr><tr><td>&quot;user_000728&quot;</td><td>&quot;2009-05-21T19:04:24Z&quot;</td><td>&quot;41c86965-305a-482d-bc1e-2daeca…</td><td>&quot;Skankfunk&quot;</td><td>&quot;e48c9ed7-34ac-44aa-ab5a-3d792a…</td><td>&quot;Melo-Pole&quot;</td></tr><tr><td>&quot;user_000990&quot;</td><td>&quot;2009-03-31T10:20:28Z&quot;</td><td>&quot;1bc69a93-8020-4e07-8b05-0b6331…</td><td>&quot;The&nbsp;Cliks&quot;</td><td>&quot;f89ba590-0226-4c65-b5c5-4b69ee…</td><td>&quot;Complicated&quot;</td></tr><tr><td>&quot;user_000174&quot;</td><td>&quot;2005-05-03T18:42:12Z&quot;</td><td>&quot;fc178247-53b6-4702-ad77-546cb0…</td><td>&quot;The&nbsp;Exposures&quot;</td><td>&quot;b222a53c-3168-43e5-a40d-65e95a…</td><td>&quot;Sake&nbsp;Rock&quot;</td></tr><tr><td>&quot;user_000412&quot;</td><td>&quot;2005-11-04T22:08:08Z&quot;</td><td>&quot;86e736b4-93e2-40ff-9e1c-fb7c63…</td><td>&quot;Barenaked&nbsp;Ladies&quot;</td><td>&quot;05b34070-535a-4b92-aa9b-ecb97c…</td><td>&quot;Call&nbsp;And&nbsp;Answer&quot;</td></tr><tr><td>&quot;user_000112&quot;</td><td>&quot;2007-12-11T01:00:05Z&quot;</td><td>&quot;fc63a914-272d-4b95-9221-61adcc…</td><td>&quot;Gal&nbsp;Costa&quot;</td><td>&quot;08345bf4-f7b1-40ff-98c3-21b34c…</td><td>&quot;Estrada&nbsp;Do&nbsp;Sol&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 6)\n",
       "┌─────────────┬────────────────┬────────────────┬────────────────┬────────────────┬────────────────┐\n",
       "│ user_id     ┆ timestamp      ┆ artist_id      ┆ artist_name    ┆ track_id       ┆ track_name     │\n",
       "│ ---         ┆ ---            ┆ ---            ┆ ---            ┆ ---            ┆ ---            │\n",
       "│ str         ┆ str            ┆ str            ┆ str            ┆ str            ┆ str            │\n",
       "╞═════════════╪════════════════╪════════════════╪════════════════╪════════════════╪════════════════╡\n",
       "│ user_000806 ┆ 2008-08-09T19: ┆ fc61dd75-880b- ┆ Prefuse 73     ┆ 60f3a1c9-e756- ┆ Altoid         │\n",
       "│             ┆ 28:14Z         ┆ 44ba-9ba9-c7b6 ┆                ┆ 4a48-8a3e-c441 ┆ Addiction      │\n",
       "│             ┆                ┆ 43…            ┆                ┆ 40…            ┆ (Interlude)    │\n",
       "│ user_000108 ┆ 2007-12-19T17: ┆ 6ae51665-8261- ┆ Filter         ┆ 784f24f6-6fa7- ┆ The Best       │\n",
       "│             ┆ 14:42Z         ┆ 4ae5-883f-1899 ┆                ┆ 44e7-81a5-a7b5 ┆ Things         │\n",
       "│             ┆                ┆ 65…            ┆                ┆ 92…            ┆                │\n",
       "│ user_000079 ┆ 2008-12-01T00: ┆ 48896dee-a985- ┆ Johnny Mathis  ┆ e77a742f-eb2c- ┆ Can'T Get Out  │\n",
       "│             ┆ 09:19Z         ┆ 424d-9849-8480 ┆                ┆ 417c-9b48-45e4 ┆ Of This Mood   │\n",
       "│             ┆                ┆ 2f…            ┆                ┆ 04…            ┆                │\n",
       "│ user_000407 ┆ 2008-05-20T15: ┆ 8bfac288-ccc5- ┆ Red Hot Chili  ┆ 7a3e8796-a0b3- ┆ Otherside      │\n",
       "│             ┆ 37:40Z         ┆ 448d-9573-c33e ┆ Peppers        ┆ 4999-b268-4e2d ┆                │\n",
       "│             ┆                ┆ a2…            ┆                ┆ 47…            ┆                │\n",
       "│ user_000861 ┆ 2008-02-12T22: ┆ 31aa6f87-8d00- ┆ Alphaville     ┆ f11939cf-9ad1- ┆ Big In Japan   │\n",
       "│             ┆ 25:17Z         ┆ 4ae9-a5cc-6d7e ┆                ┆ 45b8-b927-a89b ┆                │\n",
       "│             ┆                ┆ ee…            ┆                ┆ 00…            ┆                │\n",
       "│ user_000728 ┆ 2009-05-21T19: ┆ 41c86965-305a- ┆ Skankfunk      ┆ e48c9ed7-34ac- ┆ Melo-Pole      │\n",
       "│             ┆ 04:24Z         ┆ 482d-bc1e-2dae ┆                ┆ 44aa-ab5a-3d79 ┆                │\n",
       "│             ┆                ┆ ca…            ┆                ┆ 2a…            ┆                │\n",
       "│ user_000990 ┆ 2009-03-31T10: ┆ 1bc69a93-8020- ┆ The Cliks      ┆ f89ba590-0226- ┆ Complicated    │\n",
       "│             ┆ 20:28Z         ┆ 4e07-8b05-0b63 ┆                ┆ 4c65-b5c5-4b69 ┆                │\n",
       "│             ┆                ┆ 31…            ┆                ┆ ee…            ┆                │\n",
       "│ user_000174 ┆ 2005-05-03T18: ┆ fc178247-53b6- ┆ The Exposures  ┆ b222a53c-3168- ┆ Sake Rock      │\n",
       "│             ┆ 42:12Z         ┆ 4702-ad77-546c ┆                ┆ 43e5-a40d-65e9 ┆                │\n",
       "│             ┆                ┆ b0…            ┆                ┆ 5a…            ┆                │\n",
       "│ user_000412 ┆ 2005-11-04T22: ┆ 86e736b4-93e2- ┆ Barenaked      ┆ 05b34070-535a- ┆ Call And       │\n",
       "│             ┆ 08:08Z         ┆ 40ff-9e1c-fb7c ┆ Ladies         ┆ 4b92-aa9b-ecb9 ┆ Answer         │\n",
       "│             ┆                ┆ 63…            ┆                ┆ 7c…            ┆                │\n",
       "│ user_000112 ┆ 2007-12-11T01: ┆ fc63a914-272d- ┆ Gal Costa      ┆ 08345bf4-f7b1- ┆ Estrada Do Sol │\n",
       "│             ┆ 00:05Z         ┆ 4b95-9221-61ad ┆                ┆ 40ff-98c3-21b3 ┆                │\n",
       "│             ┆                ┆ cc…            ┆                ┆ 4c…            ┆                │\n",
       "└─────────────┴────────────────┴────────────────┴────────────────┴────────────────┴────────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Carrega os dados do dataset (http://ocelma.net/MusicRecommendationDataset/lastfm-1K.html)\n",
    "user_profiles = pl.read_csv(\"./data/lastfm-dataset-1K/userid-profile.tsv\", separator=\"\\t\")\n",
    "user_interactions = pl.read_csv(\"./data/lastfm-dataset-1K/userid-timestamp-artid-artname-traid-traname.tsv\", separator=\"\\t\", has_header=False, quote_char=None)\n",
    "\n",
    "# Renomeia as colunas\n",
    "user_profiles.columns = [\"user_id\", \"gender\", \"age\", \"country\", \"registered\"]\n",
    "user_interactions.columns = [\"user_id\", \"timestamp\", \"artist_id\", \"artist_name\", \"track_id\", \"track_name\"]\n",
    "\n",
    "# Descarta linhas com valores nulos nas iterações\n",
    "user_interactions = user_interactions.drop_nulls()\n",
    "\n",
    "display(user_profiles.sample(10, seed=RANDOM_SEED))\n",
    "display(user_interactions.sample(10, seed=RANDOM_SEED))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T19:10:53.402635Z",
     "start_time": "2024-11-23T19:10:43.477374Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>uid</th><th>iid</th><th>ts</th></tr><tr><td>i64</td><td>i64</td><td>datetime[μs]</td></tr></thead><tbody><tr><td>1</td><td>73722</td><td>2006-03-24&nbsp;19:47:21</td></tr><tr><td>1</td><td>328201</td><td>2006-03-24&nbsp;19:51:35</td></tr><tr><td>1</td><td>632506</td><td>2006-03-24&nbsp;19:55:08</td></tr><tr><td>1</td><td>644966</td><td>2006-03-24&nbsp;20:04:33</td></tr><tr><td>1</td><td>684610</td><td>2006-03-24&nbsp;20:11:47</td></tr><tr><td>1</td><td>314717</td><td>2006-03-24&nbsp;20:17:19</td></tr><tr><td>1</td><td>756273</td><td>2006-03-24&nbsp;20:22:53</td></tr><tr><td>1</td><td>402184</td><td>2006-03-24&nbsp;20:26:45</td></tr><tr><td>1</td><td>607225</td><td>2006-03-24&nbsp;20:30:44</td></tr><tr><td>1</td><td>785747</td><td>2006-03-24&nbsp;20:35:21</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 3)\n",
       "┌─────┬────────┬─────────────────────┐\n",
       "│ uid ┆ iid    ┆ ts                  │\n",
       "│ --- ┆ ---    ┆ ---                 │\n",
       "│ i64 ┆ i64    ┆ datetime[μs]        │\n",
       "╞═════╪════════╪═════════════════════╡\n",
       "│ 1   ┆ 73722  ┆ 2006-03-24 19:47:21 │\n",
       "│ 1   ┆ 328201 ┆ 2006-03-24 19:51:35 │\n",
       "│ 1   ┆ 632506 ┆ 2006-03-24 19:55:08 │\n",
       "│ 1   ┆ 644966 ┆ 2006-03-24 20:04:33 │\n",
       "│ 1   ┆ 684610 ┆ 2006-03-24 20:11:47 │\n",
       "│ 1   ┆ 314717 ┆ 2006-03-24 20:17:19 │\n",
       "│ 1   ┆ 756273 ┆ 2006-03-24 20:22:53 │\n",
       "│ 1   ┆ 402184 ┆ 2006-03-24 20:26:45 │\n",
       "│ 1   ┆ 607225 ┆ 2006-03-24 20:30:44 │\n",
       "│ 1   ┆ 785747 ┆ 2006-03-24 20:35:21 │\n",
       "└─────┴────────┴─────────────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cria um mapeamento dos IDs para números\n",
    "item_ids = user_interactions['track_id'].unique().to_list()\n",
    "user_ids = user_interactions['user_id'].unique().to_list()\n",
    "\n",
    "\n",
    "item_id_index = {id: i + 1 for i, id in enumerate(item_ids)}\n",
    "item_id_index_rev = {v: k for k, v in item_id_index.items()}\n",
    "\n",
    "user_id_index = {id: i + 1 for i, id in enumerate(user_ids)}\n",
    "user_id_index_rev = {v: k for k, v in user_id_index.items()}\n",
    "\n",
    "\n",
    "# Aplica as transformações no dataframe\n",
    "dataset = user_interactions.select(\n",
    "    pl.col('user_id').replace_strict(user_id_index).alias('uid'),\n",
    "    pl.col('track_id').replace_strict(item_id_index).alias('iid'),\n",
    "    pl.col('timestamp').cast(pl.Datetime).alias('ts')\n",
    ").sort('uid', 'ts')\n",
    "\n",
    "max_iid = dataset['iid'].max()\n",
    "\n",
    "display(dataset.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separando as sessões\n",
    "\n",
    "Devido a natureza do Last.FM, cada usuário possui um histórico de músicas ao \n",
    "longo de um extenso período de tempo. Para melhorar a qualidade e usabilidade do\n",
    "modelo, separamemos as reproduções em sessões, definindo o fim de uma sessão \n",
    "como um período de tempo de 30 minutos onde não houve nenhuma reprodução de \n",
    "música.\n",
    "\n",
    "Desse modo conseguimos ter sessões de tamanho arbitrário que representam a \n",
    "reprodução contínua de músicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T19:10:54.014693Z",
     "start_time": "2024-11-23T19:10:53.644882Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (16_982_280, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>uid</th><th>iid</th><th>ts</th><th>sid</th></tr><tr><td>i64</td><td>i64</td><td>datetime[μs]</td><td>u32</td></tr></thead><tbody><tr><td>1</td><td>73722</td><td>2006-03-24&nbsp;19:47:21</td><td>1</td></tr><tr><td>1</td><td>328201</td><td>2006-03-24&nbsp;19:51:35</td><td>1</td></tr><tr><td>1</td><td>632506</td><td>2006-03-24&nbsp;19:55:08</td><td>1</td></tr><tr><td>1</td><td>644966</td><td>2006-03-24&nbsp;20:04:33</td><td>1</td></tr><tr><td>1</td><td>684610</td><td>2006-03-24&nbsp;20:11:47</td><td>1</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>992</td><td>541802</td><td>2006-06-18&nbsp;20:09:43</td><td>899897</td></tr><tr><td>992</td><td>949131</td><td>2006-06-18&nbsp;20:14:17</td><td>899897</td></tr><tr><td>992</td><td>690845</td><td>2006-06-18&nbsp;20:17:58</td><td>899897</td></tr><tr><td>992</td><td>741339</td><td>2006-06-18&nbsp;20:22:14</td><td>899897</td></tr><tr><td>992</td><td>502793</td><td>2009-03-20&nbsp;02:55:52</td><td>899898</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (16_982_280, 4)\n",
       "┌─────┬────────┬─────────────────────┬────────┐\n",
       "│ uid ┆ iid    ┆ ts                  ┆ sid    │\n",
       "│ --- ┆ ---    ┆ ---                 ┆ ---    │\n",
       "│ i64 ┆ i64    ┆ datetime[μs]        ┆ u32    │\n",
       "╞═════╪════════╪═════════════════════╪════════╡\n",
       "│ 1   ┆ 73722  ┆ 2006-03-24 19:47:21 ┆ 1      │\n",
       "│ 1   ┆ 328201 ┆ 2006-03-24 19:51:35 ┆ 1      │\n",
       "│ 1   ┆ 632506 ┆ 2006-03-24 19:55:08 ┆ 1      │\n",
       "│ 1   ┆ 644966 ┆ 2006-03-24 20:04:33 ┆ 1      │\n",
       "│ 1   ┆ 684610 ┆ 2006-03-24 20:11:47 ┆ 1      │\n",
       "│ …   ┆ …      ┆ …                   ┆ …      │\n",
       "│ 992 ┆ 541802 ┆ 2006-06-18 20:09:43 ┆ 899897 │\n",
       "│ 992 ┆ 949131 ┆ 2006-06-18 20:14:17 ┆ 899897 │\n",
       "│ 992 ┆ 690845 ┆ 2006-06-18 20:17:58 ┆ 899897 │\n",
       "│ 992 ┆ 741339 ┆ 2006-06-18 20:22:14 ┆ 899897 │\n",
       "│ 992 ┆ 502793 ┆ 2009-03-20 02:55:52 ┆ 899898 │\n",
       "└─────┴────────┴─────────────────────┴────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "threshold = timedelta(minutes=30)\n",
    "\n",
    "# Marca cada música como se ela representa ou não o início de uma nova sessão\n",
    "new_session_col = dataset.group_by('uid') \\\n",
    "    .agg(\n",
    "        # Separa por usuário (uma sessão é de um usuário)\n",
    "        pl.col('iid'), \n",
    "\n",
    "        # Computa a diferença entre a música atual e a anterior, se essa \n",
    "        # diferença for nula ou maior igual ao nosso limite de tempo,\n",
    "        # então é um início de sessão.\n",
    "        (pl.col('ts').diff().fill_null(threshold) >= threshold).alias('start') , \n",
    "    # Expande as duas listas simultaneamente para que voltemos ao formato inicial\n",
    "    ).explode('iid', 'start')['start'] \n",
    "\n",
    "# Agora, para criar um id para cada sessão, vamos usar a função cum_sum (isso \n",
    "# funciona pois nossos dados estão ordenados por usuário e timestamp, \n",
    "# respectivamente)\n",
    "dataset_with_session = dataset.with_columns(new_session_col.cum_sum().alias('sid'))\n",
    "\n",
    "display(dataset_with_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T19:10:54.404130Z",
     "start_time": "2024-11-23T19:10:54.252276Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>sid</th><th>iids</th></tr><tr><td>u32</td><td>list[i64]</td></tr></thead><tbody><tr><td>122313</td><td>[596439,&nbsp;695196,&nbsp;…&nbsp;431967]</td></tr><tr><td>215764</td><td>[801849]</td></tr><tr><td>699454</td><td>[40355]</td></tr><tr><td>720024</td><td>[807305,&nbsp;412151]</td></tr><tr><td>821755</td><td>[201595,&nbsp;896875,&nbsp;…&nbsp;122965]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 2)\n",
       "┌────────┬────────────────────────────┐\n",
       "│ sid    ┆ iids                       │\n",
       "│ ---    ┆ ---                        │\n",
       "│ u32    ┆ list[i64]                  │\n",
       "╞════════╪════════════════════════════╡\n",
       "│ 122313 ┆ [596439, 695196, … 431967] │\n",
       "│ 215764 ┆ [801849]                   │\n",
       "│ 699454 ┆ [40355]                    │\n",
       "│ 720024 ┆ [807305, 412151]           │\n",
       "│ 821755 ┆ [201595, 896875, … 122965] │\n",
       "└────────┴────────────────────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>value</th></tr><tr><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>899898.0</td></tr><tr><td>&quot;null_count&quot;</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>18.871339</td></tr><tr><td>&quot;std&quot;</td><td>43.066011</td></tr><tr><td>&quot;min&quot;</td><td>1.0</td></tr><tr><td>&quot;25%&quot;</td><td>3.0</td></tr><tr><td>&quot;50%&quot;</td><td>9.0</td></tr><tr><td>&quot;75%&quot;</td><td>21.0</td></tr><tr><td>&quot;max&quot;</td><td>5435.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 2)\n",
       "┌────────────┬───────────┐\n",
       "│ statistic  ┆ value     │\n",
       "│ ---        ┆ ---       │\n",
       "│ str        ┆ f64       │\n",
       "╞════════════╪═══════════╡\n",
       "│ count      ┆ 899898.0  │\n",
       "│ null_count ┆ 0.0       │\n",
       "│ mean       ┆ 18.871339 │\n",
       "│ std        ┆ 43.066011 │\n",
       "│ min        ┆ 1.0       │\n",
       "│ 25%        ┆ 3.0       │\n",
       "│ 50%        ┆ 9.0       │\n",
       "│ 75%        ┆ 21.0      │\n",
       "│ max        ┆ 5435.0    │\n",
       "└────────────┴───────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Agrupa as reproduções por sessão em um array\n",
    "dataset_grouped = dataset_with_session.group_by('sid').agg(pl.col('iid').alias('iids'))\n",
    "display(dataset_grouped.head())\n",
    "\n",
    "# Imprime a distribuição do tamanho das sessões\n",
    "display(dataset_grouped['iids'].list.len().describe())\n",
    "\n",
    "\n",
    "# Reduz o número de amostras para reduzir o tempo de treinamento (ao custo de\n",
    "# uma redução na qualidade da base de dados) Seguiremos com 100k sessões das\n",
    "# ~900k presentes na base.\n",
    "dataset_grouped = dataset_grouped.sample(1e5, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separação dos dados de treino, teste e validação\n",
    "\n",
    "Iremos dividir o dataset em 3 conjuntos de treino, teste e validação. Desta\n",
    "forma, conseguimos avaliar ao longo do treinamento a qualidade do modelo\n",
    "por meio dos dados de validação evitando um enviesamento para a avaliação final\n",
    "utilizando os dados de teste.\n",
    "\n",
    "Temos duas estratégias possíveis para separação aqui: a primeira seria\n",
    "utilizar uma separação por sessão, ou seja, dedicar parte das sessões para\n",
    "cada um dos conjuntos. Outra alternativa é manter todas as sessões nos 3\n",
    "conjuntos, modificando removendo as últimas duas reproduções para os dados\n",
    "de treino, a última para os dados de validação e mantendo os dados completos\n",
    "para os dados de teste.\n",
    "\n",
    "Seguiremos com a segunda estratégia, mantendo todas as sessões nos 3 conjuntos,\n",
    "já que parece ter sido a estratégia tomada no artigo original, entretanto \n",
    "acreditamos que isso pode afetar a qualidade da avaliação final pela\n",
    "similaridade com os dados de treino durante a validação e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T19:10:55.006495Z",
     "start_time": "2024-11-23T19:10:54.642475Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_slice(data: list[int]) -> list[int]:\n",
    "    if len(data) < 3:\n",
    "        return data\n",
    "    \n",
    "    return data[:-2]\n",
    "\n",
    "def validation_slice(data: list[int]) -> tuple[list[int], int] | None:\n",
    "    if len(data) < 3:\n",
    "        return None\n",
    "    \n",
    "    return (data[:-2], data[-2])\n",
    "\n",
    "def test_slice(data: list[int]) -> tuple[list[int], int] | None:\n",
    "    if len(data) < 3:\n",
    "        return None\n",
    "    \n",
    "    return (data[:-1], data[-1])\n",
    "\n",
    "train_data = [train_slice(data.to_numpy()) for data in dataset_grouped['iids']]\n",
    "validation_data = [validation_slice(data.to_numpy()) for data in dataset_grouped['iids'] if len(data) > 2]\n",
    "test_data = [test_slice(data.to_numpy()) for data in dataset_grouped['iids'] if len(data) > 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O modelo \"Self-Attentive Sequential Recommendation\" (SASRec)\n",
    "\n",
    "O modelo SASRec foi proposto em 2018 pelos pesquisadores\n",
    "[Wang-Cheng Kang e Julian McAuley](https://arxiv.org/abs/1808.09781). Ele\n",
    "consiste de um modelo para recomendação sequencial baseado na (recente no \n",
    "momento de lançamento) arquitetura de atenção \n",
    "([Attention is All You Need](https://arxiv.org/abs/1706.03762)), construindo\n",
    "assim uma rede neural profunda com embeddings, camadas de atenção e camadas de\n",
    "avanço pontual para o propósito de gerar recomendações baseadas em dados \n",
    "sequenciais. Esse modelo foi um dos pioneiros nessa estratégia, resultando em\n",
    "avanços significativos na qualidade das recomendações. Um dos seus pontos\n",
    "limitantes é a não inclusão de informações contextuais (como dados dos itens e\n",
    "usuários) para a geração das recomendações.\n",
    "\n",
    "![Diagrama simplificado da estrutura do modelo - retirado do paper original](./assets/sasrec-diagram.png)\n",
    "\n",
    "Esse modelo foi capaz de superar os resultados de outros modelos proeminentes\n",
    "durante seu lançamento, como o BPR, FPMC, TransRec e GRU4Rec.\n",
    "\n",
    "### A implementação\n",
    "\n",
    "Partimos de uma implementação já existente em PyTorch que se baseia, \n",
    "indiretamente, na implementação original dos autores em TensorFlow:\n",
    "[versão em PyTorch por _seanswyi_](https://github.com/seanswyi/sasrec-pytorch).\n",
    "\n",
    "Fizemos algumas adaptações em relação ao original, porém sem afetar a estrutura\n",
    "da rede em si, apenas mudando o otmizado utilizado, batch size, parâmetros e\n",
    "alguns pequenos ajustes no código para fica mais organizado, marginalmente mais\n",
    "eficiente e ao ambiente de desenvolvimento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T19:10:55.243881Z",
     "start_time": "2024-11-23T19:10:55.238120Z"
    }
   },
   "outputs": [],
   "source": [
    "# The following SASRec implementation is an adaptation from https://github.com/seanswyi/sasrec-pytorch\n",
    "\n",
    "InputSequences = torch.Tensor\n",
    "PositiveSamples = torch.Tensor\n",
    "NegativeSamples = torch.Tensor\n",
    "\n",
    "class PointWiseFFNN(nn.Module):\n",
    "    def __init__(self, hidden_dim: int) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.W1 = nn.Linear(in_features=hidden_dim, out_features=hidden_dim)\n",
    "        self.W2 = nn.Linear(in_features=hidden_dim, out_features=hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_1 = self.relu(self.W1(x))\n",
    "        x_2 = self.W2(x_1)\n",
    "\n",
    "        return x_2\n",
    "\n",
    "\n",
    "class SelfAttnBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_seq_len: int,\n",
    "        hidden_dim: int,\n",
    "        dropout_p: float,\n",
    "        device: str,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.layer_norm = nn.LayerNorm(normalized_shape=hidden_dim)\n",
    "        self.dropout = nn.Dropout(p=dropout_p)\n",
    "\n",
    "        self.self_attn = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_dim,\n",
    "            num_heads=1,\n",
    "            dropout=dropout_p,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.ffnn = PointWiseFFNN(hidden_dim=hidden_dim)\n",
    "\n",
    "    def dropout_layernorm(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        layer_norm_output = self.layer_norm(x)\n",
    "        dropout_output = self.dropout(layer_norm_output)\n",
    "\n",
    "        return dropout_output\n",
    "\n",
    "    def forward(self, x: torch.Tensor, padding_mask: torch.Tensor) -> torch.Tensor:\n",
    "        seq_len = x.shape[1]\n",
    "        attention_mask = ~torch.tril(\n",
    "            torch.ones(size=(seq_len, seq_len), dtype=torch.bool, device=x.device.type)\n",
    "        )\n",
    "\n",
    "        x_attn, _ = self.self_attn(\n",
    "            key=self.layer_norm(x),\n",
    "            query=x,\n",
    "            value=x,\n",
    "            attn_mask=attention_mask,\n",
    "        )\n",
    "        x_attn_output = x + self.dropout_layernorm(x_attn)\n",
    "\n",
    "        x_ffnn = self.ffnn(x_attn_output)\n",
    "        x_ffnn_output = x_attn_output + self.dropout_layernorm(x_ffnn)\n",
    "\n",
    "        output = x_ffnn_output * padding_mask.unsqueeze(-1)\n",
    "        return output\n",
    "\n",
    "\n",
    "class EmbeddingLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_items: int,\n",
    "        hidden_dim: int,\n",
    "        max_seq_len: int,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.item_emb_matrix = nn.Embedding(\n",
    "            num_embeddings=num_items + 1,\n",
    "            embedding_dim=hidden_dim,\n",
    "        )\n",
    "        self.positional_emb = nn.Embedding(\n",
    "            num_embeddings=max_seq_len,\n",
    "            embedding_dim=hidden_dim,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.item_emb_matrix(x)\n",
    "        x *= self.hidden_dim ** 0.5\n",
    "\n",
    "        batch_size = x.shape[0]\n",
    "        seq_len = x.shape[1]\n",
    "        device = x.device.type\n",
    "\n",
    "        positions = torch.tile(torch.arange(seq_len, device=device), dims=(batch_size, 1))\n",
    "\n",
    "        positional_embs = self.positional_emb(positions)\n",
    "        x += positional_embs\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class SASRec(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_items: int,\n",
    "        num_blocks: int,\n",
    "        hidden_dim: int,\n",
    "        max_seq_len: int,\n",
    "        dropout_p: float,\n",
    "        device: str,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        self.embedding_layer = EmbeddingLayer(\n",
    "            num_items=num_items,\n",
    "            hidden_dim=hidden_dim,\n",
    "            max_seq_len=max_seq_len,\n",
    "        )\n",
    "        self_attn_blocks = [\n",
    "            SelfAttnBlock(\n",
    "                max_seq_len=max_seq_len,\n",
    "                hidden_dim=hidden_dim,\n",
    "                dropout_p=dropout_p,\n",
    "                device=device,\n",
    "            )\n",
    "            for _ in range(num_blocks)\n",
    "        ]\n",
    "        self.self_attn_blocks = nn.Sequential(*self_attn_blocks)\n",
    "\n",
    "        self.dropout = nn.Dropout(p=dropout_p)\n",
    "        self.layer_norm = nn.LayerNorm(normalized_shape=hidden_dim)\n",
    "\n",
    "    def get_padding_mask(self, seqs: torch.Tensor) -> torch.Tensor:\n",
    "        is_padding = seqs == 0\n",
    "        padding_mask = ~is_padding\n",
    "\n",
    "        return padding_mask\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_seqs: torch.Tensor,\n",
    "        item_idxs: torch.Tensor = None,\n",
    "        positive_seqs: torch.Tensor = None,\n",
    "        negative_seqs: torch.Tensor = None,\n",
    "    ) -> torch.Tensor:\n",
    "        padding_mask = self.get_padding_mask(seqs=input_seqs)\n",
    "\n",
    "        input_embs = self.dropout(self.embedding_layer(input_seqs))\n",
    "        input_embs *= padding_mask.unsqueeze(-1)\n",
    "\n",
    "        # For loop because nn.Sequential can't handle multiple inputs.\n",
    "        attn_output = input_embs\n",
    "        for block in self.self_attn_blocks:\n",
    "            attn_output = block(x=attn_output, padding_mask=padding_mask)\n",
    "        attn_output = self.layer_norm(attn_output)\n",
    "\n",
    "        if item_idxs is not None:  # Inference.\n",
    "            item_embs = self.embedding_layer.item_emb_matrix(item_idxs)\n",
    "            logits = attn_output @ item_embs.transpose(2, 1)\n",
    "            logits = logits[:, -1, :]\n",
    "            outputs = (logits,)\n",
    "        elif (positive_seqs is not None) and (negative_seqs is not None):  # Training.\n",
    "            positive_embs = self.dropout(self.embedding_layer(positive_seqs))\n",
    "            negative_embs = self.dropout(self.embedding_layer(negative_seqs))\n",
    "\n",
    "            positive_logits = (attn_output * positive_embs).sum(dim=-1)\n",
    "            negative_logits = (attn_output * negative_embs).sum(dim=-1)\n",
    "\n",
    "            outputs = (positive_logits,)\n",
    "            outputs += (negative_logits,)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobre os dados de entrada\n",
    "\n",
    "Conforme feito originalmente, seguimos a estratégia de geramento de amostras\n",
    "negativas para as recomendações, isto é, para cada recomendação esperada, \n",
    "geramos aleatoriamente exemplos de recomendações negativas (\"errada\"), desse\n",
    "modo alcançando resultados melhores e expandindo o conjunto de dados.\n",
    "\n",
    "Além disso, devido a natureza do modelo, é imporante que as sequências tenham\n",
    "tamanho fixo, por conta disso é feito um processamento de _padding_ ou \n",
    "truncamento da amostra para que tenha esse tamanho. Isso também influenciou o\n",
    "nosso mapeamento anterior dos itens em identificadores numéricos, inciando a\n",
    "sequência a partir do 1, já que usaremos o 0 como identificador de padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_negatives = {}\n",
    "\n",
    "# This will be only used by test/eval\n",
    "def get_or_generate_negatives(iid: int, sample_size: int = 100) -> list[int]:\n",
    "    global sample_negatives\n",
    "    if iid not in sample_negatives:\n",
    "        sample_negatives[iid] = np.random.randint(1, max_iid, size=sample_size)\n",
    "    return sample_negatives[iid]\n",
    "\n",
    "# This will be only used by train\n",
    "def gen_negative(iid: int) -> int:\n",
    "    global max_iid\n",
    "    while True:\n",
    "        negative = np.random.randint(1, max_iid)\n",
    "        if negative != iid:\n",
    "            return negative\n",
    "\n",
    "def pad_or_truncate_seq(\n",
    "    sequence: list[int],\n",
    "    max_seq_len: int,\n",
    ") -> torch.Tensor:\n",
    "    if isinstance(sequence, list) or isinstance(sequence, np.ndarray):\n",
    "        sequence = torch.tensor(sequence)\n",
    "\n",
    "    if len(sequence) > max_seq_len:\n",
    "        sequence = sequence[-max_seq_len:]\n",
    "    else:\n",
    "        diff = max_seq_len - len(sequence)\n",
    "        sequence = F.pad(sequence, pad=(diff, 0))\n",
    "\n",
    "    return sequence\n",
    "\n",
    "class SASRecTrainDataset(Dataset):\n",
    "    def __init__(self, data: list[list[int]], max_seq_len: int = MAX_SEQUENCE_LENGTH):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "        # Pre-pad all sequences\n",
    "        self.sequences = [pad_or_truncate_seq(seq, max_seq_len=max_seq_len) for seq in self.data]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        positive_seq = self.sequences[index]\n",
    "        positive_idxs = torch.where(positive_seq != 0)\n",
    "\n",
    "        input_seq = positive_seq.roll(shifts=-1)\n",
    "\n",
    "        negative_seq = torch.zeros_like(positive_seq)\n",
    "        for i in range(positive_seq.shape[0]):\n",
    "            if positive_seq[i] == 0:\n",
    "                continue\n",
    "\n",
    "            negative_seq[i] = gen_negative(positive_seq[i])\n",
    "\n",
    "        negative_idxs = torch.where(negative_seq != 0)\n",
    "\n",
    "        return input_seq, positive_seq, negative_seq \n",
    "\n",
    "class SASRecEvalDataset(Dataset):\n",
    "    def __init__(self, data: list[tuple[list[int], int]], max_seq_len: int = MAX_SEQUENCE_LENGTH, sample_size: int = 100):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.sample_size = sample_size\n",
    "\n",
    "        # Pre-pad all sequences\n",
    "        self.sequences = [pad_or_truncate_seq(seq, max_seq_len=max_seq_len) for seq, _ in self.data]\n",
    "        self.positives = [positive for _, positive in self.data]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        negative_samples = get_or_generate_negatives(self.positives[index], sample_size=self.sample_size)\n",
    "        return self.sequences[index], torch.tensor([self.positives[index], *negative_samples])\n",
    "    \n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=SASRecTrainDataset(data=train_data, max_seq_len=MAX_SEQUENCE_LENGTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=8,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=SASRecEvalDataset(data=test_data, max_seq_len=MAX_SEQUENCE_LENGTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    ")\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "    dataset=SASRecEvalDataset(data=validation_data, max_seq_len=MAX_SEQUENCE_LENGTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento\n",
    "\n",
    "Por fim chegamos ao treinamento do modelo. Usaremos duas métricas de avaliação,\n",
    "o NDCG@10 (Normalized Discounted Cumulative Gain nas 10 primeiras recomendações)\n",
    "e o HIT@10 (Hit Rate nas 10 primeiras recomendações). Para mais informações sobre,\n",
    "recomendamos a leitura na página do [EvidentlyAI](https://www.evidentlyai.com/ranking-metrics/evaluating-recommender-systems#hit-rate).\n",
    "Que explica melhor essas métricas.\n",
    "\n",
    "Para o treinamento, usamos um _batch size_ de 1024 e uma taxa\n",
    "de aprendizado fixa de 0.01. Para o otimizador usamos o AdamW e como função de \n",
    "perda usamos o BCELossWithLogits (Binary Cross Entropy with Logits).\n",
    "\n",
    "Mais informações sobre os parâmetros de treinamento estão no começo do notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T19:11:12.623423Z",
     "start_time": "2024-11-23T19:11:12.602836Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_loss(\n",
    "    positive_idxs: torch.Tensor,\n",
    "    negative_idxs: torch.Tensor,\n",
    "    positive_logits: torch.Tensor,\n",
    "    negative_logits: torch.Tensor,\n",
    ") -> torch.Tensor:\n",
    "    global bce_criterion, PYTORCH_DEVICE\n",
    "\n",
    "    positive_logits = positive_logits[positive_idxs]\n",
    "    positive_labels = torch.ones(size=positive_logits.shape, device=PYTORCH_DEVICE)\n",
    "\n",
    "    negative_logits = negative_logits[negative_idxs]\n",
    "    negative_labels = torch.zeros(size=negative_logits.shape, device=PYTORCH_DEVICE)\n",
    "\n",
    "    positive_loss = bce_criterion(positive_logits, positive_labels)\n",
    "    negative_loss = bce_criterion(negative_logits, negative_labels)\n",
    "\n",
    "    return positive_loss + negative_loss\n",
    "\n",
    "def evaluate_model(\n",
    "    model: SASRec,\n",
    "    loader: DataLoader,\n",
    "    device: str = PYTORCH_DEVICE,\n",
    "    autocast: bool = False,\n",
    "    autocast_dtype: torch.dtype = torch.bfloat16,\n",
    ") -> tuple[float, float]:\n",
    "    global EVAL_K\n",
    "    ndcg = 0\n",
    "    hit = 0\n",
    "    total = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=\"Evaluating Validation: \", total=len(loader), leave=False):\n",
    "            input_seqs, item_idxs = batch\n",
    "            total += input_seqs.shape[0]\n",
    "\n",
    "            input_seqs = input_seqs.to(device)\n",
    "            item_idxs = item_idxs.to(device)\n",
    "\n",
    "            if autocast:\n",
    "                with torch.amp.autocast(device_type=device, dtype=autocast_dtype):\n",
    "                    outputs = model(input_seqs, item_idxs=item_idxs)\n",
    "            else:\n",
    "                outputs = model(input_seqs, item_idxs=item_idxs)\n",
    "\n",
    "            logits = -outputs[0]\n",
    "\n",
    "            # Metal shenanigans\n",
    "            if logits.device.type == 'mps':\n",
    "                logits = logits.detach().cpu()\n",
    "            \n",
    "            ranks = logits.argsort().argsort()\n",
    "            ranks = [r[0].item() for r in ranks]\n",
    "\n",
    "            for rank in ranks:\n",
    "                if rank < EVAL_K:\n",
    "                    ndcg += 1 / np.log2(rank + 2)\n",
    "                    hit += 1\n",
    "        \n",
    "    ndcg /= total\n",
    "    hit /= total\n",
    "\n",
    "    return ndcg, hit\n",
    "\n",
    "def train_model(\n",
    "    model: SASRec,\n",
    "    optimizer: optim.Optimizer,\n",
    "    scheduler: optim.lr_scheduler.LRScheduler | None,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    num_epochs: int,\n",
    "    device: str = PYTORCH_DEVICE,\n",
    "    autocast: bool = False,\n",
    "    autocast_dtype: torch.dtype = torch.bfloat16,\n",
    ") -> tuple[list[float], list[float], list[float], tuple[dict, dict, dict], tuple[dict, dict, dict]]:\n",
    "    global positive2negatives\n",
    "\n",
    "    best_ndcg = 0\n",
    "    best_hit = 0\n",
    "    best_ndcg_epoch = 0\n",
    "    best_hit_epoch = 0\n",
    "\n",
    "    losses = []\n",
    "    ndcgs = []\n",
    "    hits = []\n",
    "    lrs = []\n",
    "\n",
    "    best_ncdg_model_state = None\n",
    "    best_ncdg_optimizer_state = None\n",
    "    best_ncdg_scheduler_state = None\n",
    "\n",
    "    best_hit_model_state = None\n",
    "    best_hit_optimizer_state = None \n",
    "    best_hit_scheduler_state = None\n",
    "\n",
    "    # Plot the loss and other metrics\n",
    "\n",
    "    fig_loss_widget = go.FigureWidget(layout=go.Layout(title=\"Loss\"))\n",
    "    fig_ndcg_widget = go.FigureWidget(layout=go.Layout(title=\"NDCG@\" + str(EVAL_K)))\n",
    "    fig_hit_widget = go.FigureWidget(layout=go.Layout(title=\"HIT@\" + str(EVAL_K)))\n",
    "    fig_lr_widget = go.FigureWidget(layout=go.Layout(title=\"Learning Rate\"))\n",
    "\n",
    "\n",
    "    fig_loss_widget.add_scatter(x=np.arange(len(losses)) + 1, y=losses)\n",
    "    fig_ndcg_widget.add_scatter(x=np.arange(len(ndcgs)) + 1, y=ndcgs)\n",
    "    fig_hit_widget.add_scatter(x=np.arange(len(hits)) + 1, y=hits)\n",
    "    fig_lr_widget.add_scatter(x=np.arange(len(lrs)) + 1, y=lrs)\n",
    "\n",
    "    fig_loss_widget.update_xaxes(title_text='Epoch')\n",
    "    fig_ndcg_widget.update_xaxes(title_text='Epoch')\n",
    "    fig_hit_widget.update_xaxes(title_text='Epoch')\n",
    "    fig_lr_widget.update_xaxes(title_text='Epoch')\n",
    "    \n",
    "    fig_loss_widget.update_yaxes(title_text='Loss', type='log')\n",
    "    fig_ndcg_widget.update_yaxes(title_text='NDCG@' + str(EVAL_K))\n",
    "    fig_hit_widget.update_yaxes(title_text='Epoch@' + str(EVAL_K))\n",
    "    fig_lr_widget.update_yaxes(title_text='Learning Rate')\n",
    "\n",
    "    display(HBox([fig_loss_widget, fig_lr_widget]))\n",
    "    display(HBox([fig_ndcg_widget, fig_hit_widget]))\n",
    "\n",
    "    # Wait for widgets to load\n",
    "    time.sleep(1)\n",
    "\n",
    "    steps = 0\n",
    "    for epoch in tqdm(range(num_epochs), desc=\"Epoch: \"):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        lrs.append([pg['lr'] for pg in optimizer.param_groups][0])\n",
    "\n",
    "        for batch in tqdm(train_loader, desc=\"Training: \", total=len(train_loader), leave=False):\n",
    "            model.zero_grad()\n",
    "\n",
    "            input_seqs, positive_seqs, negative_seqs = batch\n",
    "            positive_idxs, negative_idxs = torch.where(positive_seqs != 0), torch.where(negative_seqs != 0)\n",
    "\n",
    "            input_seqs = input_seqs.to(device)\n",
    "            positive_seqs = positive_seqs.to(device)\n",
    "            negative_seqs = negative_seqs.to(device)\n",
    "\n",
    "            if autocast:\n",
    "                with torch.amp.autocast(device_type=device, dtype=autocast_dtype):\n",
    "                    output = model(input_seqs, positive_seqs=positive_seqs, negative_seqs=negative_seqs)\n",
    "        \n",
    "                    positive_logits = output[0]\n",
    "                    negative_logits = output[1]\n",
    "        \n",
    "                    loss = compute_loss(positive_idxs, negative_idxs, positive_logits, negative_logits)\n",
    "            else:\n",
    "                output = model(input_seqs, positive_seqs=positive_seqs, negative_seqs=negative_seqs)\n",
    "    \n",
    "                positive_logits = output[0]\n",
    "                negative_logits = output[1]\n",
    "    \n",
    "                loss = compute_loss(positive_idxs, negative_idxs, positive_logits, negative_logits)\n",
    "                \n",
    "            loss.backward()\n",
    "            epoch_loss += loss.item()\n",
    "            optimizer.step()\n",
    "\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "            \n",
    "            steps += 1\n",
    "\n",
    "        ndcg, hit = evaluate_model(model, val_loader, device=device, autocast=autocast, autocast_dtype=autocast_dtype)\n",
    "\n",
    "        if ndcg > best_ndcg:\n",
    "            best_ndcg = ndcg\n",
    "            best_ndcg_epoch = epoch\n",
    "            best_ncdg_model_state = copy.deepcopy(model.state_dict())\n",
    "            best_ncdg_optimizer_state = copy.deepcopy(optimizer.state_dict())\n",
    "            if scheduler is not None:\n",
    "                best_ncdg_scheduler_state = copy.deepcopy(scheduler.state_dict())\n",
    "        \n",
    "        if hit > best_hit:\n",
    "            best_hit = hit\n",
    "            best_hit_epoch = epoch\n",
    "            best_hit_model_state = copy.deepcopy(model.state_dict())\n",
    "            best_hit_optimizer_state = copy.deepcopy(optimizer.state_dict())\n",
    "            if scheduler is not None:\n",
    "                best_hit_scheduler_state = copy.deepcopy(scheduler.state_dict())\n",
    "        \n",
    "        losses.append(epoch_loss)\n",
    "        ndcgs.append(ndcg)\n",
    "        hits.append(hit)\n",
    "\n",
    "        \n",
    "        fig_loss_widget.data[0].x = np.arange(len(losses)) + 1\n",
    "        fig_loss_widget.data[0].y = losses\n",
    "        fig_ndcg_widget.data[0].x = np.arange(len(ndcgs)) + 1\n",
    "        fig_ndcg_widget.data[0].y = ndcgs\n",
    "        fig_hit_widget.data[0].x = np.arange(len(hits)) + 1\n",
    "        fig_hit_widget.data[0].y = hits\n",
    "        fig_lr_widget.data[0].x = np.arange(len(lrs)) + 1\n",
    "        fig_lr_widget.data[0].y = lrs\n",
    "\n",
    "    print(f\"Best NDCG@{EVAL_K} Epoch: {best_ndcg_epoch + 1}, NDCG@{EVAL_K}: {best_ndcg:.4f}\")\n",
    "    print(f\"Best HIT@{EVAL_K} Epoch: {best_hit_epoch + 1}, HIT@{EVAL_K}: {best_hit:.4f}\")\n",
    "    \n",
    "    return losses, ndcgs, hits, \\\n",
    "        (best_ncdg_model_state, best_ncdg_optimizer_state, best_ncdg_scheduler_state), \\\n",
    "        (best_hit_model_state, best_hit_optimizer_state, best_hit_scheduler_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T19:54:39.148753Z",
     "start_time": "2024-11-23T19:11:12.627671Z"
    }
   },
   "outputs": [],
   "source": [
    "model = SASRec(num_items=max_iid, num_blocks=NUM_BLOCKS, hidden_dim=HIDDEN_DIM, \n",
    "               max_seq_len=MAX_SEQUENCE_LENGTH, dropout_p=DROPOUT_PROB, device=PYTORCH_DEVICE)\n",
    "\n",
    "model.to(PYTORCH_DEVICE)\n",
    "\n",
    "bce_criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, betas=(BETA_1, BETA_2), eps=EPS, weight_decay=WEIGHT_DECAY, amsgrad=AMSGRAD)\n",
    "\n",
    "scheduler = None\n",
    "if USE_SCHEDULER:\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer=optimizer,\n",
    "        max_lr=LEARNING_RATE,\n",
    "        total_steps=TOTAL_EPOCHS * len(train_dataloader),\n",
    "        pct_start=WARMUP_RATIO,\n",
    "        anneal_strategy=\"linear\",\n",
    "    )\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    results = train_model(model, optimizer, scheduler, train_dataloader, validation_dataloader, TOTAL_EPOCHS, device=PYTORCH_DEVICE, autocast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T20:10:16.927522Z",
     "start_time": "2024-11-23T20:10:15.921893Z"
    }
   },
   "outputs": [],
   "source": [
    "losses, ndcgs, hits, \\\n",
    "    (best_ncdg_model_state, best_ncdg_optimizer_state, best_ncdg_scheduler_state), \\\n",
    "    (best_hit_model_state, best_hit_optimizer_state, best_hit_scheduler_state) = results\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "os.makedirs(f\"models/sasrec/{timestamp}/\", exist_ok=True)\n",
    "\n",
    "torch.save(best_ncdg_model_state, f\"models/sasrec/{timestamp}/best_ncdg_model_state.pt\")\n",
    "torch.save(best_hit_model_state, f\"models/sasrec/{timestamp}/best_hit_model_state.pt\")\n",
    "\n",
    "torch.save(best_ncdg_optimizer_state, f\"models/sasrec/{timestamp}/best_ncdg_optimizer_state.pt\")\n",
    "torch.save(best_hit_optimizer_state, f\"models/sasrec/{timestamp}/best_hit_optimizer_state.pt\")\n",
    "\n",
    "torch.save(best_ncdg_scheduler_state, f\"models/sasrec/{timestamp}/best_ncdg_scheduler_state.pt\")\n",
    "torch.save(best_hit_scheduler_state, f\"models/sasrec/{timestamp}/best_hit_scheduler_state.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500
         ],
         "y": [
          2869.831738948822,
          150.00612497329712,
          134.60798966884613,
          133.62138104438782,
          131.3324338197708,
          127.47119867801666,
          122.42657589912415,
          116.83692216873169,
          111.08707058429718,
          105.49138569831848,
          100.16961538791656,
          95.08330368995667,
          90.78815269470215,
          86.67842161655426,
          83.24717265367508,
          80.30926650762558,
          77.53919875621796,
          75.14811581373215,
          72.84569329023361,
          70.372110247612,
          67.89820456504822,
          65.45184224843979,
          63.39765876531601,
          61.24041390419006,
          59.233172595500946,
          57.55138564109802,
          55.856700241565704,
          54.264486730098724,
          52.78279274702072,
          51.39166021347046,
          50.0414192378521,
          48.57490295171738,
          47.33571317791939,
          46.08433982729912,
          44.95359832048416,
          43.702007591724396,
          42.71855226159096,
          41.67545419931412,
          40.675541162490845,
          39.633527010679245,
          38.81154617667198,
          37.70528319478035,
          36.9832022190094,
          36.11825376749039,
          35.381712198257446,
          34.528574109077454,
          33.86712044477463,
          33.05104619264603,
          32.48390311002731,
          31.8813653588295,
          31.25998142361641,
          30.670007437467575,
          30.071475833654404,
          29.4963221848011,
          28.881715774536133,
          28.502092003822327,
          27.938099026679993,
          27.61123102903366,
          27.089243918657303,
          26.767117768526077,
          26.452527344226837,
          26.000570073723793,
          25.77964447438717,
          25.438893631100655,
          25.07711410522461,
          24.70708131790161,
          24.54722870886326,
          24.196296378970146,
          24.012894555926323,
          23.747426122426987,
          23.507234439253807,
          23.202699825167656,
          23.11444951593876,
          22.900862589478493,
          22.591303035616875,
          22.482593029737473,
          22.18402996659279,
          22.07607840001583,
          21.972232595086098,
          21.685321271419525,
          21.65888512134552,
          21.464394703507423,
          21.206818744540215,
          21.100575014948845,
          21.008974716067314,
          20.832376584410667,
          20.680109903216362,
          20.673134073615074,
          20.388073980808258,
          20.365873605012894,
          20.239184841513634,
          20.17034587264061,
          19.86769162118435,
          19.778455808758736,
          19.78964476287365,
          19.701051473617554,
          19.478936284780502,
          19.399999633431435,
          19.348926097154617,
          19.194526225328445,
          19.0847589969635,
          19.02602879703045,
          19.052096232771873,
          18.86812087893486,
          18.747629910707474,
          18.731623008847237,
          18.64135867357254,
          18.49984022974968,
          18.524061992764473,
          18.471771001815796,
          18.383189722895622,
          18.27190388739109,
          18.171474531292915,
          18.120336189866066,
          18.12663908302784,
          18.068236723542213,
          18.013349324464798,
          17.785225316882133,
          17.810949191451073,
          17.749279782176018,
          17.644368663430214,
          17.690898150205612,
          17.57226838171482,
          17.640473812818527,
          17.46346129477024,
          17.41788336634636,
          17.38603599369526,
          17.20230683684349,
          17.28411355614662,
          17.228303909301758,
          17.222351789474487,
          17.269450709223747,
          17.223252534866333,
          17.15732166171074,
          16.966498091816902,
          16.950083017349243,
          17.027294158935547,
          16.93108080327511,
          16.87474462389946,
          16.82111106812954,
          16.80568663775921,
          16.794066041707993,
          16.74607889354229,
          16.705758333206177,
          16.81411063671112,
          16.68391825258732,
          16.711455643177032,
          16.629181161522865,
          16.665940165519714,
          16.583930730819702,
          16.536935657262802,
          16.601254180073738,
          16.470909252762794,
          16.498710691928864,
          16.57149150967598,
          16.375495955348015,
          16.417918294668198,
          16.44084930419922,
          16.38656537234783,
          16.352196589112282,
          16.342950478196144,
          16.37494358420372,
          16.323487401008606,
          16.247115209698677,
          16.23741489648819,
          16.329328075051308,
          16.106319665908813,
          16.15110109746456,
          16.12938119471073,
          16.181988328695297,
          16.33391310274601,
          16.05432640016079,
          16.187397837638855,
          16.174737498164177,
          16.18781104683876,
          16.080920368433,
          16.180291548371315,
          16.14815978705883,
          16.097249537706375,
          16.175074115395546,
          16.040533632040024,
          16.09710554778576,
          16.083092018961906,
          16.100822776556015,
          16.04756088554859,
          16.037257343530655,
          15.99100050330162,
          15.93205015361309,
          15.92375499010086,
          16.124251291155815,
          16.02771759033203,
          16.095286279916763,
          16.002434849739075,
          15.99447576701641,
          16.066017761826515,
          16.048651561141014,
          15.972858771681786,
          15.8522869348526,
          15.809169843792915,
          15.962436005473137,
          15.847832843661308,
          15.972006246447563,
          15.969476774334908,
          15.948604002594948,
          15.763794258236885,
          15.845932081341743,
          15.774948880076408,
          15.832764729857445,
          15.733010828495026,
          15.70605331659317,
          15.861800894141197,
          15.844156801700592,
          15.70487031340599,
          15.692815646529198,
          15.794595643877983,
          15.860745444893837,
          15.804029241204262,
          15.685919642448425,
          15.751996383070946,
          15.660209372639656,
          15.693578451871872,
          15.6611909866333,
          15.640308201313019,
          15.662136569619179,
          15.628354206681252,
          15.75573816895485,
          15.606350064277649,
          15.691587001085281,
          15.630395501852036,
          15.67224906384945,
          15.75489741563797,
          15.56358227133751,
          15.58281221985817,
          15.600848004221916,
          15.659034132957458,
          15.675188526511192,
          15.586812600493431,
          15.607819855213165,
          15.574643641710281,
          15.406136497855186,
          15.498165309429169,
          15.543938249349594,
          15.669017150998116,
          15.649316787719727,
          15.68819859623909,
          15.598757848143578,
          15.556415900588036,
          15.492672055959702,
          15.703373581171036,
          15.549129232764244,
          15.503841176629066,
          15.711519360542297,
          15.610717937350273,
          15.614441812038422,
          15.628801926970482,
          15.567569062113762,
          15.559562787413597,
          15.431313678622246,
          15.551515772938728,
          15.514671623706818,
          15.373223960399628,
          15.438549160957336,
          15.436505317687988,
          15.419231221079826,
          15.449728041887283,
          15.442906931042671,
          15.512805923819542,
          15.491456374526024,
          15.494636192917824,
          15.438984870910645,
          15.37084475159645,
          15.405530482530594,
          15.438729956746101,
          15.535170510411263,
          15.461668848991394,
          15.410711541771889,
          15.238725319504738,
          15.33024063706398,
          15.233559310436249,
          15.339217200875282,
          15.253845870494843,
          15.342867136001587,
          15.356831833720207,
          15.445566579699516,
          15.305501967668533,
          15.312302261590958,
          15.305799946188927,
          15.222717240452766,
          15.275677621364594,
          15.394243940711021,
          15.314906284213066,
          15.409927383065224,
          15.473655015230179,
          15.35546986758709,
          15.377333045005798,
          15.5103168040514,
          15.281623363494873,
          15.39527228474617,
          15.281385242938995,
          15.178675502538681,
          15.248999178409576,
          15.339748308062553,
          15.385430485010147,
          15.37931165099144,
          15.196678072214127,
          15.342763900756836,
          15.360009476542473,
          15.368415102362633,
          15.36165401339531,
          15.31027166545391,
          15.233214125037193,
          15.272287338972092,
          15.266790077090263,
          15.28384916484356,
          15.189793512225151,
          15.040325835347176,
          15.2317553460598,
          15.220041364431381,
          15.210664108395576,
          15.193648234009743,
          15.180288657546043,
          15.24058024585247,
          15.30459712445736,
          15.270399436354637,
          15.132767960429192,
          15.223359227180481,
          15.279155403375626,
          15.412192806601524,
          15.18629264831543,
          15.211663693189621,
          15.264866948127747,
          15.25861343741417,
          15.299477994441986,
          15.293066889047623,
          15.102003425359726,
          15.056052669882774,
          15.120424136519432,
          15.088931649923325,
          15.096418112516403,
          15.267477467656136,
          15.178093746304512,
          15.293244332075119,
          15.300185024738312,
          15.16985508799553,
          15.289225995540619,
          15.215161636471748,
          15.31835375726223,
          15.283979997038841,
          15.090310111641884,
          15.120153605937958,
          15.082668215036392,
          15.1796253323555,
          15.144457086920738,
          15.214260071516037,
          15.229843631386757,
          14.90480524301529,
          14.904955372214317,
          14.923736944794655,
          15.060440301895142,
          15.034009605646133,
          15.10545265674591,
          15.08496879041195,
          15.094836428761482,
          15.113455682992935,
          15.122807532548904,
          15.008887201547623,
          15.046538025140762,
          15.101059466600418,
          15.01761843264103,
          15.034944921731949,
          15.062154158949852,
          15.074206382036209,
          15.13048492372036,
          15.101686984300613,
          15.110144689679146,
          15.162575393915176,
          15.177644714713097,
          15.139075681567192,
          15.092721194028854,
          14.97764840722084,
          14.88023516535759,
          14.874101534485817,
          14.881666287779808,
          14.933438003063202,
          14.85197202861309,
          15.000737115740776,
          14.974989518523216,
          15.153102651238441,
          15.277197644114494,
          15.183031886816025,
          15.158211216330528,
          14.970397934317589,
          15.094576463103294,
          15.06788744032383,
          15.005138948559761,
          14.92080269753933,
          15.10931271314621,
          15.143221363425255,
          15.143109500408173,
          15.046525239944458,
          14.96960112452507,
          14.953380569815636,
          14.99941298365593,
          14.891645312309265,
          15.008719190955162,
          15.100459679961205,
          14.967865899205208,
          15.084310054779053,
          15.112439811229706,
          15.092497795820236,
          15.070014297962189,
          15.107158526778221,
          14.970780178904533,
          15.001958042383194,
          14.882172107696533,
          14.975208967924118,
          15.053586691617966,
          15.004060059785843,
          14.97509029507637,
          14.849886536598206,
          14.96702167391777,
          15.018171906471252,
          14.942062333226204,
          15.031401216983795,
          15.04010933637619,
          15.141171008348465,
          14.936999917030334,
          14.910373732447624,
          14.998053669929504,
          14.964873015880585,
          15.00161811709404,
          14.948339030146599,
          14.949745878577232,
          14.86565750837326,
          14.763159766793251,
          14.788683116436005,
          14.790188416838646,
          14.87241318821907,
          14.88022693991661,
          14.907827943563461,
          14.85621426999569,
          14.958117485046387,
          14.995007783174515,
          14.970533549785614,
          15.078825175762177,
          14.952385425567627,
          15.112772479653358,
          15.033137768507004,
          14.973399981856346,
          14.96341848373413,
          14.977420076727867,
          14.94195006787777,
          14.92362605035305,
          14.987015843391418,
          15.14965507388115,
          14.955417975783348,
          15.027342438697815,
          15.008254706859589,
          15.028352111577988,
          15.06714004278183,
          15.175761610269547,
          14.924488231539726,
          14.998810216784477,
          14.930512398481369,
          14.890169307589531,
          14.862361714243889,
          14.861398994922638,
          15.009893283247948,
          14.85898806154728,
          14.876518338918686,
          14.750131949782372,
          14.838461071252823,
          14.83235327899456,
          14.830875501036644,
          14.919065296649933,
          14.891710862517357,
          14.867029964923859,
          14.9178396910429,
          14.94418215751648,
          15.087156549096107,
          14.94080001115799,
          15.073450654745102,
          15.180585473775864,
          15.062040090560913,
          14.8020209223032,
          14.926839232444763,
          14.989922195672989,
          15.007873207330704,
          15.03972202539444,
          15.14220541715622,
          15.025732681155205,
          14.952752992510796,
          14.852704375982285,
          14.735038787126541,
          14.904790088534355,
          14.839221075177193,
          14.857287719845772,
          14.76825499534607,
          14.934383377432823,
          14.752290591597557
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Loss"
        },
        "xaxis": {
         "title": {
          "text": "Epoch"
         },
         "type": "log"
        },
        "yaxis": {
         "title": {
          "text": "Loss"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500
         ],
         "y": [
          0.08645076761915928,
          0.08754854454339746,
          0.09322691180200897,
          0.10211824245562966,
          0.11715011555374236,
          0.13224329954800168,
          0.14923147352147978,
          0.16708932362162382,
          0.18540583898210533,
          0.20651557715932609,
          0.22772721520781652,
          0.24978628560571955,
          0.27074569398922926,
          0.29440890713516643,
          0.3122448299480116,
          0.332924729344336,
          0.3489058490127742,
          0.3655874485769838,
          0.3802959363226513,
          0.39130477059749225,
          0.4020939960028191,
          0.4108218612680592,
          0.42035083358138375,
          0.42877833377493596,
          0.4350862142141674,
          0.4399828346340679,
          0.4461586400808937,
          0.45093886558251256,
          0.45581095010586037,
          0.45894802826626796,
          0.4630217686397975,
          0.4669139217601728,
          0.47050748451795743,
          0.47520452798132445,
          0.4799152372736478,
          0.4833485791876768,
          0.4874419107897749,
          0.4908574754322123,
          0.4928750827338534,
          0.4978998042047388,
          0.5024034357160014,
          0.5053403646916158,
          0.5086232517173408,
          0.511696539746275,
          0.5157998233942864,
          0.5163430110218207,
          0.5208253030912496,
          0.5253587354335383,
          0.5276549206491687,
          0.5306254385905741,
          0.5342892876902468,
          0.5378106065390568,
          0.5390129880347608,
          0.5427093049780837,
          0.545247436221113,
          0.5467790195153951,
          0.5477513385914257,
          0.5530902869531678,
          0.5552055558016193,
          0.5561080740354594,
          0.5584299109058176,
          0.5620361423627708,
          0.5621961853006493,
          0.5649826699395878,
          0.5659583041950071,
          0.5683497551818801,
          0.5687238252319887,
          0.5719737487174572,
          0.5734547753210503,
          0.5754950418497498,
          0.5743329261617169,
          0.5768780211498137,
          0.5800634315544209,
          0.5818028356775822,
          0.5820557269036979,
          0.584821025756951,
          0.585368420990468,
          0.5870778544312732,
          0.5870839573693287,
          0.5888181632848564,
          0.590154408126726,
          0.5909390897025052,
          0.5933363445277382,
          0.594607074307631,
          0.594986367275834,
          0.5972657135570412,
          0.597232212102799,
          0.5986406279679902,
          0.5998177099340081,
          0.601959057581385,
          0.6032596521249081,
          0.6036432902498831,
          0.6053885634247561,
          0.6059138637631004,
          0.60652281121833,
          0.6075456188863166,
          0.6094083353399987,
          0.6101955695900066,
          0.6115203779905354,
          0.6129861145201958,
          0.614749294745294,
          0.614111767610246,
          0.6154448346282018,
          0.6163748982773214,
          0.6180946068958104,
          0.6196713186258405,
          0.6203976199588872,
          0.6210254804181601,
          0.6213822556247194,
          0.6219227146766875,
          0.6227905414695942,
          0.6239173329409013,
          0.6262608055149527,
          0.6259595727678339,
          0.6268990459747228,
          0.6281027292562721,
          0.6296888703420943,
          0.6304149394714155,
          0.6302409130624602,
          0.630996388009521,
          0.6329461495492817,
          0.6325454826070582,
          0.6333138393234214,
          0.6336414934136442,
          0.6347686413637186,
          0.6352500540460547,
          0.6362919013112901,
          0.637119960060145,
          0.637364606179019,
          0.6378127522296506,
          0.638227052126235,
          0.6401081153059773,
          0.6398678095905634,
          0.6404783547801882,
          0.6412402809854725,
          0.6405330560221002,
          0.6409325717555998,
          0.6421339329809889,
          0.6420234410473614,
          0.6421873221904831,
          0.6448667698937658,
          0.6444115123968959,
          0.6454110006059636,
          0.6449455951832387,
          0.6460718562145784,
          0.645669309472875,
          0.6475548222173695,
          0.6472305847328941,
          0.6488520702915023,
          0.6480099744285306,
          0.648581259857675,
          0.6494072372952707,
          0.6505940185843779,
          0.6495244319114554,
          0.6502696469005207,
          0.6503721655122008,
          0.6513031784569537,
          0.6529003019696501,
          0.6510566461295075,
          0.6529819284359919,
          0.6526059629501619,
          0.6537099815521582,
          0.654041772533364,
          0.6545762193106641,
          0.6544188953350419,
          0.6545698005200312,
          0.6547390240128542,
          0.6543050704665452,
          0.655703221059704,
          0.6549254764609472,
          0.6555758081644504,
          0.6570369382695764,
          0.6557514155927612,
          0.6573662774784141,
          0.6583455981134576,
          0.6575610720290043,
          0.6578418846247891,
          0.6586541902412796,
          0.6598988243750525,
          0.659776330661173,
          0.6600684213894851,
          0.6609329771993592,
          0.6597708266630067,
          0.6619549272766808,
          0.6606361852216927,
          0.6610846671063413,
          0.6623420397371645,
          0.6615399282981687,
          0.6620856780893369,
          0.6625911969678485,
          0.661870812678745,
          0.6624125575418509,
          0.6624311718856406,
          0.6630993477583261,
          0.6643374370372128,
          0.6633710049218494,
          0.6632528908880451,
          0.6657154405340355,
          0.664443323425137,
          0.6642679374833561,
          0.6647375162218093,
          0.6651265513575721,
          0.6649693462455317,
          0.6659190332248075,
          0.6655740366673573,
          0.6649457622329539,
          0.6667149705494111,
          0.6667235399954555,
          0.6661350046552449,
          0.6665687013922302,
          0.6667004760586396,
          0.6678460284152158,
          0.6680765213694562,
          0.6677456181324586,
          0.6671231348601927,
          0.6678649605432074,
          0.6679920476903525,
          0.66899816630725,
          0.6681040210561189,
          0.669375012862968,
          0.6696341617901859,
          0.6689257427715931,
          0.6704426273706582,
          0.6693961222950189,
          0.6688993580921653,
          0.6703298068222114,
          0.6703681580326832,
          0.6710242675182106,
          0.671181761313745,
          0.672321004101619,
          0.6704231326773569,
          0.670297332265455,
          0.672041605010119,
          0.6713379401500271,
          0.671397584642973,
          0.6724856415602336,
          0.6724724170482103,
          0.6726277747661376,
          0.6717410557249659,
          0.6721679862148624,
          0.6724800724532155,
          0.6724626956979923,
          0.6723833371660981,
          0.6726040599238023,
          0.6733169236867043,
          0.6724493637972191,
          0.6727191974053152,
          0.672885609888071,
          0.6736028690052607,
          0.6735858250402255,
          0.6724390046292396,
          0.6732510193553106,
          0.6732377397389421,
          0.6745738011690873,
          0.6748225640608732,
          0.6749758947182783,
          0.6747202793341773,
          0.6737262312780329,
          0.6744409509473815,
          0.6753008582124023,
          0.6749902378912216,
          0.674891452239741,
          0.6759143490883645,
          0.6763645974569131,
          0.6754662023443265,
          0.6766914265204551,
          0.67635255652264,
          0.6746669048708653,
          0.6757162652302122,
          0.6756272307942154,
          0.6768880523081974,
          0.676530230211912,
          0.676262161117529,
          0.6772466196555644,
          0.6771136132705764,
          0.677081855030359,
          0.6768805481672153,
          0.6774868677594256,
          0.6772806149106686,
          0.6767960773508525,
          0.6764470961258492,
          0.6774780365905106,
          0.6771083425539255,
          0.6769538202942956,
          0.6765961943225997,
          0.6777782294085256,
          0.6773135188509346,
          0.6779324386883103,
          0.6771842261550032,
          0.6791507799120184,
          0.6782026575507634,
          0.6766259349971165,
          0.678948187486481,
          0.6787355918698245,
          0.6772785052875692,
          0.6790073160004376,
          0.6789703556252096,
          0.6787531690857617,
          0.6775709206529061,
          0.6798039681120338,
          0.6792912978486634,
          0.6786723167001963,
          0.6793273994704928,
          0.6795527980450712,
          0.6799792562617691,
          0.6793061269038984,
          0.6800418157180422,
          0.6804390477309393,
          0.6808706248105257,
          0.6806448829494461,
          0.6808824953955999,
          0.6809926232547213,
          0.6818986166662573,
          0.6809915728737691,
          0.6809399203981263,
          0.6813769725924548,
          0.6812060451486712,
          0.6804926730324496,
          0.6806766949861327,
          0.6802711535725771,
          0.6812258285081598,
          0.6804479771760519,
          0.6804320355311954,
          0.6793536069396241,
          0.6819949097073309,
          0.6811103497950708,
          0.6806255065393164,
          0.6816262414193318,
          0.680961227309637,
          0.6820917229270991,
          0.6810398538884683,
          0.6818980808380634,
          0.6816604956022058,
          0.6828105842955532,
          0.6823337875879618,
          0.6828079477364071,
          0.6822627985852349,
          0.6826744432313305,
          0.6837636596602571,
          0.6835556050667758,
          0.683271015424985,
          0.6825698193372927,
          0.682992367961475,
          0.6820827286978224,
          0.6827130807003029,
          0.6833769196850887,
          0.683133028827737,
          0.6834866485142707,
          0.6837357491230457,
          0.6836264557301864,
          0.682796640417326,
          0.6836409220400739,
          0.6842192897753111,
          0.6840535775308896,
          0.6831270094972125,
          0.6844605309125571,
          0.684135231193506,
          0.6837886947737902,
          0.6846583518364456,
          0.6837980266304972,
          0.6853501042266829,
          0.6846457939332906,
          0.685067332000505,
          0.6843002926333629,
          0.6842943858946865,
          0.6858348567822068,
          0.6850806593095435,
          0.6853240561564461,
          0.6848489208212077,
          0.6853506795425416,
          0.6850658505972239,
          0.6841330576967973,
          0.6848318079671623,
          0.6853454361152906,
          0.6843231136920376,
          0.6850690666574986,
          0.684196121875135,
          0.6850091205128809,
          0.685351229721273,
          0.6854152614131596,
          0.6863003709070006,
          0.6853757019713791,
          0.6859240688034615,
          0.6853344439963678,
          0.6852523158649074,
          0.6858514491032254,
          0.6856691762457857,
          0.6857595981453057,
          0.6854881004720528,
          0.6853412678163276,
          0.6850442306450714,
          0.6852958169442894,
          0.6857468463854312,
          0.6865251698895513,
          0.6862966231874625,
          0.6863106280384148,
          0.6868711260916542,
          0.6863378046122391,
          0.6847962613096821,
          0.6866531250350166,
          0.6878573477283658,
          0.6866529124884625,
          0.6868434856022352,
          0.6861831257243198,
          0.6856842575354503,
          0.6864051304361382,
          0.6875698412649822,
          0.6861849781482426,
          0.6873166851030473,
          0.6873879273765716,
          0.6875745037443644,
          0.6865135242501926,
          0.6873128144861445,
          0.6883520219697924,
          0.6880500733213947,
          0.6866849430249863,
          0.686732178607118,
          0.6869115868132957,
          0.6876186417773246,
          0.6871555549111514,
          0.6872826304900086,
          0.6882983779718401,
          0.6874680906071461,
          0.6883569141810678,
          0.6874004558942174,
          0.6880518426890432,
          0.687434265639008,
          0.6883036814047813,
          0.6874353229161597,
          0.68877650620977,
          0.6873560006226951,
          0.688239973943355,
          0.6883409135303536,
          0.6886941763473411,
          0.6886222386202246,
          0.6890207415022748,
          0.6886173515558184,
          0.689020479637383,
          0.6880523192106868,
          0.6888882430509382,
          0.6880360958657135,
          0.6894156133426819,
          0.6873320779055628,
          0.6891548781066115,
          0.6878375656872651,
          0.6891639131645543,
          0.689850168493019,
          0.6886926736515981,
          0.6894811546091412,
          0.6884539566631528,
          0.68943740940066,
          0.6889045077444479,
          0.6892884396521115,
          0.6896197858555485,
          0.6894251649737985,
          0.6899631157949446,
          0.6895577143478722,
          0.6887845338267758,
          0.688923190618976,
          0.6889131600629645,
          0.6878746721348931,
          0.6895122638702943,
          0.6890162941919482,
          0.6897724534708453,
          0.6901257527418906,
          0.6904243570385775,
          0.6904768294798677,
          0.6889610095558466,
          0.6889859680277578,
          0.6902298802261916,
          0.6902245367801305,
          0.6896263638385256,
          0.6899666384083886,
          0.690192736228575,
          0.6903793862676142,
          0.688692748890855,
          0.690087557244903,
          0.6895856542399003,
          0.6891063389935622,
          0.6900840671400427,
          0.6892830202246163,
          0.6895213854941014,
          0.6885660292167723,
          0.6880480508190796,
          0.6894651911795777,
          0.6897846890355099,
          0.6899838179870479,
          0.6904231947750777,
          0.6889202196495207,
          0.6892724531538106,
          0.6896129518018567,
          0.690385311799392,
          0.6923356544694692,
          0.6916690902527433,
          0.6921133834069045,
          0.6905973528772911,
          0.6911800744313102,
          0.6904989668703314,
          0.6909378192440474,
          0.6893726608492095
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "NDCG@10"
        },
        "xaxis": {
         "title": {
          "text": "Epoch"
         }
        },
        "yaxis": {
         "title": {
          "text": "NDCG@10"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500
         ],
         "y": [
          0.14468164329154773,
          0.1462579123743329,
          0.15866947995531835,
          0.17652972570435646,
          0.2080178726573166,
          0.24067270696288942,
          0.27405982375574034,
          0.306838773737123,
          0.34002730544867815,
          0.3750527491622192,
          0.41011542757850317,
          0.44458235075089986,
          0.4762070249472508,
          0.5099913119026933,
          0.5336601712796326,
          0.5581854288196599,
          0.5782425220305325,
          0.5938935087501551,
          0.6105374208762566,
          0.6212734268338092,
          0.6303338711679285,
          0.6390219684746183,
          0.6476231848082413,
          0.6541144346530967,
          0.6588184187662902,
          0.6621571304455752,
          0.6662157130445575,
          0.6694427206156137,
          0.6738984733771876,
          0.6767903686235571,
          0.6780811716519797,
          0.6801911381407472,
          0.6822390467916097,
          0.685466054362666,
          0.6885068884200074,
          0.6890033511232468,
          0.691448429936701,
          0.6932108725332009,
          0.6936949236688594,
          0.6956063050763311,
          0.6967481692937818,
          0.6989698398907782,
          0.6988953704852923,
          0.7004840511356585,
          0.7011666873526127,
          0.7046667494104505,
          0.7023085515700633,
          0.705188035248852,
          0.7058210251954822,
          0.7046046915725456,
          0.7062306069256548,
          0.7061064912498448,
          0.7078813454139258,
          0.7102891895246369,
          0.7096313764428447,
          0.7097306689834926,
          0.7108228869306193,
          0.712001985850813,
          0.7125729179595383,
          0.7122626287700137,
          0.7142981258532952,
          0.7131686732034256,
          0.7140374829340945,
          0.7130073228248728,
          0.7141864217450664,
          0.7152041702867072,
          0.7148938810971825,
          0.71624674196351,
          0.7165446195854537,
          0.7165570311530346,
          0.7170038475859501,
          0.7191634603450415,
          0.7179098920193621,
          0.7186669976418022,
          0.7202805014273302,
          0.7209010798063795,
          0.7212610152662281,
          0.7201687973191014,
          0.7200943279136155,
          0.7229738115924041,
          0.7235447437011294,
          0.7234330395929006,
          0.7242522030532457,
          0.7246369616482562,
          0.7248479582971329,
          0.7249968971081048,
          0.724748665756485,
          0.7283852550577138,
          0.7269827479210624,
          0.7272185677051012,
          0.7270696288941293,
          0.7284224897604568,
          0.7292912994911257,
          0.7299367010053369,
          0.7311282114931116,
          0.7305821025195482,
          0.7307186297629391,
          0.7312399156013405,
          0.7329899466302594,
          0.7335732903065657,
          0.7346903313888544,
          0.7334119399280129,
          0.7355715526871044,
          0.7354226138761325,
          0.7364279508501924,
          0.7379793967978155,
          0.7379669852302346,
          0.7377684001489389,
          0.7388109718257416,
          0.7380042199329775,
          0.7376939307434529,
          0.7396301352860867,
          0.7396549584212486,
          0.7406727069628894,
          0.7423979148566464,
          0.741826982747921,
          0.7435397790740971,
          0.7450912250217202,
          0.7437880104257167,
          0.7431798436142485,
          0.7437011294526499,
          0.7449919324810723,
          0.7450539903189772,
          0.7462579123743329,
          0.7451160481568823,
          0.7463820280501428,
          0.7477224773488892,
          0.7473004840511357,
          0.7474245997269455,
          0.7482561747548715,
          0.7483306441603574,
          0.7485788755119772,
          0.7484919945389102,
          0.7484671714037483,
          0.7493359811344172,
          0.7500310289189525,
          0.7502172024326672,
          0.7501179098920193,
          0.7494228621074842,
          0.75037855281122,
          0.75214099540772,
          0.7520541144346531,
          0.7526126349757974,
          0.752972570435646,
          0.7524885192999876,
          0.7537048529229242,
          0.7542385503289065,
          0.7543626660047164,
          0.7551197716271565,
          0.7548715402755368,
          0.7545860742211742,
          0.7554176492491002,
          0.7561871664391212,
          0.7571180340076952,
          0.755566588060072,
          0.7565471018989698,
          0.7553928261139382,
          0.7573910884944769,
          0.7576765545488395,
          0.7571800918456001,
          0.7569194489263994,
          0.7569939183318853,
          0.7576765545488395,
          0.7583591907657937,
          0.7596003475238923,
          0.7587935956311282,
          0.7596748169293782,
          0.7582847213603078,
          0.760630507633114,
          0.7594762318480824,
          0.7600719870919698,
          0.7606553307682761,
          0.7596251706590542,
          0.7599602829837409,
          0.7608911505523147,
          0.7610152662281247,
          0.7618964875263746,
          0.7625046543378429,
          0.7634727566091597,
          0.7614372595258782,
          0.7619337222291175,
          0.7627777088246246,
          0.7627777088246246,
          0.7638326920690083,
          0.7636465185552935,
          0.7639195730420753,
          0.7639071614744942,
          0.7648256174754872,
          0.7637458110959414,
          0.7633238177981879,
          0.7641305696909519,
          0.7643539779074097,
          0.764937321583716,
          0.7643415663398287,
          0.7650738488271068,
          0.7644532704480576,
          0.7645897976914484,
          0.766612883207149,
          0.7656447809358322,
          0.7661784783418145,
          0.7654461958545364,
          0.7667742335857018,
          0.7661784783418145,
          0.766699764180216,
          0.7671217574779695,
          0.7667121757477969,
          0.7678043936949237,
          0.7677547474245997,
          0.7674196350999131,
          0.7673948119647511,
          0.767518927640561,
          0.7682512101278391,
          0.7686607918580116,
          0.7688966116420504,
          0.7681643291547723,
          0.7699019486161102,
          0.7690579620206032,
          0.7677547474245997,
          0.7676306317487899,
          0.7682512101278391,
          0.7706962889412933,
          0.7700632989946631,
          0.7704728807248356,
          0.7689710810475363,
          0.76926895866948,
          0.7713168673203425,
          0.770125356832568,
          0.7703611766166066,
          0.7709072855901701,
          0.7698523023457863,
          0.7704108228869306,
          0.7708576393198461,
          0.7716271565098672,
          0.7707211120764552,
          0.7709072855901701,
          0.7725083778081172,
          0.7713292788879236,
          0.7723966736998883,
          0.7713789251582475,
          0.7718381531587439,
          0.7714906292664764,
          0.7712672210500187,
          0.7736874767283107,
          0.7730048405113565,
          0.7731289561871665,
          0.772632493483927,
          0.7728683132679658,
          0.7721360307806876,
          0.7725207893756981,
          0.7719498572669728,
          0.7716768027801911,
          0.7719870919697158,
          0.7724214968350502,
          0.7722477348889165,
          0.7725332009432792,
          0.77430805510736,
          0.7730544867816805,
          0.7733523644036242,
          0.7738364155392826,
          0.7734020106739481,
          0.7740970584584833,
          0.7740970584584833,
          0.7739729427826735,
          0.7753754499193248,
          0.7740101774854165,
          0.7746804021347896,
          0.77443217078317,
          0.77443217078317,
          0.7742832319721981,
          0.7737619461337967,
          0.7746804021347896,
          0.7740722353233214,
          0.7738488271068636,
          0.7750279260270572,
          0.7755616234330396,
          0.7758967357577262,
          0.7751023954325431,
          0.776976542137272,
          0.7749782797567333,
          0.7750775722973812,
          0.7751892764056101,
          0.7761449671093459,
          0.7750403375946382,
          0.7756485044061064,
          0.7749534566215713,
          0.7765049025691945,
          0.7753754499193248,
          0.7755492118654586,
          0.7761822018120889,
          0.7759712051632122,
          0.776020851433536,
          0.776045674568698,
          0.7769641305696909,
          0.776926895866948,
          0.7772123619213107,
          0.7763683753258036,
          0.7761573786769269,
          0.7757353853791734,
          0.7772247734888916,
          0.7774605932729304,
          0.7765917835422614,
          0.7768524264614621,
          0.7765545488395185,
          0.7774233585701874,
          0.7775847089487402,
          0.7775598858135783,
          0.7775474742459972,
          0.7781928757602086,
          0.777783294030036,
          0.7767158992180713,
          0.7771999503537297,
          0.7778081171651979,
          0.7785652227876381,
          0.7783169914360184,
          0.7780067022464937,
          0.7784659302469902,
          0.7788010425716768,
          0.7791609780315254,
          0.7787638078689338,
          0.7788010425716768,
          0.7785155765173142,
          0.778664515328286,
          0.7778577634355219,
          0.7781680526250465,
          0.7790865086260395,
          0.77783294030036,
          0.7777336477597121,
          0.777795705597617,
          0.778639692193124,
          0.7786148690579621,
          0.7783542261387614,
          0.7794588556534691,
          0.7795705597616979,
          0.7790740970584585,
          0.7789499813826486,
          0.7798436142484796,
          0.7801166687352613,
          0.7792478590045923,
          0.7790865086260395,
          0.7787886310040958,
          0.7790368623557156,
          0.7787886310040958,
          0.7800173761946134,
          0.7792478590045923,
          0.7792602705721733,
          0.7806007198709197,
          0.7793967978155641,
          0.779446444085888,
          0.7797567332754127,
          0.7801166687352613,
          0.7803524885193,
          0.7795705597616979,
          0.7802780191138141,
          0.7808117165197964,
          0.7792602705721733,
          0.7805262504654338,
          0.781196475114807,
          0.7805634851681768,
          0.7810475363038352,
          0.7817177609532084,
          0.7821397542509619,
          0.7817922303586943,
          0.7818418766290183,
          0.7816929378180464,
          0.7817177609532084,
          0.782052873277895,
          0.7814571180340077,
          0.7818294650614372,
          0.7819163460345041,
          0.7811592404120641,
          0.7809110090604443,
          0.7824376318729056,
          0.7809606553307683,
          0.7824500434404865,
          0.7815315874394936,
          0.7809358321956062,
          0.781146828844483,
          0.7815688221422366,
          0.7822762814943527,
          0.7816557031153034,
          0.782040461710314,
          0.7819163460345041,
          0.7821645773861239,
          0.7817177609532084,
          0.7823135161970957,
          0.7818542881965992,
          0.7824624550080675,
          0.7830333871167928,
          0.7830830333871168,
          0.7818542881965992,
          0.7819535807372471,
          0.7827975673327541,
          0.7823011046295147,
          0.7830954449546977,
          0.7823507508998386,
          0.7823879856025816,
          0.7839518431177858,
          0.7832195606305077,
          0.7822762814943527,
          0.7831326796574407,
          0.7831575027926027,
          0.7823879856025816,
          0.7826486285217823,
          0.7818915228993422,
          0.7832940300359935,
          0.7823011046295147,
          0.7826858632245253,
          0.7834553804145463,
          0.7840759587935956,
          0.7836043192255182,
          0.7822390467916098,
          0.7831078565222788,
          0.7826858632245253,
          0.7843366017127963,
          0.7841131934963386,
          0.7826734516569442,
          0.7836663770634231,
          0.7840635472260147,
          0.7831575027926027,
          0.7840139009556907,
          0.7834677919821273,
          0.7844855405237682,
          0.7828099789003351,
          0.7839642546853668,
          0.7827727441975921,
          0.7843614248479583,
          0.7847337718753878,
          0.784684125605064,
          0.7840387240908526,
          0.7848578875511977,
          0.7843862479831203,
          0.7832319721980886,
          0.784609656199578,
          0.7843490132803773,
          0.783790492739233,
          0.7853419386868562,
          0.7847834181457118,
          0.7858259898225146,
          0.7840263125232717,
          0.7854288196599231,
          0.7845103636589301,
          0.785490877497828,
          0.7841007819287577,
          0.7847337718753878,
          0.7841131934963386,
          0.7853667618220181,
          0.785466054362666,
          0.7839642546853668,
          0.785416408092342,
          0.7851061189028175,
          0.7855405237681519,
          0.7843862479831203,
          0.7852922924165322,
          0.7856522278763808,
          0.7847958297132928,
          0.7851557651731413,
          0.7846717140374829,
          0.7851681767407224,
          0.7844607173886062,
          0.7838897852798808,
          0.7852922924165322,
          0.78463447933474,
          0.7858011666873526,
          0.7851681767407224,
          0.7851805883083033,
          0.7854039965247611,
          0.7861735137147822,
          0.7853667618220181,
          0.7857391088494476,
          0.7862852178230111,
          0.7856149931736378,
          0.7855901700384759,
          0.7859997517686483,
          0.7862107484175251,
          0.785490877497828,
          0.7869057962020604,
          0.7868065036614125,
          0.786260394687849,
          0.7861859252823632,
          0.7862231599851062,
          0.7851309420379794,
          0.7853419386868562,
          0.785466054362666,
          0.7853543502544371,
          0.7859501054983244,
          0.7857639319846097,
          0.7859128707955815,
          0.7854039965247611,
          0.7856025816060569,
          0.7856398163087998,
          0.7863596872284969,
          0.7861238674444583,
          0.7857266972818667,
          0.7858135782549336,
          0.7868809730668983,
          0.7858135782549336,
          0.7861486905796202,
          0.7858632245252576,
          0.785478465930247,
          0.7855157006329899
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "HIT@10"
        },
        "xaxis": {
         "title": {
          "text": "Epoch"
         }
        },
        "yaxis": {
         "title": {
          "text": "Epoch@10"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = go.Figure(layout = go.Layout(title=\"Loss\"))\n",
    "fig.add_scatter(x=np.arange(len(losses)) + 1, y=losses)\n",
    "fig.update_xaxes(title_text='Epoch', type='log')\n",
    "fig.update_yaxes(title_text='Loss')\n",
    "display(fig)\n",
    "\n",
    "fig = go.Figure(layout = go.Layout(title=\"NDCG@\" + str(EVAL_K)))\n",
    "fig.add_scatter(x=np.arange(len(ndcgs)) + 1, y=ndcgs)\n",
    "fig.update_xaxes(title_text='Epoch')\n",
    "fig.update_yaxes(title_text='NDCG@' + str(EVAL_K))\n",
    "display(fig)\n",
    "\n",
    "fig = go.Figure(layout = go.Layout(title=\"HIT@\" + str(EVAL_K)))\n",
    "fig.add_scatter(x=np.arange(len(hits)) + 1, y=hits)\n",
    "fig.update_xaxes(title_text='Epoch')\n",
    "fig.update_yaxes(title_text='Epoch@' + str(EVAL_K))\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T20:13:30.975385Z",
     "start_time": "2024-11-23T20:13:29.072236Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2239087d3e324c5f980b5b3b88df41d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating Validation:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test NDCG@10: 0.6757\n",
      "Test HIT@10: 0.7704\n",
      "Time taken: 1.4454 seconds\n"
     ]
    }
   ],
   "source": [
    "# Load the best model during training\n",
    "test_model = SASRec(num_items=max_iid, num_blocks=NUM_BLOCKS, hidden_dim=HIDDEN_DIM,\n",
    "                    max_seq_len=MAX_SEQUENCE_LENGTH, dropout_p=DROPOUT_PROB, device=PYTORCH_DEVICE)\n",
    "test_model.to(PYTORCH_DEVICE)\n",
    "test_model.load_state_dict(best_ncdg_model_state)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    start_time = time.time()\n",
    "    ndcg, hit = evaluate_model(test_model, test_dataloader, device=PYTORCH_DEVICE, autocast=False)\n",
    "    end_time = time.time()\n",
    "\n",
    "print(f\"Test NDCG@{EVAL_K}: {ndcg:.4f}\")\n",
    "print(f\"Test HIT@{EVAL_K}: {hit:.4f}\")\n",
    "print(f\"Time taken: {end_time - start_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referências\n",
    "\n",
    "- [Self-Attentive Sequential Recommendation](https://cseweb.ucsd.edu/~jmcauley/pdfs/icdm18.pdf)\n",
    "- [SASRec em PyTorch (por Pmixer)](https://github.com/pmixer/SASRec.pytorch)\n",
    "- [SASRec em PyTorch (por Seanswyi)](https://github.com/seanswyi/sasrec-pytorch)\n",
    "- [Métricas: NDCG e HIT](https://www.evidentlyai.com/ranking-metrics/evaluating-recommender-systems#hit-rate)\n",
    "- [Attention Is All You Need](https://arxiv.org/abs/1706.03762)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys-tp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
